
@inproceedings{10.1145/3613904.3642406,
author = {Benharrak, Karim and Zindulka, Tim and Lehmann, Florian and Heuer, Hendrik and Buschek, Daniel},
title = {Writer-Defined AI Personas for On-Demand Feedback Generation},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642406, https://docs.google.com/document/d/13OMgbLUoBlZCHXLdj4fkpTl4e6cBaI5L-wnkkNmQHBc/edit?tab=t.0},
doi = {10.1145/3613904.3642406},
abstract = {Compelling writing is tailored to its audience. This is challenging, as writers may struggle to empathize with readers, get feedback in time, or gain access to the target group. We propose a concept that generates on-demand feedback, based on writer-defined AI personas of any target audience. We explore this concept with a prototype (using GPT-3.5) in two user studies (N=5 and N=11): Writers appreciated the concept and strategically used personas for getting different perspectives. The feedback was seen as helpful and inspired revisions of text and personas, although it was often verbose and unspecific. We discuss the impact of on-demand feedback, the limited representativity of contemporary AI systems, and further ideas for defining AI personas. This work contributes to the vision of supporting writers with AI by expanding the socio-technical perspective in AI tool design: To empower creators, we also need to keep in mind their relationship to an audience.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {1049},
numpages = {18},
keywords = {Human-AI interaction, Large language models, Personas, Text feedback, Writing assistance},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642535,
author = {Aljuneidi, Saja and Heuten, Wilko and Abdenebaoui, Larbi and Wolters, Maria K and Boll, Susanne},
title = {Why the Fine, AI? The Effect of Explanation Level on Citizens' Fairness Perception of AI-based Discretion in Public Administrations},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642535},
doi = {10.1145/3613904.3642535},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {318},
numpages = {18},
keywords = {Administrative discretion, Algorithmic decision-making, Distributive fairness, Explainable AI, Informational fairness},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642364,
author = {Neuhaus, Robin and Ringfort-Felner, Ronda and Courtney, Daniel and Kneile, Madlen and Hassenzahl, Marc},
title = {Virtual Unreality: Augmentation-Oriented Ideation Through Design Cards},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642364},
doi = {10.1145/3613904.3642364},
abstract = {While realism is a common design goal for virtual reality (VR), VR also offers opportunities that are impossible in the real world (e.g., telekinesis). So far, there is no design support to exploit the potential of such “impossible” augmentations, especially for serious applications. We developed a card set and a workshop format, which features 15 opportunities to facilitate the ideation of augmentation-oriented VR. We piloted the method in five workshops with people in the early stages of developing a VR application (N=35). Participants found the cards easy to use and to inspire viable new concepts that differed from earlier ideas. Analysis of the concepts with interaction criticism identified two strategies: (1) augmentations that are only loosely related to the purpose of the application, simply to increase “fun”, and (2) augmentations that are closely related to the core purpose and thereby subtly facilitate its fulfillment. The latter has the greater potential.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {608},
numpages = {23},
keywords = {augmented human capabilities, design tools, superpowers, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642828,
author = {Vega, Gabriela and Martinez-Missir, Valentin and Wittchen, Dennis and Sabnis, Nihar and Girouard, Audrey and Cochrane, Karen Anne and Strohmeier, Paul},
title = {vARitouch: Back of the Finger Device for Adding Variable Compliance to Rigid Objects},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642828},
doi = {10.1145/3613904.3642828},
abstract = {We present vARitouch, a back-of-the-finger wearable that can modify the perceived tactile material properties of the uninstrumented world around us: vARitouch can modulate the perceived softness of a rigid object through a vibrotactile compliance illusion. As vARitouch does not cover the fingertip, all-natural tactile properties are preserved. We provide three contributions: (1) We demonstrate the feasibility of the concept through a psychophysics study, showing that virtual compliance can be continuously modulated, and perceived softness can be increased by approximately 30 Shore A levels. (2) A qualitative study indicates the desirability of such a device, showing that a back-of-the-finger haptic device has many attractive qualities. (3) To implement vARitouch, we identify a novel way to measure pressure from the back of the finger by repurposing a pulse oximetry sensor. Based on these contributions, we present the finalized vARitouch system, accompanied by a series of application scenarios.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {414},
numpages = {20},
keywords = {compliance, finger wearable, haptic illusion, nail, softness, tactile, wearable haptics},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642585,
author = {Faltaous, Sarah and Williamson, Julie R. and Koelle, Marion and Pfeiffer, Max and Keppel, Jonas and Schneegass, Stefan},
title = {Understanding User Acceptance of Electrical Muscle Stimulation in Human-Computer Interaction},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642585},
doi = {10.1145/3613904.3642585},
abstract = {Electrical Muscle Stimulation (EMS) has unique capabilities that can manipulate users’ actions or perceptions, such as actuating user movement while walking, changing the perceived texture of food, and guiding movements for a user learning an instrument. These applications highlight the potential utility of EMS, but such benefits may be lost if users reject EMS. To investigate user acceptance of EMS, we conducted an online survey (N = 101). We compared eight scenarios, six from HCI research applications and two from the sports and health domain. To gain further insights, we conducted in-depth interviews with a subset of the survey respondents (N = 10). The results point to the challenges and potential of EMS regarding social and technological acceptance, showing that there is greater acceptance of applications that manipulate action than those that manipulate perception. The interviews revealed safety concerns and user expectations for the design and functionality of future EMS applications.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {428},
numpages = {16},
keywords = {Acceptability, Electrical Muscle Stimulation, Social Acceptability},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642086,
author = {Grootjen, Jesse W. and Weing\"{a}rtner, Henrike and Mayer, Sven},
title = {Uncovering and Addressing Blink-Related Challenges in Using Eye Tracking for Interactive Systems},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642086},
doi = {10.1145/3613904.3642086},
abstract = {Currently, interactive systems use physiological sensing to enable advanced functionalities. While eye tracking is a promising means to understand the user, eye tracking data inherently suffers from missing data due to blinks, which may result in reduced system performance. We conducted a literature review to understand how researchers deal with this issue. We uncovered that researchers often implemented their use-case-specific pipeline to overcome the issue, ranging from ignoring missing data to artificial interpolation. With these first insights, we run a large-scale analysis on 11 publicly available datasets to understand the impact of the various approaches on data quality and accuracy. By this, we highlight the pitfalls in data processing and which methods work best. Based on our results, we provide guidelines for handling eye tracking data for interactive systems. Further, we propose a standard data processing pipeline that allows researchers and practitioners to pre-process and standardize their data efficiently.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {322},
numpages = {23},
keywords = {blinks, eye tracking, human computer interaction, interactive systems},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642292,
author = {Dufresne, Florian and Nilsson, Tommy and Gorisse, Geoffrey and Guerra, Enrico and Zenner, Andr\'{e} and Christmann, Olivier and Bensch, Leonie and Callus, Nikolai Anton and Cowley, Aidan},
title = {Touching the Moon: Leveraging Passive Haptics, Embodiment and Presence for Operational Assessments in Virtual Reality},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642292},
doi = {10.1145/3613904.3642292},
abstract = {Space agencies are in the process of drawing up carefully thought-out Concepts of Operations (ConOps) for future human missions on the Moon. These are typically assessed and validated through costly and logistically demanding analogue field studies. While interactive simulations in Virtual Reality (VR) offer a comparatively cost-effective alternative, they have faced criticism for lacking the fidelity of real-world deployments. This paper explores the applicability of passive haptic interfaces in bridging the gap between simulated and real-world ConOps assessments. Leveraging passive haptic props (equipment mockup and astronaut gloves), we virtually recreated the Apollo 12 mission procedure and assessed it with experienced astronauts and other space experts. Quantitative and qualitative findings indicate that haptics increased presence and embodiment, thus improving perceived simulation fidelity and validity of user reflections. We conclude by discussing the potential role of passive haptic modalities in facilitating early-stage ConOps assessments for human endeavours on the Moon and beyond.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {413},
numpages = {18},
keywords = {concepts of operations, embodiment, passive haptic feedback, presence, scenario assessment, space exploration, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,Best Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642411,
author = {Sakel, Sophia and Blenk, Tabea and Schmidt, Albrecht and Haliburton, Luke},
title = {The Social Journal: Investigating Technology to Support and Reflect on Social Interactions},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642411},
doi = {10.1145/3613904.3642411},
abstract = {Social interaction is a crucial part of what it means to be human. Maintaining a healthy social life is strongly tied to positive outcomes for both physical and mental health. While we use personal informatics data to reflect on many aspects of our lives, technology-supported reflection for social interactions is currently under-explored. To address this, we first conducted an online survey (N=124) to understand how users want to be supported in their social interactions. Based on this, we designed and developed an app for users to track and reflect on their social interactions and deployed it in the wild for two weeks (N=25). Our results show that users are interested in tracking meaningful in-person interactions that are currently untraced and that an app can effectively support self-reflection on social interaction frequency and social load. We contribute insights and concrete design recommendations for technology-supported reflection for social interaction.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {1007},
numpages = {18},
keywords = {Reflection, Social Interaction, Well-being},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3641933,
author = {Feick, Martin and Zenner, Andr\'{e} and Seibert, Simon and Tang, Anthony and Kr\"{u}ger, Antonio},
title = {The Impact of Avatar Completeness on Embodiment and the Detectability of Hand Redirection in Virtual Reality},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641933},
doi = {10.1145/3613904.3641933},
abstract = {To enhance interactions in VR, many techniques introduce offsets between the virtual and real-world position of users’ hands. Nevertheless, such hand redirection (HR) techniques are only effective as long as they go unnoticed by users—not disrupting the VR experience. While several studies consider how much unnoticeable redirection can be applied, these focus on mid-air floating hands that are disconnected from users’ bodies. Increasingly, VR avatars are embodied as being directly connected with the user’s body, which provide more visual cue anchoring, and may therefore reduce the unnoticeable redirection threshold. In this work, we studied more complete avatars and their effect on the sense of embodiment and the detectability of HR. We found that higher avatar completeness increases embodiment, and we provide evidence for the absence of practically relevant effects on the detectability of HR.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {548},
numpages = {9},
keywords = {Virtual reality, avatar embodiment, detection thresholds, hand redirection, illusions},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613905.3650875,
author = {Bosch, Esther and Welsch, Robin and Ayach, Tamim and Katins, Christopher and Kosch, Thomas},
title = {The Illusion of Performance: The Effect of Phantom Display Refresh Rates on User Expectations and Reaction Times},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650875},
doi = {10.1145/3613905.3650875},
abstract = {User expectations impact the evaluation of new interactive systems. Increased expectations may enhance the perceived effectiveness of interfaces in user studies, similar to a placebo effect observed in medical studies. To showcase the placebo effect, we conducted a user study with 18 participants who performed a target selection reaction time test with two different display refresh rates. Participants saw a stated screen refresh rate before every condition, which corresponded to the true refresh rate only in half of the conditions and was lower or higher in the other half. Results revealed successful priming, as participants believed in superior or inferior performance based on the narrative despite using the opposite refresh rate. Post-experiment questionnaires confirmed participants still held onto the initial narrative. Interestingly, the objective performance remained unchanged between both refresh rates. We discuss how study narratives influence subjective measures and suggest strategies to mitigate placebo effects in user-centered study designs.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {317},
numpages = {6},
keywords = {Human-AI Interfaces, Placebo, Placebo Effect, Refresh Rates, User Expectations, User Studies},
location = {Honolulu, HI, USA},
series = {CHI EA '24},
tags ={Late Breaking Work,CHI24}
}
@inproceedings{10.1145/3613905.3651058,
author = {Wolf, Sara and Friedrich, Paula and Hurtienne, J\"{o}rn},
title = {Still Not a Lot of Research? Re-Examining HCI Research on Religion and Spirituality},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3651058},
doi = {10.1145/3613905.3651058},
abstract = {A decade after Buie and Blythe’s review "Spirituality: There’s an App for That! (But Not a Lot of Research)", this sequel assesses the evolving landscape of Human-Computer Interaction (HCI) research on religion and spirituality. While the enduring importance of religion and spirituality for humanity and its influence on technology use remains, the last decade has seen transformative shifts catalysed by technological advances and the global impact of the COVID-19 pandemic. This paper explores whether and how HCI research on religion and spirituality has also changed. Providing a snapshot of the current research, we document and reflect on changes in the lines of research with a shift towards community, an increased consideration of religion and spirituality in related areas such as health, education, and society, and the broadening of challenges for HCI research on religion and spirituality.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {302},
numpages = {15},
keywords = {faith, religion, scoping review, spirituality, techno-spirituality},
location = {Honolulu, HI, USA},
series = {CHI EA '24},
tags ={Late Breaking Work,CHI24}
}
@inproceedings{10.1145/3613904.3642657,
author = {Krauter, Christian and Angerbauer, Katrin and Sousa Calepso, Aim\'{e}e and Achberger, Alexander and Mayer, Sven and Sedlmair, Michael},
title = {Sitting Posture Recognition and Feedback: A Literature Review},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642657},
doi = {10.1145/3613904.3642657},
abstract = {Extensive sitting is unhealthy; thus, countermeasures are needed to react to the ongoing trend toward more prolonged sitting. A variety of studies and guidelines have long addressed the question of how we can improve our sitting habits. Nevertheless, sitting time is still increasing. Here, smart devices can provide a general overview of sitting habits for more nuanced feedback on the user’s sitting posture. Based on a literature review (N=223), including publications from engineering, computer science, medical sciences, electronics, and more, our work guides developers of posture systems. There is a large variety of approaches, with pressure-sensing hardware and visual feedback being the most prominent. We found factors like environment, cost, privacy concerns, portability, and accuracy important for deciding hardware and feedback types. Further, one should consider the user’s capabilities, preferences, and tasks. Regarding user studies for sitting posture feedback, there is a need for better comparability and for investigating long-term effects.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {943},
numpages = {20},
keywords = {Literature review, chair, posture, sitting},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags={Full Paper,CHI24}
}
@inproceedings{10.1145/3613905.3650843,
author = {Polenz, Laureen and Joeres, Fabian and Hansen, Christian and Heinrich, Florian},
title = {Simulating projective Augmented Reality Visualizations in Virtual Reality: Is VR a feasible Environment for medical AR Evaluations?},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650843},
doi = {10.1145/3613905.3650843},
abstract = {Augmented Reality (AR) has demonstrated potential in medical applications, such as enhancing surgical navigation. However, evaluating medical AR visualizations entails high costs and effort to provide suitable hardware solutions. This is particularly crucial in projective AR, as these systems require several error-prone calibration and registration steps. This work investigates the suitability of Virtual Reality (VR) as a cost-effective and controlled study environment for evaluating projective AR visualizations. A virtual twin of a real laboratory environment was created, and a user study comparing two needle navigation visualizations was conducted. The study simulated identical experiments in both AR and VR to assess if similar results would emerge. Our findings indicate that both AR and VR experiments exhibited comparable effects in terms of performance and workload of both needle insertion visualizations. This study serves as a preliminary step in demonstrating the feasibility of using VR as an evaluation environment for projective AR visualizations.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {291},
numpages = {8},
keywords = {Medical Augmented Reality, Surgical Navigation, Virtual Reality},
location = {Honolulu, HI, USA},
series = {CHI EA '24},
tags={Late Breaking Work,CHI24}
}
@inproceedings{10.1145/3613904.3641907,
author = {Jingu, Arata and Sabnis, Nihar and Strohmeier, Paul and Steimle, J\"{u}rgen},
title = {Shaping Compliance: Inducing Haptic Illusion of Compliance in Different Shapes with Electrotactile Grains},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641907},
doi = {10.1145/3613904.3641907},
abstract = {Compliance, the degree of displacement under applied force, is pivotal in determining the material perception when touching an object. Vibrotactile actuators can be used for creating grain-based virtual compliance, but they have poor spatial resolution and a limiting rigid form factor. We propose a novel electrotactile compliance illusion that renders grains of electrical pulses on an electrode array in response to finger force changes. We demonstrate its ability to render compliance in distinct shapes through a thin, lightweight, and flexible finger-worn interface. Detailed technical parameters and the implementation of our device are provided. A controlled experiment confirms the technique can (1) create virtual compliance; (2) adjust the compliance magnitude with grain and electrode parameters; and (3) render compliance with specific shapes. In three example applications, we present how this illusion can enhance physical objects, elements in graphical user interfaces, and virtual reality experiences.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {432},
numpages = {13},
keywords = {Haptics, compliance, electrotactile, haptic illusion, virtual reality.},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags={Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642942,
author = {Wang, Yao and Wang, Weitian and Abdelhafez, Abdullah and Elfares, Mayar and Hu, Zhiming and B\^{a}ce, Mihai and Bulling, Andreas},
title = {SalChartQA: Question-driven Saliency on Information Visualisations},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642942},
doi = {10.1145/3613904.3642942},
abstract = {Understanding the link between visual attention and users’ information needs when visually exploring information visualisations is under-explored due to a lack of large and diverse datasets to facilitate these analyses. To fill this gap we introduce SalChartQA – a novel crowd-sourced dataset that uses the BubbleView interface to track user attention and a question-answering (QA) paradigm to induce different information needs in users. SalChartQA contains 74,340 answers to 6,000 questions on 3,000 visualisations. Informed by our analyses demonstrating the close correlation between information needs and visual saliency, we propose the first computational method to predict question-driven saliency on visualisations. Our method outperforms state-of-the-art saliency models for several metrics, such as the correlation coefficient and the Kullback-Leibler divergence. These results show the importance of information needs for shaping attentive behaviour and pave the way for new applications, such as task-driven optimisation of visualisations or explainable AI in chart question-answering.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {763},
numpages = {14},
keywords = {Information visualisation, deep learning, eye-tracking study, gaze bahaviour, visual saliency},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags={Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3641940,
author = {Yoo, MinYoung and Odom, William and Berger, Arne and Barnett, Samuel and Kenny, Sadhbh and Lo, Priscilla and Shamsher, Samein and Russell, Gillian and Knight, Lauren},
title = {Remembering through Sound: Co-creating Sound-based Mementos together with People with Blindness},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641940},
doi = {10.1145/3613904.3641940},
abstract = {Sound is a preferred and dominant medium that people with blindness use to capture, share and reflect on meaningful moments in their lives. Within the timeframe of 12 months, we worked with seven people with blindness and two of their sighted loved ones to engage in a multi-stage co-creative design process involving multiple steps building toward the final co-design workshop. We report three types of sonic mementos, designed together with the participants, that Encapsulate, Augment and Re-imagine personal audio recordings into more interesting and meaningful sonic memories. Building on these sonic mementos, we critically reflect and describe insights into designing sound that supports personal and social experiences of reminiscence for people with blindness through sound. We propose design opportunities to promote collective remembering between people with blindness and their sighted loved ones and design recommendations for remembering through sound.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {886},
numpages = {19},
keywords = {Co-creation, Co-design, People with Blindness, Reminiscence, Research through Design, Sonic memory, Sound},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags={Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642583,
author = {Terzimehi\'{c}, Na\dj{}a and Huber, Julia and Aragon-Hahner, Sarah and Mayer, Sven},
title = {Real-World Winds: Micro Challenges to Promote Balance Post Smartphone Overload},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642583},
doi = {10.1145/3613904.3642583},
abstract = {We present and evaluate the concept of winds – micro challenges to be done in the physical world post-smartphone overload, to encourage exiting the digital smartphone tunnel and promote refreshing breaks from the digital realm. Whereas digital detox solutions are unsustainable in everyday life, current everyday interventions such as screen time reminders or app blockers can induce negative feelings in users. We hypothesize that winds, delivered by our mobile app Real-World Wind (RWW), promote balance between the user’s physical and digital activities, as well as engagement with the intervention. RWW tracks users’ smartphone use behavior and distributes winds of five categories upon overload pattern detection. We evaluated the effectiveness of RWW in a week-long field study with 25 participants. Our findings show that winds foster a fun and engaging experience, and significantly promote balance between the digital and physical world post-smartphone overload. We discuss implications for future technology overload interventions.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {246},
numpages = {16},
keywords = {balance, behavior change, digital wellbeing, intervention, micro breaks, micro challenges, mobile app, smartphone overload},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags={Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642341,
author = {Bu, Fanjun and Li, Stacey and Goedicke, David and Colley, Mark and Sharma, Gyanendra and Ju, Wendy},
title = {Portobello: Extending Driving Simulation from the Lab to the Road},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642341},
doi = {10.1145/3613904.3642341},
abstract = {In automotive user interface design, testing often starts with lab-based driving simulators and migrates toward on-road studies to mitigate risks. Mixed reality (XR) helps translate virtual study designs to the real road to increase ecological validity. However, researchers rarely run the same study in both in-lab and on-road simulators due to the challenges of replicating studies in both physical and virtual worlds. To provide a common infrastructure to port in-lab study designs on-road, we built a platform-portable infrastructure, Portobello, to enable us to run twinned physical-virtual studies. As a proof-of-concept, we extended the on-road simulator XR-OOM with Portobello. We ran a within-subjects, autonomous-vehicle crosswalk cooperation study (N=32) both in-lab and on-road to investigate study design portability and platform-driven influences on study outcomes. To our knowledge, this is the first system that enables the twinning of studies originally designed for in-lab simulators to be carried out in an on-road platform.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {256},
numpages = {13},
keywords = {Driving Simulations, Human-Autonomous Vehicle Interaction},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags={Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642355,
author = {Kaltenhauser, Annika and Stefanidi, Evropi and Sch\"{o}ning, Johannes},
title = {Playing with Perspectives and Unveiling the Autoethnographic Kaleidoscope in HCI – A Literature Review of Autoethnographies},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642355},
doi = {10.1145/3613904.3642355},
abstract = {Autoethnography is a valuable methodological approach bridging the gap between personal experiences and academic inquiry, enabling researchers to gain deep insights into various dimensions of technology use and design. While its adoption in Human-Computer Interaction (HCI) continues to grow, a comprehensive investigation of its function and role within HCI research is still lacking. This paper examines the evolving landscape of autoethnographies within HCI over the past two decades through a systematic literature review. We identify prevalent themes, methodologies, and contributions emerging from autoethnographies by analysing a corpus of 31 HCI publications. Furthermore, we detail data collection techniques and analysis methods and describe reporting standards. Our literature review aims to inform future (HCI) researchers, practitioners, and designers. It encourages them to embrace autoethnography’s rich opportunities by providing examples across domains (e.g., embodiment or health and wellbeing) to advance our understanding of the complex relationships between humans and technology.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {819},
numpages = {20},
keywords = {autoethnography, first-person method, literature review, literature survey, meta review, meta-analysis, qualitative methods},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags={Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642035,
author = {Schmidmaier, Matthias and Rupp, Jonathan and Cvetanova, Darina and Mayer, Sven},
title = {Perceived Empathy of Technology Scale (PETS): Measuring Empathy of Systems Toward the User},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642035},
doi = {10.1145/3613904.3642035},
abstract = {Affective computing improves rapidly, allowing systems to process human emotions. This enables systems such as conversational agents or social robots to show empathy toward users. While there are various established methods to measure the empathy of humans, there is no reliable and validated instrument to quantify the perceived empathy of interactive systems. Thus, we developed the Perceived Empathy of Technology Scale (PETS) to assess and compare how empathic users perceive technology. We followed a standardized multi-phase process of developing and validating scales. In total, we invited 30 experts for item generation, 324 participants for item selection, and 396 additional participants for scale validation. We developed our scale using 22 scenarios with opposing empathy levels, ensuring the scale is universally applicable. This resulted in the PETS, a 10-item, 2-factor scale. The PETS allows designers and researchers to evaluate and compare the perceived empathy of interactive systems rapidly.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {456},
numpages = {18},
keywords = {empathy, human-computer interaction, scale, technology},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags={Full Paper,Honorable Mention,CHI24}
}
@inproceedings{10.1145/3613904.3642083,
author = {Stemasov, Evgeny and Demharter, Simon and R\"{a}dler, Max and Gugenheimer, Jan and Rukzio, Enrico},
title = {pARam: Leveraging Parametric Design in Extended Reality to Support the Personalization of Artifacts for Personal Fabrication},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642083},
doi = {10.1145/3613904.3642083},
abstract = {Extended Reality (XR) allows in-situ previewing of designs to be manufactured through Personal Fabrication (PF). These in-situ interactions exhibit advantages for PF, like incorporating the environment into the design process. However, design-for-fabrication in XR often happens through either highly complex 3D-modeling or is reduced to rudimentary adaptations of crowd-sourced models. We present pARam, a tool combining parametric designs (PDs) and XR, enabling in-situ configuration of artifacts for PF. In contrast to modeling- or search-focused approaches, pARam supports customization through embodied and practical inputs (e.g., gestures, recommendations) and evaluation (e.g., lighting estimation) without demanding complex 3D-modeling skills. We implemented pARam for HoloLens 2 and evaluated it (n = 20), comparing XR and desktop conditions. Users succeeded in choosing context-related parameters and took their environment into account for their configuration using pARam. We reflect on the prospects and challenges of PDs in XR to streamline complex design methods for PF while retaining suitable expressivity.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {337},
numpages = {22},
keywords = {3D-modeling, Customizer Interfaces, Design Customization, In-Situ Design, In-Situ Modeling, Mixed Reality, Parametric Designs, Personal Fabrication, Remixing, pARam},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags={Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642851,
author = {Grimme, Sophie and Spoerl, Susanna Marie and Boll, Susanne and Koelle, Marion},
title = {My Data, My Choice, My Insights: Women's Requirements when Collecting, Interpreting and Sharing their Personal Health Data},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642851},
doi = {10.1145/3613904.3642851},
abstract = {HCI research has been instrumental in enabling self-directed health tracking. Despite a plethora of devices and data, however, users’ views of their own health are often fragmented. This is a problem for women’s health, where physical and mental observations and symptoms are strongly intertwined. An integrated view throughout different life stages could help to better understand these connections, facilitate symptom alleviation through life-style changes, and support timely diagnosis: currently, women’s health issues often go under-researched and under-diagnosed. To capture the needs and worries of self-directed tracking, interpreting and sharing women’s health data, we held workshops with 28 women. Drawing upon feminist methods, we conducted a Reflexive Thematic Analysis to identify six central themes that ground opportunities and challenges for life-long, self-directed tracking of intimate data. These themes inform the design of tools for data collection, analysis and sharing that empower women to better understand their bodies and demand adequate health services.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {688},
numpages = {18},
keywords = {Feminist HCI, Lifelong Health, Requirements, Women’s Health},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags={Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642031,
author = {Dey, Debargha and Senan, Toros Ufuk and Hengeveld, Bart and Colley, Mark and Habibovic, Azra and Ju, Wendy},
title = {Multi-Modal eHMIs: The Relative Impact of Light and Sound in AV-Pedestrian Interaction},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642031},
doi = {10.1145/3613904.3642031},
abstract = {External Human-Machine Interfaces (eHMIs) have been evaluated to facilitate interactions between Automated Vehicles (AVs) and pedestrians. Most eHMIs are, however, visual/ light-based solutions, and multi-modal eHMIs have received little attention to date. We ran an experimental video study (<Formula format="inline"><TexMath><?TeX $N~=~29$?></TexMath><AltText>Math 1</AltText><File name="chi24-142-inline1" type="svg"/></Formula>) to systematically understand the effect on pedestrian’s willingness to cross the road and user preferences of a light-based eHMI (light bar on the bumper) and two sound-based eHMIs (bell sound and droning sound), and combinations thereof. We found no objective change in pedestrians’ willingness to cross the road based on the nature of eHMI, although people expressed different subjective preferences for the different ways an eHMI may communicate, and sometimes even strong dislike for multi-modal eHMIs. This shows that the modality of the evaluated eHMI concepts had relatively little impact on their effectiveness. Consequently, this lays an important groundwork for accessibility considerations of future eHMIs, and points towards the insight that provisions can be made for taking user preferences into account without compromising effectiveness.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {91},
numpages = {16},
keywords = {Automated vehicle, VRU, eHMI, multimodal interface, pedestrian, vehicle-pedestrian interaction, vulnerable road user},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags={Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642141,
author = {Zhang, Guanhua and Hu, Zhiming and B\^{a}ce, Mihai and Bulling, Andreas},
title = {Mouse2Vec: Learning Reusable Semantic Representations of Mouse Behaviour},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642141},
doi = {10.1145/3613904.3642141},
abstract = {The mouse is a pervasive input device used for a wide range of interactive applications. However, computational modelling of mouse behaviour typically requires time-consuming design and extraction of handcrafted features, or approaches that are application-specific. We instead propose Mouse2Vec &nbsp;– a novel self-supervised method designed to learn semantic representations of mouse behaviour that are reusable across users and applications. Mouse2Vec uses a Transformer-based encoder-decoder architecture, which is specifically geared for mouse data: During pretraining, the encoder learns an embedding of input mouse trajectories while the decoder reconstructs the input and simultaneously detects mouse click events. We show that the representations learned by our method can identify interpretable mouse behaviour clusters and retrieve similar mouse trajectories. We also demonstrate on three sample downstream tasks that the representations can be practically used to augment mouse data for training supervised methods and serve as an effective feature extractor.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {621},
numpages = {17},
keywords = {Behaviour retrieval, Data augmentation, Mouse input, Representation learning, Self-supervised learning, Transformer},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags={Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642499,
author = {Ding, Yuran and Sabnis, Nihar and Strohmeier, Paul},
title = {Motionless Movement: Towards Vibrotactile Kinesthetic Displays},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642499},
doi = {10.1145/3613904.3642499},
abstract = {Beyond visual and auditory displays, tactile displays and grounded force feedback devices have become more common. Other sensory modalities are also catered to by a broad range of display devices, including temperature, taste, and olfaction. However, one sensory modality remains challenging to represent: kinesthesia – the sense of movement. Inspired by grain-based compliance illusions, we investigate how vibrotactile cues can evoke kinesthetic experiences, even when no movement is performed. We examine the effects of vibrotactile mappings and granularity on the magnitude of perceived motion; distance-based mappings provided the greatest sense of movement. Using an implementation that combines visual feedback and our prototype kinesthetic display, we demonstrate that action-coupled vibrotactile cues are significantly better at conveying an embodied sense of movement than the corresponding visual stimulus, and that combining vibrotactile and visual feedback is best. These results point towards a future where kinesthetic displays will be used in rehabilitation, sports, virtual-reality and beyond.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {418},
numpages = {16},
keywords = {embodiment, haptic illusion, haptic rendering, human augmentation, kinesthesia, kinesthetic display, movement display, movement illusion, tactile feedback},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags={Full Paper,Honorable Mention,CHI24}
}
@inproceedings{10.1145/3613905.3650853,
author = {Attig, Christiane and Wollstadt, Patricia and Schrills, Tim and Franke, Thomas and Wiebel-Herboth, Christiane B.},
title = {More than Task Performance: Developing New Criteria for Successful Human-AI Teaming Using the Cooperative Card Game Hanabi},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650853},
doi = {10.1145/3613905.3650853},
abstract = {As we shift to designing AI agents as teammates rather than tools, the social aspects of human-AI interaction become more pronounced. Consequently, to develop agents that are able to navigate the social dynamics that accompany cooperative teamwork, evaluation criteria that refer only to objective task performance will not be sufficient. We propose perceived cooperativity and teaming perception as subjective metrics for investigating successful human-AI teaming. Corresponding questionnaire scales were developed and tested in a pilot study employing the collaborative card game Hanabi, which has been identified as a unique setting for investigating human-AI teaming. Preliminary descriptive results suggest that rule-based and reinforcement learning-based agents differ in terms of perceived cooperativity and teaming perception. Future work will extend the results in a large user study to psychometrically evaluate the scales and test a conceptual framework that includes further aspects related to social dynamics in human-AI teaming.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {245},
numpages = {11},
keywords = {Human-AI teaming, collaboration, cooperation, human-autonomy teaming, social perception},
location = {Honolulu, HI, USA},
series = {CHI EA '24},
tags={Late Breaking Work,CHI24}
}
@inproceedings{10.1145/3613905.3636310,
author = {Gray, Colin M. and Gunawan, Johanna T. and Sch\"{a}fer, Ren\'{e} and Bielova, Nataliia and Sanchez Chamorro, Lorena and Seaborn, Katie and Mildner, Thomas and Sandhaus, Hauke},
title = {Mobilizing Research and Regulatory Action on Dark Patterns and Deceptive Design Practices},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3636310},
doi = {10.1145/3613905.3636310},
abstract = {Deceptive, manipulative, and coercive practices are deeply embedded in our digital experiences, impacting our ability to make informed choices and undermining our agency and autonomy. These design practices—collectively known as “dark patterns” or “deceptive patterns”—are increasingly under legal scrutiny and sanctions, largely due to the efforts of human-computer interaction scholars that have conducted pioneering research relating to dark patterns types, definitions, and harms. In this workshop, we continue building this scholarly community with a focus on organizing for action. Our aims include: (i) building capacity around specific research questions relating to methodologies for detection; (ii) characterization of harms; and (iii) creating effective countermeasures. Through the outcomes of the workshop, we will connect our scholarship to the legal, design, and regulatory communities to inform further legislative and legal action.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {482},
numpages = {6},
keywords = {dark patterns, deceptive design, ethics, manipulative user interfaces, regulation},
location = {Honolulu, HI, USA},
series = {CHI EA '24},
tags = {Workshop,CHI24}
}
@inproceedings{10.1145/3613905.3650745,
author = {Nowak, Oliver and Becker, Lennart and Pettirsch, Sebastian Valentin and Borchers, Jan},
title = {Mappings in the Home: Selecting Home Appliances in 3D Space},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650745},
doi = {10.1145/3613905.3650745},
abstract = {Unlike voice assistants, remotes, and smartphones, UIs embedded into furniture and other surfaces offer silent, discreet, and unobtrusive control of smart home appliances. However, as the number of appliances grows, fitting individual controls for each onto the surfaces in our environment becomes impractical, making it necessary to select appliances before controlling them. These appliances are placed in 3D at various heights around the room, while traditional controls are laid out in 2D, complicating control-to-target mapping. We compared six UIs using mappings with spatial analogies that are either absolute or relative to the user’s position and perspective. Participants used each to select 20 targets in a simplified living room, once while looking and once eyes-free. We investigated performance and participants’ ratings for, inter alia, ease of use, mapping comprehensibility, and mental demand. Map-based controllers were most promising, but participants also ranked perspective projection with touch input highly.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {237},
numpages = {7},
keywords = {haptic, natural mappings, smart home, target selection},
location = {Honolulu, HI, USA},
series = {CHI EA '24},
tags = {Late Breaking Work,CHI24}
}
@inproceedings{10.1145/3613905.3650982,
author = {Liebers, Carina and Pf\"{u}tzenreuter, Niklas and Prochazka, Marvin and Megarajan, Pranav and Furuno, Eike and L\"{o}ber, Jan and Stratmann, Tim C. and Auda, Jonas and Degraen, Donald and Gruenefeld, Uwe and Schneegass, Stefan},
title = {Look Over Here! Comparing Interaction Methods for User-Assisted Remote Scene Reconstruction},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650982},
doi = {10.1145/3613905.3650982},
abstract = {Detailed digital representations of physical scenes are key in many cases, such as historical site preservation or hazardous area inspection. To automate the capturing process, robots or drones mounted with sensors can algorithmically record the environment from different viewpoints. However, environmental complexities often lead to incomplete captures. We believe humans can support scene capture as their contextual understanding enables easy identification of missing areas and recording errors. Therefore, they need to perceive the recordings and suggest new sensor poses. In this work, we compare two human-centric approaches in Virtual Reality for scene reconstruction through the teleoperation of a remote robot arm, i.e., directly providing sensor poses (direct method) or specifying missing areas in the scans (indirect method). Our results show that directly providing sensor poses leads to higher efficiency and user experience. In future work, we aim to compare the quality of human assistance to automatic approaches.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {229},
numpages = {8},
keywords = {RGBD sampling, human-robot interaction, manual sampling, teleoperation, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI EA '24},
tags = {Late Breaking Work,CHI24}
}
@inproceedings{10.1145/3613904.3642542,
author = {Mildner, Thomas and Cooney, Orla and Meck, Anna-Maria and Bartl, Marion and Savino, Gian-Luca and Doyle, Philip R and Garaialde, Diego and Clark, Leigh and Sloan, John and Wenig, Nina and Malaka, Rainer and Niess, Jasmin},
title = {Listening to the Voices: Describing Ethical Caveats of Conversational User Interfaces According to Experts and Frequent Users},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642542},
doi = {10.1145/3613904.3642542},
abstract = {Advances in natural language processing and understanding have led to a rapid growth in the popularity of conversational user interfaces (CUIs). While CUIs introduce novel benefits, they also yield risks that may exploit people’s trust. Although research looking at unethical design deployed through graphical user interfaces (GUIs) established a thorough understanding of so-called dark patterns, there is a need to continue this discourse within the CUI community to understand potentially problematic interactions. Addressing this gap, we interviewed 27 participants from three cohorts: researchers, practitioners, and frequent users of CUIs. Applying thematic analysis, we construct five themes reflecting each cohort’s insights about ethical design challenges and introduce the CUI Expectation Cycle, bridging system capabilities and user expectations while considering each theme’s ethical caveats. This research aims to inform future development of CUIs to consider ethical constraints while adopting a human-centred approach.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {307},
numpages = {18},
keywords = {CUI, chatbots, conversational agents, conversational user interfaces, dark patterns, deceptive design patterns, ethical design, thematic analysis, voice agents},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642421,
author = {Albers, Ruben and Hassenzahl, Marc},
title = {Let’s Talk About Death: Existential Conversations with Chatbots},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642421},
doi = {10.1145/3613904.3642421},
abstract = {Many people prefer not to think about their own death, let alone talk about it. This contributes to fear of death and reduces the acceptance of its inevitability. We hypothesized that talking about one’s own death with a specially designed chatbot reduces fear of death and strengthens the confidence to discuss the topic further with loved ones. Participants (N=100) talked with the chatbot for an average of 25 minutes. It offered conversations about planning for one’s own death, end-of-life preferences, and hopes for the afterlife. We measured participants’ fear and acceptance of death (DAP-R questionnaire) and readiness for end-of-life conversation (REOLC questionnaire) before and after the chat. Overall, attitudes toward death improved and fear decreased, while readiness for end-of-life conversations increased. Bigger changes in attitude corresponded with longer, more reflective responses in the conversations, commitment to plans, finding meaning in death, and some notion of legacy or afterlife.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {529},
numpages = {14},
keywords = {conversational agent, death, dying, end of life, thanato-technology},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613905.3636291,
author = {Matviienko, Andrii and Boot, Mario and L\"{o}cken, Andreas and Pfleging, Bastian and L\"{o}chtefeld, Markus and Von Sawitzky, Tamara and Savino, Gian-Luca and Sturdee, Miriam and Andres, Josh and Boyer, Kristy Elizabeth and Brewster, Stephen Anthony and Mueller, Florian ‘Floyd’},
title = {Learning from Cycling: Discovering Lessons Learned from CyclingHCI},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3636291},
doi = {10.1145/3613905.3636291},
abstract = {Cycling plays an essential role in sustainable mobility, health, and socializing. This workshop aims to collect and discuss the lessons learned from Cycling Human-Computer Interaction (CyclingHCI). For this, we will gather researchers and experts in the field to discuss what we learned from designing, building, and evaluating CyclingHCI systems. We will start the workshop with three lessons learned from CyclingHCI defined by the organizers and their experience in the field, which include (1) a lack of theories, tools, and perspectives, (2) knowledge about designing for safety and inclusive cycling, and (3) evaluation methods and environments. Taken together, with this work, we aim to promote interactive technology to get more people cycling, profiting from the many associated benefits.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {480},
numpages = {5},
keywords = {bicycles, cycling, lessons learned, urban interaction},
location = {Honolulu, HI, USA},
series = {CHI EA '24},
tags = {Workshop,CHI24}
}
@inproceedings{10.1145/3613905.3648107,
author = {Karaosmanoglu, Sukran and Fittschen, Elisabeth L and Eyicalis, Hande and Kraus, David and Nickelmann, Henrik and Tomko, Anna and Steinicke, Frank},
title = {Language of Zelda: Facilitating Language Learning Practices Using ChatGPT},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3648107},
doi = {10.1145/3613905.3648107},
abstract = {The Language of Zelda is an educational game that re-imagines “The Legend of Zelda: A Link to the Past” for French language learning. With the integration of ChatGPT for non-player characters (NPCs), the game allows players to interact with NPCs to practice French through gameplay, puzzles, and quests. Our approach bridges the gap between declarative and procedural language knowledge, offering an engaging, immersive learning experience. The game’s adaptive dialogues cater to various proficiency levels, enhancing both education and entertainment values. Our work illustrates the potential of combining AI with game-based learning to create effective, enjoyable language education tools.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {635},
numpages = {5},
keywords = {chatGPT, games, language, learning, natural langugage processing},
location = {Honolulu, HI, USA},
series = {CHI EA '24},
tags = {Student Game Competition,CHI24}
}
@inproceedings{10.1145/3613904.3642279,
author = {Guntrum, Laura Gianna},
title = {Keyboard Fighters: The Use of ICTs by Activists in Times of Military Coup in Myanmar},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642279},
doi = {10.1145/3613904.3642279},
abstract = {Amidst the ongoing anti-military protests in Myanmar since 2021, there is a noticeable research gap on ICT-supported activism. Generally, ICTs play an important role during political crises in conjunction with activists’ practices on the ground. Inspired by Resource Mobilization Theory, I conducted qualitative interviews (N=16) and a qualitative online survey (N=34), which demonstrate the intersection between analog and digital domains, showcasing the ingenuity of the activists, and the rapid adoption of ICTs in a country that has experienced a digital revolution within the last few years. As not all people were able to protest on-the-ground, they acted as keyboard fighters to organize protests, to share information, and to support the civil disobedience movement in Myanmar. The study identifies, inter alia, the need for better offline applications with wider coverage in times of internet shutdowns, applications that cannot be easily identified during physical controls, and providing free and secure VPN access.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {880},
numpages = {19},
keywords = {ICT-enabled activism, Myanmar coup, digital rights, internet shutdown, protest participation, social media, social movement},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642864,
author = {Rasch, Julian and Perzl, Florian and Weiss, Yannick and M\"{u}ller, Florian},
title = {Just Undo It: Exploring Undo Mechanics in Multi-User Virtual Reality},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642864},
doi = {10.1145/3613904.3642864},
abstract = {With the proliferation of VR and a metaverse on the horizon, many multi-user activities are migrating to the VR world, calling for effective collaboration support. As one key feature, traditional collaborative systems provide users with undo mechanics to reverse errors and other unwanted changes. While undo has been extensively researched in this domain and is now considered industry standard, it is strikingly absent for VR systems in research and industry. This work addresses this research gap by exploring different undo techniques for basic object manipulation in different collaboration modes in VR. We conducted a study involving 32 participants organized in teams of two. Here, we studied users’ performance and preferences in a tower stacking task, varying the available undo techniques and their mode of collaboration. The results suggest that users desire and use undo in VR and that the choice of the undo technique impacts users’ performance and social connection.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {952},
numpages = {14},
keywords = {CSCW, Connectedness, Multi-User, SocialVR, Undo, Virtual Reality},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642365,
author = {Colley, Mark and Rajabi, Omid and Rukzio, Enrico},
title = {Investigating the Effects of External Communication and Platoon Behavior on Manual Drivers at Highway Access},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642365},
doi = {10.1145/3613904.3642365},
abstract = {Automated vehicles are expected to improve traffic safety and efficiency. One approach to achieve this is via platooning, that is, (automated) vehicles can drive behind each other at very close proximity to reduce air resistance. However, this behavior could lead to difficulties in mixed traffic, for example, when manual drivers try to enter a highway. Therefore, we report the results of a within-subject Virtual Reality study (N=29) evaluating different platoon behaviors (single vs. multiple, i.e., four, gaps) and communication strategies (HUD, AR, attached displays). Results show that AR communication reduced mental workload, improved perceived safety, and a single big gap led to the safest merging behavior. Our work helps to incorporate novel behavior enabled by automation into general traffic better.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {260},
numpages = {15},
keywords = {Automated vehicles, Virtual Reality., external communication, self-driving vehicles},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613905.3651009,
author = {Reiter, Thomas and Sakel, Sophia and Scharbert, Julian and Ter Horst, Julian and Back, Mitja and Van Zalk, Maarten and B\"{u}hner, Markus and Schoedel, Ramona},
title = {Investigating Phubbing in Everyday Life: Challenges \& Lessons for Future Research},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3651009},
doi = {10.1145/3613905.3651009},
abstract = {The ubiquitous presence of smartphones has made them an integral part of our social lives. A well-known example of this phenomenon is phubbing, where smartphone use distracts people from their daily interpersonal interactions. While previous research has mostly relied on often biased global self-reports, our work introduces a novel approach to assessing phubbing in real life. To this end, we conducted an empirical study that integrated experience sampling and mobile sensing methods to obtain a more objective measure of phubbing behavior. Based on the evaluation of our concept, we contribute insights on reliable phubbing assessment in real life and the design of phubbing-aware technologies based on it. By highlighting the challenges associated with existing methods, we aim to stimulate discussion in the field of HCI and encourage the development of socially friendly technologies that benefit real-life interpersonal interactions.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {207},
numpages = {8},
keywords = {Experience Sampling, Mobile Sensing, Phubbing, Smartphone Usage, Technoference},
location = {Honolulu, HI, USA},
series = {CHI EA '24},
tags = {Late Breaking Work,CHI24}
}
@inproceedings{10.1145/3613904.3642091,
author = {Sehrt, Jessica and Ferreira, Leonardo Leite and Weyers, Karsten and Mahmood, Amir and Kosch, Thomas and Schwind, Valentin},
title = {Improving Electromyographic Muscle Response Times through Visual and Tactile Prior Stimulation in Virtual Reality},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642091},
doi = {10.1145/3613904.3642091},
abstract = {Electromyography (EMG) enables hands-free interactions by detecting muscle activity at different human body locations. Previous studies have demonstrated that input performance based on isometric contractions is muscle-dependent and can benefit from synchronous biofeedback. However, it remains unknown whether stimulation before interaction can help to localize and tense a muscle faster. In a response-based VR experiment (N=21), we investigated whether prior stimulation using visual or tactile cues at four different target muscles (biceps, triceps, upper leg, calf) can help reduce the time to perform isometric muscle contractions. The results show that prior stimulation decreases EMG reaction times with visual, vibrotactile, and electrotactile cues. Our experiment also revealed important findings regarding learning and fatigue at the different body locations. We provide qualitative insights into the participants’ perceptions and discuss potential reasons for the improved interaction. We contribute with implications and use cases for prior stimulated muscle activation.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {637},
numpages = {17},
keywords = {Assistive Systems, Electrical Muscle Stimulation, Electromyography, Physiological Sensing, Virtual Reality},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642091,
author = {Sehrt, Jessica and Ferreira, Leonardo Leite and Weyers, Karsten and Mahmood, Amir and Kosch, Thomas and Schwind, Valentin},
title = {Improving Electromyographic Muscle Response Times through Visual and Tactile Prior Stimulation in Virtual Reality},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642091},
doi = {10.1145/3613904.3642091},
abstract = {Electromyography (EMG) enables hands-free interactions by detecting muscle activity at different human body locations. Previous studies have demonstrated that input performance based on isometric contractions is muscle-dependent and can benefit from synchronous biofeedback. However, it remains unknown whether stimulation before interaction can help to localize and tense a muscle faster. In a response-based VR experiment (N=21), we investigated whether prior stimulation using visual or tactile cues at four different target muscles (biceps, triceps, upper leg, calf) can help reduce the time to perform isometric muscle contractions. The results show that prior stimulation decreases EMG reaction times with visual, vibrotactile, and electrotactile cues. Our experiment also revealed important findings regarding learning and fatigue at the different body locations. We provide qualitative insights into the participants’ perceptions and discuss potential reasons for the improved interaction. We contribute with implications and use cases for prior stimulated muscle activation.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {637},
numpages = {17},
keywords = {Assistive Systems, Electrical Muscle Stimulation, Electromyography, Physiological Sensing, Virtual Reality},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Workshop,CHI24}
}
@inproceedings{10.1145/3613904.3642091,
author = {Sehrt, Jessica and Ferreira, Leonardo Leite and Weyers, Karsten and Mahmood, Amir and Kosch, Thomas and Schwind, Valentin},
title = {Improving Electromyographic Muscle Response Times through Visual and Tactile Prior Stimulation in Virtual Reality},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642091},
doi = {10.1145/3613904.3642091},
abstract = {Electromyography (EMG) enables hands-free interactions by detecting muscle activity at different human body locations. Previous studies have demonstrated that input performance based on isometric contractions is muscle-dependent and can benefit from synchronous biofeedback. However, it remains unknown whether stimulation before interaction can help to localize and tense a muscle faster. In a response-based VR experiment (N=21), we investigated whether prior stimulation using visual or tactile cues at four different target muscles (biceps, triceps, upper leg, calf) can help reduce the time to perform isometric muscle contractions. The results show that prior stimulation decreases EMG reaction times with visual, vibrotactile, and electrotactile cues. Our experiment also revealed important findings regarding learning and fatigue at the different body locations. We provide qualitative insights into the participants’ perceptions and discuss potential reasons for the improved interaction. We contribute with implications and use cases for prior stimulated muscle activation.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {637},
numpages = {17},
keywords = {Assistive Systems, Electrical Muscle Stimulation, Electromyography, Physiological Sensing, Virtual Reality},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Late Breaking Work,CHI24}
}
@inproceedings{10.1145/3613904.3642428,
author = {Leiser, Florian and Eckhardt, Sven and Leuthe, Valentin and Knaeble, Merlin and M\"{a}dche, Alexander and Schwabe, Gerhard and Sunyaev, Ali},
title = {HILL: A Hallucination Identifier for Large Language Models},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642428},
doi = {10.1145/3613904.3642428},
abstract = {Large language models (LLMs) are prone to hallucinations, i.e., nonsensical, unfaithful, and undesirable text. Users tend to overrely on LLMs and corresponding hallucinations which can lead to misinterpretations and errors. To tackle the problem of overreliance, we propose HILL, the "Hallucination Identifier for Large Language Models". First, we identified design features for HILL with a Wizard of Oz approach with nine participants. Subsequently, we implemented HILL based on the identified design features and evaluated HILL’s interface design by surveying 17 participants. Further, we investigated HILL’s functionality to identify hallucinations based on an existing question-answering dataset and five user interviews. We find that HILL can correctly identify and highlight hallucinations in LLM responses which enables users to handle LLM responses with more caution. With that, we propose an easy-to-implement adaptation to existing LLMs and demonstrate the relevance of user-centered designs of AI artifacts.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {482},
numpages = {13},
keywords = {Artifact Development, Artificial Hallucinations, ChatGPT, Large Language Models, Wizard of Oz},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642050,
author = {Elvitigala, Don Samitha and Karahano\u{g}lu, Arma\u{g}an and Matviienko, Andrii and Turmo Vidal, Laia and Postma, Dees and Jones, Michael D and Montoya, Maria F. and Harrison, Daniel and Elb\ae{}k, Lars and Daiber, Florian and Burr, Lisa Anneke and Patibanda, Rakesh and Buono, Paolo and H\"{a}m\"{a}l\"{a}inen, Perttu and Van Delden, Robby and Bernhaupt, Regina and Ren, Xipei and Van Rheden, Vincent and Zambetta, Fabio and Van Den Hoven, Elise and Lallemand, Carine and Reidsma, Dennis and Mueller, Florian ‘Floyd’},
title = {Grand Challenges in SportsHCI},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642050},
doi = {10.1145/3613904.3642050},
abstract = {The field of Sports Human-Computer Interaction (SportsHCI) investigates interaction design to support a physically active human being. Despite growing interest and dissemination of SportsHCI literature over the past years, many publications still focus on solving specific problems in a given sport. We believe in the benefit of generating fundamental knowledge for SportsHCI more broadly to advance the field as a whole. To achieve this, we aim to identify the grand challenges in SportsHCI, which can help researchers and practitioners in developing a future research agenda. Hence, this paper presents a set of grand challenges identified in a five-day workshop with 22 experts who have previously researched, designed, and deployed SportsHCI systems. Addressing these challenges will drive transformative advancements in SportsHCI, fostering better athlete performance, athlete-coach relationships, spectator engagement, but also immersive experiences for recreational sports or exercise motivation, and ultimately, improve human well-being.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {312},
numpages = {20},
keywords = {Physical Activity, Sports technology, grand challenges},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642038,
author = {van Rijn, Pol and Mertes, Silvan and Janowski, Kathrin and Weitz, Katharina and Jacoby, Nori and Andr\'{e}, Elisabeth},
title = {Giving Robots a Voice: Human-in-the-Loop Voice Creation and open-ended Labeling},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642038},
doi = {10.1145/3613904.3642038},
abstract = {Speech is a natural interface for humans to interact with robots. Yet, aligning a robot’s voice to its appearance is challenging due to the rich vocabulary of both modalities. Previous research has explored a few labels to describe robots and tested them on a limited number of robots and existing voices. Here, we develop a robot-voice creation tool followed by large-scale behavioral human experiments (N=2,505). First, participants collectively tune robotic voices to match 175 robot images using an adaptive human-in-the-loop pipeline. Then, participants describe their impression of the robot or their matched voice using another human-in-the-loop paradigm for open-ended labeling. The elicited taxonomy is then used to rate robot attributes and to predict the best voice for an unseen robot. We offer a web interface to aid engineers in customizing robot voices, demonstrating the synergy between cognitive science and machine learning for engineering tools.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {584},
numpages = {34},
keywords = {Crowdsourcing, Personalization, Robot, Text/Speech/Language},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613905.3650736,
author = {Allgaier, Mareen and Huettl, Florentine and Hanke, Laura Isabel and Huber, Tobias and Preim, Bernhard and Saalfeld, Sylvia and Hansen, Christian},
title = {Gamification Concepts for a VR-based Visuospatial Training for Intraoperative Liver Ultrasound},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650736},
doi = {10.1145/3613905.3650736},
abstract = {Gamification is widely used due to its positive influence on learning by adding emotions and steering behavior. In medical VR training applications, the use of gamification is rare, and when it is implemented, it often lacks thoughtful design decisions and empirical evaluation. Using a VR-based training for intraoperative ultrasound for liver surgery, we analyzed game elements regarding their suitability and examined two in more detail: difficulty levels and a kit, where the user has to assemble a virtual liver using US. In a broad audience study, levels achieved significantly better results regarding enjoyment. Qualitative feedback from medical students directly comparing the elements revealed that they prefer the kit as well as levels for training. Our studies indicate that levels and the more interactive kit improve the learning experience, which could also be taken as a basis for similar VR-based medical training applications.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {175},
numpages = {8},
keywords = {Game Elements, Gamification, Medical Training, Ultrasound, Virtual Reality, Visuospatial Skills},
location = {Honolulu, HI, USA},
series = {CHI EA '24},
tags = {Late Breaking Work,CHI24}
}
@inproceedings{10.1145/3613904.3642844,
author = {Pointecker, Fabian and Friedl-Knirsch, Judith and Jetter, Hans-Christian and Anthes, Christoph},
title = {From Real to Virtual: Exploring Replica-Enhanced Environment Transitions along the Reality-Virtuality Continuum},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642844},
doi = {10.1145/3613904.3642844},
abstract = {Recent Head-Mounted Displays enable users to perceive the real environment using a video-based see-through mode and the fully virtual environment within a single display. Leveraging these advancements, we present a generic concept to seamlessly transition between the real and virtual environment, with the goal of supporting users in engaging with and disengaging from any real environment into Virtual Reality. This transition process uses a digital replica of the real environment and incorporates various stages of Milgram’s Reality-Virtuality Continuum, along with visual transitions that facilitate gradual navigation between them. We implemented the overall transition concept and four object-based transition techniques. The overall transition concept and four techniques were evaluated in a qualitative user study, focusing on user experience, the use of the replica and visual coherence. The results of the user study show, that most participants stated that the replica facilitates the cognitive processing of the transition and supports spatial orientation.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {799},
numpages = {13},
keywords = {Augmented Reality, Augmented Virtuality, Cross-Reality, Replica, Transitions, User Study, Virtual Reality, Visual Coherence},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642264,
author = {Hartwig, Katrin and Biselli, Tom and Schneider, Franziska and Reuter, Christian},
title = {From Adolescents' Eyes: Assessing an Indicator-Based Intervention to Combat Misinformation on TikTok},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642264},
doi = {10.1145/3613904.3642264},
abstract = {Misinformation poses a recurrent challenge for video-sharing platforms (VSPs) like TikTok. Obtaining user perspectives on digital interventions addressing the need for transparency (e.g., through indicators) is essential. This article offers a thorough examination of the comprehensibility, usefulness, and limitations of an indicator-based intervention from an adolescents’ perspective. This study (N = 39; aged 13-16 years) comprised two qualitative steps: (1) focus group discussions and (2) think-aloud sessions, where participants engaged with a smartphone-app for TikTok. The results offer new insights into how video-based indicators can assist adolescents’ assessments. The intervention received positive feedback, especially for its transparency, and could be applicable to new content. This paper sheds light on how adolescents are expected to be experts while also being prone to video-based misinformation, with limited understanding of an intervention’s limitations. By adopting teenagers’ perspectives, we contribute to HCI research and provide new insights into the chances and limitations of interventions for VSPs.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {905},
numpages = {20},
keywords = {adolescents, disinformation, fake news, misinformation, social media, teenagers, user intervention, video-sharing platforms},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642848,
author = {Haynes, Alice C and Steimle, J\"{u}rgen},
title = {Flextiles: Designing Customisable Shape-Change in Textiles with SMA-Actuated Smocking Patterns},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642848},
doi = {10.1145/3613904.3642848},
abstract = {Shape Memory Alloys (SMAs) afford the seamless integration of shape-changing behaviour into textiles, enabling designers to augment apparel with dynamic shaping and styling. However, existing works fall short of providing versatile methods adaptable to varying scales, materials, and applications, curtailing designers’ capacity to prototype customised solutions. To address this, we introduce Flextiles, parameterised SMA design schema that leverage the traditional craft of smocking to integrate planar shape-change seamlessly into diverse textile projects. The conception of Flextiles stems from material experimentation and consultative dialogues with designers, whose insights inspired strategies for customising scale, elasticity, geometry, and actuation of Flextiles. To support the practical implementation of Flextiles, we provide a design tool and experimentally characterise their material properties. Lastly, through a workshop with practitioners, we explore the multifaceted applications and perspectives surrounding Flextiles, and subsequently realise four scenarios that illustrate the creative potential of these modular, customisable patterns.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {517},
numpages = {17},
keywords = {Actuated Textiles, Fabrication, Shape Memory Alloys},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642848,
author = {Haynes, Alice C and Steimle, J\"{u}rgen},
title = {Flextiles: Designing Customisable Shape-Change in Textiles with SMA-Actuated Smocking Patterns},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642848},
doi = {10.1145/3613904.3642848},
abstract = {Shape Memory Alloys (SMAs) afford the seamless integration of shape-changing behaviour into textiles, enabling designers to augment apparel with dynamic shaping and styling. However, existing works fall short of providing versatile methods adaptable to varying scales, materials, and applications, curtailing designers’ capacity to prototype customised solutions. To address this, we introduce Flextiles, parameterised SMA design schema that leverage the traditional craft of smocking to integrate planar shape-change seamlessly into diverse textile projects. The conception of Flextiles stems from material experimentation and consultative dialogues with designers, whose insights inspired strategies for customising scale, elasticity, geometry, and actuation of Flextiles. To support the practical implementation of Flextiles, we provide a design tool and experimentally characterise their material properties. Lastly, through a workshop with practitioners, we explore the multifaceted applications and perspectives surrounding Flextiles, and subsequently realise four scenarios that illustrate the creative potential of these modular, customisable patterns.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {517},
numpages = {17},
keywords = {Actuated Textiles, Fabrication, Shape Memory Alloys},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642661,
author = {Sch\"{a}fer, Ren\'{e} and Preuschoff, Paul Miles and R\"{o}pke, Ren\'{e} and Sahabi, Sarah and Borchers, Jan},
title = {Fighting Malicious Designs: Towards Visual Countermeasures Against Dark Patterns},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642661},
doi = {10.1145/3613904.3642661},
abstract = {Dark patterns are malicious UI design strategies that nudge users towards decisions going against their best interests. To create technical countermeasures against them, dark patterns must be automatically detectable. While researchers have devised algorithms to detect some patterns automatically, there has only been little work to use obtained results to technically counter the effects of dark patterns when users face them on their devices. To address this, we tested three visual countermeasures against 13 common dark patterns in an interactive lab study. The countermeasures we tested either (a) highlighted and explained the manipulation, (b) hid it from the user, or (c) let the user switch between the original view and the hidden version. From our data, we were able to extract multiple clusters of dark patterns where participants preferred specific countermeasures for similar reasons. To support creating effective countermeasures, we discuss our findings with a recent ontology of dark patterns.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {296},
numpages = {13},
keywords = {dark patterns, deceptive design, lab study, visual countermeasures},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags ={Full Paper,CHI24}
}
@inproceedings{10.1145/3613905.3651044,
author = {Bu, Fanjun and Bremers, Alexandra W.D. and Colley, Mark and Ju, Wendy},
title = {Field Notes on Deploying Research Robots in Public Spaces},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3651044},
doi = {10.1145/3613905.3651044},
abstract = {Human-robot interaction requires to be studied in the wild. In the summers of 2022 and 2023, we deployed two trash barrel service robots through the wizard-of-oz protocol in public spaces to study human-robot interactions in urban settings. We deployed the robots at two different public plazas in downtown Manhattan and Brooklyn for a collective of 20 hours of field time. To date, relatively few long-term human-robot interaction studies have been conducted in shared public spaces. To support researchers aiming to fill this gap, we would like to share some of our insights and learned lessons that would benefit both researchers and practitioners on how to deploy robots in public spaces. We share best practices and lessons learned with the HRI research community to encourage more in-the-wild research of robots in public spaces and call for the community to share their lessons learned to a GitHub repository.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {162},
numpages = {6},
keywords = {HRI, behavioral elicitation, field experiment, social robots, urban spaces, wizard-of-oz},
location = {Honolulu, HI, USA},
series = {CHI EA '24},
tags = {Late Breaking Work,CHI24}
}
@inproceedings{10.1145/3613904.3642786,
author = {Kordyaka, Bastian and Laato, Samuli and Weber, Sebastian and Hamari, Juho and Niehaves, Bjoern},
title = {Exploring the association between engagement with location-based game features and getting inspired about environmental issues and nature},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642786},
doi = {10.1145/3613904.3642786},
abstract = {Today, millions worldwide play popular location-based games (LBGs) such as Pok\'{e}mon GO. LBGs are designed to be played outdoors, and past research has shown that they can incentivize players to travel to nature. To further explore this nature-connection, we investigated via a mixed-methods approach the connections between engagement with LBGs, inspiration and environmental awareness as follows. First, we identified relevant gamification features in Study 1. Based on the insights, we built a survey that we sent to Pok\'{e}mon GO players (N=311) in Study 2. The results showed that (a) social networking features, reminders, and virtual objects were the most relevant gamification features to explain inspired by playing Pok\'{e}mon GO and that (b) inspired to outdoor engagement partially mediated the relationship between inspired by playing Pok\'{e}mon GO and environmental awareness. These results warrant further investigations into whether LBGs could motivate pro-environment attitudes and inspire people to care for nature.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {755},
numpages = {15},
keywords = {Location based games, environmental awareness, gamification, inspiration, mixed-methods},
location = {Honolulu, HI, USA},
series = {CHI '24},
TAGS = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613905.3638181,
author = {Luo, Weizhou},
title = {Exploring Spatial Organization Strategies for Virtual Content in Mixed Reality Environments},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3638181},
doi = {10.1145/3613905.3638181},
abstract = {Our future will likely be reshaped by Mixed Reality (MR) offering boundless display space while preserving the context of real-world surroundings. However, to fully leverage the spatial capabilities of MR technology, a better understanding of how and where to place virtual content like documents is required, particularly considering the situated context. I aim to explore spatial organization strategies for virtual content in MR environments. For that, we conducted empirical studies investigating users’ strategies for document layout and placement and examined two real-world factors: physical environments and people present. With this knowledge, we proposed a mixed-reality approach for the in-situ exploration and analysis of human movement data utilizing physical objects in the original space as referents. My next steps include exploring arrangement strategies, designing techniques empowering spatial organization, and extending understandings for multi-user scenarios. My dissertation will enrich the immersive interface repertoire and contribute to the design of future MR systems.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {436},
numpages = {6},
keywords = {Augmented Reality, Mixed Reality, Spatiality, affordance, content organization, spatial layout},
location = {Honolulu, HI, USA},
series = {CHI EA '24},
tags = {Doctoral Consortium,CHI24}
}
@inproceedings{10.1145/3613904.3642176,
author = {Stellmacher, Carolin and Mathis, Florian and Weiss, Yannick and Loerakker, Meagan B. and Wagener, Nadine and Sch\"{o}ning, Johannes},
title = {Exploring Mobile Devices as Haptic Interfaces for Mixed Reality},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642176},
doi = {10.1145/3613904.3642176},
abstract = {Dedicated handheld controllers facilitate haptic experiences of virtual objects in mixed reality (MR). However, as mobile MR becomes more prevalent, we observe the emergence of controller-free MR interactions. To retain immersive haptic experiences, we explore the use of mobile devices as a substitute for specialised MR controller. In an exploratory gesture elicitation study (n = 18), we examined users’ (1) intuitive hand gestures performed with prospective mobile devices and (2) preferences for real-time haptic feedback when exploring haptic object properties. Our results reveal three haptic exploration modes for the mobile device, as an object, hand substitute, or as an additional tool, and emphasise the benefits of incorporating the device’s unique physical features into the object interaction. This work expands the design possibilities using mobile devices for tangible object interaction, guiding the future design of mobile devices for haptic MR experiences.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {422},
numpages = {17},
keywords = {gesture elicitation, haptic exploration, haptic feedback, haptic interfaces, mixed reality, mobile gestures, mobile phones},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642563,
author = {Weitz, Katharina and Schlagowski, Ruben and Andr\'{e}, Elisabeth and M\"{a}nniste, Maris and George, Ceenu},
title = {Explaining It Your Way - Findings from a Co-Creative Design Workshop on Designing XAI Applications with AI End-Users from the Public Sector},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642563},
doi = {10.1145/3613904.3642563},
abstract = {Human-Centered AI prioritizes end-users’ needs like transparency and usability. This is vital for applications that affect people’s everyday lives, such as social assessment tasks in the public sector. This paper discusses our pioneering effort to involve public sector AI users in XAI application design through a co-creative workshop with unemployment consultants from Estonia. The workshop’s objectives were identifying user needs and creating novel XAI interfaces for the used AI system. As a result of our user-centered design approach, consultants were able to develop AI interface prototypes that would support them in creating success stories for their clients by getting detailed feedback and suggestions. We present a discussion on the value of co-creative design methods with end-users working in the public sector to improve AI application design and provide a summary of recommendations for practitioners and researchers working on AI systems in the public sector.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {745},
numpages = {14},
keywords = {Co-Creation, Explainable AI, Focus Group, Human-Centered AI, Social Assessment, Unemployment Insurance, User-Centered Design},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642563,
author = {Weitz, Katharina and Schlagowski, Ruben and Andr\'{e}, Elisabeth and M\"{a}nniste, Maris and George, Ceenu},
title = {Explaining It Your Way - Findings from a Co-Creative Design Workshop on Designing XAI Applications with AI End-Users from the Public Sector},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642563},
doi = {10.1145/3613904.3642563},
abstract = {Human-Centered AI prioritizes end-users’ needs like transparency and usability. This is vital for applications that affect people’s everyday lives, such as social assessment tasks in the public sector. This paper discusses our pioneering effort to involve public sector AI users in XAI application design through a co-creative workshop with unemployment consultants from Estonia. The workshop’s objectives were identifying user needs and creating novel XAI interfaces for the used AI system. As a result of our user-centered design approach, consultants were able to develop AI interface prototypes that would support them in creating success stories for their clients by getting detailed feedback and suggestions. We present a discussion on the value of co-creative design methods with end-users working in the public sector to improve AI application design and provide a summary of recommendations for practitioners and researchers working on AI systems in the public sector.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {745},
numpages = {14},
keywords = {Co-Creation, Explainable AI, Focus Group, Human-Centered AI, Social Assessment, Unemployment Insurance, User-Centered Design},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613905.3636304,
author = {Villa, Steeven and Welsch, Robin and Denisova, Alena and Kosch, Thomas},
title = {Evaluating Interactive AI: Understanding and Controlling Placebo Effects in Human-AI Interaction},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3636304},
doi = {10.1145/3613905.3636304},
abstract = {In the medical field, patients often experience tangible benefits from treatments they expect will improve their condition, even if the treatment has no mechanism of effect. This phenomenon often obscuring scientific evaluation of human treatment is termed the "placebo effect." Latest research in human-computer interaction has shown that using cutting-edge technologies similarly raises expectations of improvement, culminating in placebo effects that undermine evaluation efforts for user studies. This workshop delves into the role of placebo effects in human-computer interaction for cutting-edge technologies such as artificial intelligence, its influence as a confounding factor in user studies, and identifies methods that researchers can adopt to reduce its impact on study findings. By the end of this workshop, attendees will be equipped to incorporate placebo control measures in their experimental designs.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {468},
numpages = {4},
keywords = {AI, Adaptive Interface, Evaluation, Expectation, Placebo, User Studies},
location = {Honolulu, HI, USA},
series = {CHI EA '24},
tags = {Workshop,CHI24}
}
@inproceedings{10.1145/3613905.3651068,
author = {Kumar, Chandan and Saini, Bhupender Kumar and Staab, Steffen},
title = {Enhancing Online Meeting Experience through Shared Gaze-Attention},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3651068},
doi = {10.1145/3613905.3651068},
abstract = {Eye contact represents a fundamental element of human social interactions, providing essential non-verbal signals. Traditionally, it has played a crucial role in fostering social bonds during in-person gatherings. However, in the realm of virtual and online meetings, the capacity for meaningful eye contact is often compromised by the limitations of the platforms we use. In response to this challenge, we present an application framework that leverages webcams to detect and share eye gaze attention among participants. Through the framework, we organized 13 group meetings involving a total of 43 participants. The results highlight that the inclusion of gaze attention can enrich interactive experiences and elevate engagement levels in online meetings. Additionally, our evaluation of two levels of gaze sharing schemes indicates that users predominantly favor viewing gaze attention directed toward themselves, as opposed to visualizing detailed attention, which tends to lead to distraction and information overload.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {128},
numpages = {6},
keywords = {collaboration, eye contact, gaze attention, social interaction, virtual meeting},
location = {Honolulu, HI, USA},
series = {CHI EA '24},
tags = {Late Breaking Work,CHI24}
}
@inproceedings{10.1145/3613904.3641909,
author = {Colley, Mark and Wanner, Beate and R\"{a}dler, Max and R\"{o}tzer, Marcel and Frommel, Julian and Hirzle, Teresa and Jansen, Pascal and Rukzio, Enrico},
title = {Effects of a Gaze-Based 2D Platform Game on User Enjoyment, Perceived Competence, and Digital Eye Strain},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641909},
doi = {10.1145/3613904.3641909},
abstract = {Gaze interaction is a promising interaction method to increase variety, challenge, and fun in games.We present “Shed Some Fear”, a 2D platform game including numerous eye-gaze-based interactions. “Shed Some Fear” includes control with eye-gaze and traditional keyboard input. The eye-gaze interactions are partially based on eye exercises reducing digital eye strain but also on employing peripheral vision. By employing eye-gaze as a necessary input mechanism, we explore the effects on and tradeoffs between user enjoyment and digital eye strain in a five-day longitudinal between-subject study (N=17) compared to interaction with a traditional mouse. We found that perceived competence was significantly higher with eye gaze interaction and significantly higher internal eye strain. With this work, we contribute to the not straightforward inclusion of eye tracking as a useful and fun input method for games.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {369},
numpages = {14},
keywords = {2D platform, digital eye strain, eye-gaze, gamification},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642243,
author = {Stemasov, Evgeny and Wagner, Tobias and Askari, Ali and Janek, Jessica and Rajabi, Omid and Schikorr, Anja and Frommel, Julian and Gugenheimer, Jan and Rukzio, Enrico},
title = {DungeonMaker: Embedding Tangible Creation and Destruction in Hybrid Board Games through Personal Fabrication Technology},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642243},
doi = {10.1145/3613904.3642243},
abstract = {Hybrid board games (HBGs) augment their analog origins digitally (e.g., through apps) and are an increasingly popular pastime activity. Continuous world and character development and customization, known to facilitate engagement in video games, remain rare in HBGs. If present, they happen digitally or imaginarily, often leaving physical aspects generic. We developed DungeonMaker, a fabrication-augmented HBG bridging physical and digital game elements: 1) the setup narrates a story and projects a digital game board onto a laser cutter; 2) DungeonMaker assesses player-crafted artifacts; 3) DungeonMaker’s modified laser head senses and moves player- and non-player figures, and 4) can physically damage figures. An evaluation (n = 4 \texttimes{} 3) indicated that DungeonMaker provides an engaging experience, may support players’ connection to their figures, and potentially spark novices’ interest in fabrication. DungeonMaker provides a rich constellation to play HBGs by blending aspects of craft and automation to couple the physical and digital elements of an HBG tightly.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {328},
numpages = {20},
keywords = {3D-Printers, Board Games, Craft Games, Fabrication Games, Hybrid Board Games, Laser Cutters, Personal Fabrication, Playful Fabrication},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642863,
author = {Delgado Rodriguez, Sarah and Chatterjee, Priyasha and Dao Phuong, Anh and Alt, Florian and Marky, Karola},
title = {Do You Need to Touch? Exploring Correlations between Personal Attributes and Preferences for Tangible Privacy Mechanisms},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642863},
doi = {10.1145/3613904.3642863},
abstract = {This paper explores how personal attributes, such as age, gender, technological expertise, or “need for touch”, correlate with people’s preferences for properties of tangible privacy protection mechanisms, for example, physically covering a camera. For this, we conducted an online survey (N = 444) where we captured participants’ preferences of eight established tangible privacy mechanisms well-known in daily life, their perceptions of effective privacy protection, and personal attributes. We found that the attributes that correlated most strongly with participants’ perceptions of the established tangible privacy mechanisms were their “need for touch” and previous experiences with the mechanisms. We use our findings to identify desirable characteristics of tangible mechanisms to better inform future tangible, digital, and mixed privacy protections. We also show which individuals benefit most from tangibles, ultimately motivating a more individual and effective approach to privacy protection in the future.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {981},
numpages = {23},
keywords = {internet of things, privacy, tangible, tangible privacy},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,Honorable Mention,CHI24}
}
@inproceedings{10.1145/3613904.3642408,
author = {Ring, Patrizia and Tietenberg, Julius and Emmerich, Katharina and Masuch, Maic},
title = {Development and Validation of the Collision Anxiety Questionnaire for VR Applications},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642408},
doi = {10.1145/3613904.3642408},
abstract = {The high degree of sensory immersion is a distinctive feature of head-mounted virtual reality (VR) systems. While the visual detachment from the real world enables unique immersive experiences, users risk collisions due to their inability to perceive physical obstacles in their environment. Even the mere anticipation of a collision can adversely affect the overall experience and erode user confidence in the VR system. However, there are currently no valid tools for assessing collision anxiety. We present the iterative development and validation of the Collision Anxiety Questionnaire (CAQ), involving an exploratory and a confirmatory factor analysis with a total of 159 participants. The results provide evidence for both discriminant and convergent validity and a good model fit for the final CAQ with three subscales: general collision anxiety, orientation, and interpersonal collision anxiety. By utilizing the CAQ, researchers can examine potential confounding effects of collision anxiety and evaluate methods for its mitigation.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {605},
numpages = {13},
keywords = {assessment, collision anxiety, discomfort, fear, user experience, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,Honorable Mention,CHI24}
}
@inproceedings{10.1145/3613904.3642859,
author = {Bensch, Leonie and Nilsson, Tommy and Wulkop, Jan and Demedeiros, Paul and Herzberger, Nicolas Daniel and Preutenborbeck, Michael and Gerndt, Andreas and Flemisch, Frank and Dufresne, Florian and Albuquerque, Georgia and Cowley, Aidan},
title = {Designing for Human Operations on the Moon: Challenges and Opportunities of Navigational HUD Interfaces},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642859},
doi = {10.1145/3613904.3642859},
abstract = {Future crewed missions to the Moon will face significant environmental and operational challenges, posing risks to the safety and performance of astronauts navigating its inhospitable surface. Whilst head-up displays (HUDs) have proven effective in providing intuitive navigational support on Earth, the design of novel human-spaceflight solutions typically relies on costly and time-consuming analogue deployments, leaving the potential use of lunar HUDs largely under-explored. This paper explores an alternative approach by simulating navigational HUD concepts in a high-fidelity Virtual Reality (VR) representation of the lunar environment. In evaluating these concepts with astronauts and other aerospace experts (n=25), our mixed methods study demonstrates the efficacy of simulated analogues in facilitating rapid design assessments of early-stage HUD solutions. We illustrate this by elaborating key design challenges and guidelines for future lunar HUDs. In reflecting on the limitations of our approach, we propose directions for future design exploration of human-machine interfaces for the Moon.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {718},
numpages = {21},
keywords = {astronaut, augmented reality, head-up display, human factors, human space flight, human-system exploration, lunar exploration, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642143,
author = {Yu, Xingyao and Lee, Benjamin and Sedlmair, Michael},
title = {Design Space of Visual Feedforward And Corrective Feedback in XR-Based Motion Guidance Systems},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642143},
doi = {10.1145/3613904.3642143},
abstract = {Extended reality (XR) technologies are highly suited in assisting individuals in learning motor skills and movements—referred to as motion guidance. In motion guidance, the “feedforward’’ provides instructional cues of the motions that are to be performed, whereas the “feedback’’ provides cues which help correct mistakes and minimize errors. Designing synergistic feedforward and feedback is vital to providing an effective learning experience, but this interplay between the two has not yet been adequately explored. Based on a survey of the literature, we propose design space for both motion feedforward and corrective feedback in XR, and describe the interaction effects between them. We identify common design approaches of XR-based motion guidance found in our literature corpus, and discuss them through the lens of our design dimensions. We then discuss additional contextual factors and considerations that influence this design, together with future research opportunities for motion guidance in XR.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {723},
numpages = {15},
keywords = {Design Space, Extended Reality, Motion Guidance, Visualization},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642591,
author = {Marky, Karola and St\"{o}ver, Alina and Prange, Sarah and Bleck, Kira and Gerber, Paul and Zimmermann, Verena and M\"{u}ller, Florian and Alt, Florian and M\"{u}hlh\"{a}user, Max},
title = {Decide Yourself or Delegate - User Preferences Regarding the Autonomy of Personal Privacy Assistants in Private IoT-Equipped Environments},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642591},
doi = {10.1145/3613904.3642591},
abstract = {Personalized privacy assistants (PPAs) communicate privacy-related decisions of their users to Internet of Things (IoT) devices. There are different ways to implement PPAs by varying the degree of autonomy or decision model. This paper investigates user perceptions of PPA autonomy models and privacy profiles – archetypes of individual privacy needs – as a basis for PPA decisions in private environments (e.g., a friend’s home). We first explore how privacy profiles can be assigned to users and propose an assignment method. Next, we investigate user perceptions in 18 usage scenarios with varying contexts, data types and number of decisions in a study with 1126 participants. We found considerable differences between the profiles in settings with few decisions. If the number of decisions gets high (> 1/h), participants exclusively preferred fully autonomous PPAs. Finally, we discuss implications and recommendations for designing scalable PPAs that serve as privacy interfaces for future IoT devices.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {851},
numpages = {20},
keywords = {IoT, personal privacy assistance, privacy, privacy profiles},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613905.3636287,
author = {Desai, Smit and Wei, Christina Ziying and Sin, Jaisie and Dubiel, Mateusz and Zargham, Nima and Ahire, Shashank and Porcheron, Martin and Kuzminykh, Anastasia and Lee, Minha and Candello, Heloisa and Fischer, Joel E and Munteanu, Cosmin and Cowan, Benjamin R.},
title = {CUI@CHI 2024: Building Trust in CUIs—From Design to Deployment},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3636287},
doi = {10.1145/3613905.3636287},
abstract = {Conversational user interfaces (CUIs) have become an everyday technology for people the world over, as well as a booming area of research. Advances in voice synthesis and the emergence of chatbots powered by large language models (LLMs), notably ChatGPT, have pushed CUIs to the forefront of human-computer interaction (HCI) research and practice. Now that these technologies enable an elemental level of usability and user experience (UX), we must turn our attention to higher-order human factors: trust and reliance. In this workshop, we aim to bring together a multidisciplinary group of researchers and practitioners invested in the next phase of CUI design. Through keynotes, presentations, and breakout sessions, we will share our knowledge, identify cutting-edge resources, and fortify an international network of CUI scholars. In particular, we will engage with the complexity of trust and reliance as attitudes and behaviours that emerge when people interact with conversational agents.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {460},
numpages = {7},
keywords = {chatbots, conversational AI, conversational agents, conversational user interfaces, reliance, trust, voice assistants},
location = {Honolulu, HI, USA},
series = {CHI EA '24},
tags = {Workshop,CHI24}
}
@inproceedings{10.1145/3613905.3650780,
author = {Kaushik, Smirity and Sharma, Tanusree and Yu, Yaman and Ali, Amna F and Wang, Yang and Zou, Yixin},
title = {Cross-Country Examination of People’s Experience with Targeted Advertising on Social Media},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650780},
doi = {10.1145/3613905.3650780},
abstract = {Social media effectively connects businesses with diverse audiences. However, research related to targeted advertising and social media is rarely done beyond Western contexts. Through an online survey with 412 participants in the United States and three South Asian countries (Bangladesh, India, and Pakistan), we found significant differences in participants’ ad preferences, perceptions, and coping behaviors that correlate with individuals’ country of origin, culture, religion, and other demographic factors. For instance, Indian and Pakistani participants preferred video ads to those in the US. Participants relying on themselves (horizontal individualism) also expressed more concerns about the security and privacy issues of targeted ads. Muslim participants were more likely to hide ads as a coping strategy than other religious groups. Our findings highlight that people’s experiences with targeted advertising are rooted in their national, cultural, and religious backgrounds—an important lesson for the design of ad explanations and settings, user education, and platform governance.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {91},
numpages = {10},
keywords = {Privacy, South Asia, Targeted Advertisement},
location = {Honolulu, HI, USA},
series = {CHI EA '24},
tags = {Late Breaking Work,CHI24}
}
@inproceedings{10.1145/3613904.3642687,
author = {Hosseini, Masoumehsadat and Mueller, Heiko and Boll, Susanne},
title = {Controlling the Rooms: How People Prefer Using Gestures to Control Their Smart Homes},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642687},
doi = {10.1145/3613904.3642687},
abstract = {Gesture interactions have become ubiquitous, and with increasingly reliable sensing technology we can anticipate their use in everyday environments such as smart homes. Gestures must meet users’ needs and constraints in diverse scenarios to gain widespread acceptance. Although mid-air gestures have been proposed in various user contexts, it is still unclear to what extent users want to integrate them into different scenarios in their smart homes, along with the motivations driving this desire. Furthermore, it is uncertain whether users will remain consistent in their suggestions when transitioning to alternative scenarios within a smart home. This study contributes methodologically by adapting a bottom-up frame-based design process. We offer insights into preferred devices and commands in different smart home scenarios. Using our results, we can assist in designing gestures in the smart home that are consistent with individual needs across devices and scenarios, while maximizing the reuse and transferability of gestural knowledge.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {550},
numpages = {18},
keywords = {Gesture elicitation, agreement rate, scenario-based interaction, smart home, study design},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613905.3650830,
author = {Sehrt, Jessica and Yilmaz, Ugur and Kosch, Thomas and Schwind, Valentin},
title = {Closing the Loop: The Effects of Biofeedback Awareness on Physiological Stress Response Using Electrodermal Activity in Virtual Reality},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650830},
doi = {10.1145/3613905.3650830},
abstract = {This paper presents the results of a user study examining the impact of biofeedback awareness on the effectiveness of stress management, utilizing Electrodermal Activity (EDA) as the primary metric within an immersive Virtual Reality (VR). Employing a between-subjects design (N=30), we probed whether informing individuals of their capacity to manipulate the VR environment’s weather impacts their physiological stress responses. Our results indicate lower EDA levels of participants who were informed of their biofeedback control than those participants who were not informed about their biofeedback control. Interestingly, the participants who were informed about the control over the environment also manifested variations in their EDA responses. Participants who were not informed of their ability to control the weather showed decreased EDA measures until the end of the biofeedback phase. This study enhances our comprehension of the significance of awareness in biofeedback in immersive settings and its potential to augment stress management techniques.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {76},
numpages = {7},
keywords = {Awareness, Biofeedback, Electrodermal Activity, Stress, Virtual Reality},
location = {Honolulu, HI, USA},
series = {CHI EA '24},
tags = {Late Breaking Work,CHI24}
}
@inproceedings{10.1145/3613904.3642124,
author = {Karaosmanoglu, Sukran and Cmentowski, Sebastian and Nacke, Lennart E. and Steinicke, Frank},
title = {Born to Run, Programmed to Play: Mapping the Extended Reality Exergames Landscape},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642124},
doi = {10.1145/3613904.3642124},
abstract = {Many people struggle to exercise regularly, raising the risk of serious health-related issues. Extended reality (XR) exergames address these hurdles by combining physical exercises with enjoyable, immersive gameplay. While a growing body of research explores XR exergames, no previous review has structured this rapidly expanding research landscape. We conducted a scoping review of the current state of XR exergame research to (i) provide a structured overview, (ii) highlight trends, and (iii) uncover knowledge gaps. After identifying 1318 papers in human-computer interaction and medical databases, we ultimately included 186 papers in our analysis. We provide a quantitative and qualitative summary of XR exergame research, showing current trends and potential future considerations. Finally, we provide a taxonomy of XR exergames to help future design and methodological investigation and reporting.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {309},
numpages = {28},
keywords = {active games, active video games, augmented reality, exercise, exergames, extended reality, games, mixed reality, motion games, movement games, review, sports games, taxonomy, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642073,
author = {Zenner, Andr\'{e} and Karr, Chiara and Feick, Martin and Ariza, Oscar and Kr\"{u}ger, Antonio},
title = {Beyond the Blink: Investigating Combined Saccadic \& Blink-Suppressed Hand Redirection in Virtual Reality},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642073},
doi = {10.1145/3613904.3642073},
abstract = {In pursuit of hand redirection techniques that are ever more tailored to human perception, we propose the first algorithm for hand redirection in virtual reality that makes use of saccades, i.e., fast ballistic eye movements that are accompanied by the perceptual phenomenon of change blindness. Our technique combines the previously proposed approaches of gradual hand warping and blink-suppressed hand redirection with the novel approach of saccadic redirection in one unified yet simple algorithm. We compare three variants of the proposed Saccadic \& Blink-Suppressed Hand Redirection (SBHR) technique with the conventional approach to redirection in a psychophysical study (N = 25). Our results highlight the great potential of our proposed technique for comfortable redirection by showing that SBHR allows for significantly greater magnitudes of unnoticeable redirection while being perceived as significantly less intrusive and less noticeable than commonly employed techniques that only use gradual hand warping.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {750},
numpages = {14},
keywords = {change blindness, detection thresholds, eye blinks, hand redirection, saccades, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642666,
author = {Bahnsen, Kilian L and Tiemann, Lucas and Plabst, Lucas and Grundgeiger, Tobias},
title = {Augmented Reality Cues Facilitate Task Resumption after Interruptions in Computer-Based and Physical Tasks},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642666},
doi = {10.1145/3613904.3642666},
abstract = {Many work domains include numerous interruptions, which can contribute to errors. We investigated the potential of augmented reality (AR) cues to facilitate primary task resumption after interruptions of varying lengths. Experiment 1 (N&nbsp;=&nbsp;83) involved a computer-based primary task with a red AR arrow at the to-be-resumed task step which was placed via a gesture by the participants or automatically. Compared to no cue, both cues significantly reduced the resumption lag (i.e., the time between the end of the interruption and the resumption of the primary task) following long but not short interruptions. Experiment 2 (N&nbsp;=&nbsp;38) involved a tangible sorting task, utilizing only the automatic cue. The AR cue facilitated task resumption compared to not cue after both short and long interruptions. We demonstrated the potential of AR cues in mitigating the negative effects of interruptions and make suggestions for integrating AR technologies for task resumption.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {78},
numpages = {16},
keywords = {Augmented Reality, Human Error, Interruption, Resumption Lag, Task Resumption},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642631,
author = {Katins, Christopher and Wo\'{z}niak, Pawe\l{} W. and Chen, Aodi and Tumay, Ihsan and Le, Luu Viet Trinh and Uschold, John and Kosch, Thomas},
title = {Assessing User Apprehensions About Mixed Reality Artifacts and Applications: The Mixed Reality Concerns (MRC) Questionnaire},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642631},
doi = {10.1145/3613904.3642631},
abstract = {Current research in Mixed Reality (MR) presents a wide range of novel use cases for blending virtual elements with the real world. This yet-to-be-ubiquitous technology challenges how users currently work and interact with digital content. While offering many potential advantages, MR technologies introduce new security, safety, and privacy challenges. Thus, it is relevant to understand users’ apprehensions towards MR technologies, ranging from security concerns to social acceptance. To address this challenge, we present the Mixed Reality Concerns (MRC) Questionnaire, designed to assess users’ concerns towards MR artifacts and applications systematically. The development followed a structured process considering previous work, expert interviews, iterative refinements, and confirmatory tests to analytically validate the questionnaire. The MRC Questionnaire offers a new method of assessing users’ critical opinions to compare and assess novel MR artifacts and applications regarding security, privacy, social implications, and trust.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {604},
numpages = {13},
keywords = {Concerns, Mixed Reality, Privacy, Safety, Security, Social Acceptance, Trust, User Apprehensions},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642436,
author = {Gray, Colin M. and Santos, Cristiana Teixeira and Bielova, Nataliia and Mildner, Thomas},
title = {An Ontology of Dark Patterns Knowledge: Foundations, Definitions, and a Pathway for Shared Knowledge-Building},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642436},
doi = {10.1145/3613904.3642436},
abstract = {Deceptive and coercive design practices are increasingly used by companies to extract profit, harvest data, and limit consumer choice. Dark patterns represent the most common contemporary amalgamation of these problematic practices, connecting designers, technologists, scholars, regulators, and legal professionals in transdisciplinary dialogue. However, a lack of universally accepted definitions across the academic, legislative, practitioner, and regulatory space has likely limited the impact that scholarship on dark patterns might have in supporting sanctions and evolved design practices. In this paper, we seek to support the development of a shared language of dark patterns, harmonizing ten existing regulatory and academic taxonomies of dark patterns and proposing a three-level ontology with standardized definitions for 64 synthesized dark pattern types across low-, meso-, and high-level patterns. We illustrate how this ontology can support translational research and regulatory action, including transdisciplinary pathways to extend our initial types through new empirical work across application and technology domains.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {289},
numpages = {22},
keywords = {dark patterns, deceptive design, ontology, regulation},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3641930,
author = {Xiao, Lan and Bandukda, Maryam and Angerbauer, Katrin and Lin, Weiyue and Bhatnagar, Tigmanshu and Sedlmair, Michael and Holloway, Catherine},
title = {A Systematic Review of Ability-diverse Collaboration through Ability-based Lens in HCI},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641930},
doi = {10.1145/3613904.3641930},
abstract = {In a world where diversity is increasingly recognised and celebrated, it is important for HCI to embrace the evolving methods and theories for technologies to reflect the diversity of its users and be ability-centric. Interdependence Theory, an example of this evolution, highlights the interpersonal relationships between humans and technologies and how technologies should be designed to meet shared goals and outcomes for people, regardless of their abilities. This necessitates a contemporary understanding of "ability-diverse collaboration," which motivated this review. In this review, we offer an analysis of 117 papers sourced from the ACM Digital Library spanning the last two decades. We contribute (1) a unified taxonomy and the Ability-Diverse Collaboration Framework, (2) a reflective discussion and mapping of the current design space, and (3) future research opportunities and challenges. Finally, we have released our data and analysis tool to encourage the HCI research community to contribute to this ongoing effort.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {961},
numpages = {21},
keywords = {Interdependence, ability-based method, accessibility, collaboration},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags  = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642071,
author = {Liao, Yi-Chi and Desai, Ruta and Pierce, Alec M and Taylor, Krista E. and Benko, Hrvoje and Jonker, Tanya R. and Gupta, Aakar},
title = {A Meta-Bayesian Approach for Rapid Online Parametric Optimization for Wrist-based Interactions},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642071},
doi = {10.1145/3613904.3642071},
abstract = {Wrist-based input often requires tuning parameter settings in correspondence to between-user and between-session differences, such as variations in hand anatomy, wearing position, posture, etc. Traditionally, users either work with predefined parameter values not optimized for individuals or undergo time-consuming calibration processes. We propose an online Bayesian Optimization (BO)-based method for rapidly determining the user-specific optimal settings of wrist-based pointing. Specifically, we develop a meta-Bayesian optimization (meta-BO) method, differing from traditional human-in-the-loop BO: By incorporating meta-learning of prior optimization data from a user population with BO, meta-BO enables rapid calibration of parameters for new users with a handful of trials. We evaluate our method with two representative and distinct wrist-based interactions: absolute and relative pointing. On a weighted-sum metric that consists of completion time, aiming error, and trajectory quality, meta-BO improves absolute pointing performance by <Formula format="inline"><TexMath><?TeX $22.92\%$?></TexMath><AltText>Math 1</AltText><File name="chi24-182-inline1" type="svg"/></Formula> and <Formula format="inline"><TexMath><?TeX $21.35\%$?></TexMath><AltText>Math 2</AltText><File name="chi24-182-inline2" type="svg"/></Formula> compared to BO and manual calibration, and improves relative pointing performance by <Formula format="inline"><TexMath><?TeX $25.43\%$?></TexMath><AltText>Math 3</AltText><File name="chi24-182-inline3" type="svg"/></Formula> and <Formula format="inline"><TexMath><?TeX $13.60\%$?></TexMath><AltText>Math 4</AltText><File name="chi24-182-inline4" type="svg"/></Formula>.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {410},
numpages = {38},
keywords = {Bayesian optimization, adaptive interface., calibration, human-in-the-loop optimization, meta-Bayesian optimization, meta-learning, target selection, wrist-based interaction},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642370,
author = {Haliburton, Luke and Gr\"{u}ning, David Joachim and Riedel, Frederik and Schmidt, Albrecht and Terzimehi\'{c}, Na\dj{}a},
title = {A Longitudinal In-the-Wild Investigation of Design Frictions to Prevent Smartphone Overuse},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642370},
doi = {10.1145/3613904.3642370},
abstract = {Smartphone overuse is hyper-prevalent in society, and developing tools to prevent this overuse has become a focus of HCI. However, there is a lack of work investigating smartphone overuse interventions over the long term. We collected usage data from N = 1, 039 users of one sec over an average of 13.4 weeks and qualitative insights from 249 of the users through an online survey. We found that users overwhelmingly choose to target Social Media apps. We found that the short design frictions introduced by one sec effectively reduce how often users attempt to open target apps and lead to more intentional app-openings over time. Additionally, we found that users take periodic breaks from one sec interventions, and quickly rebound from a pattern of overuse when returning from breaks. Overall, we contribute findings from a longitudinal investigation of design frictions in the wild and identify usage patterns from real users in practice.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {243},
numpages = {16},
keywords = {behavior change, design frictions, long-term, smartphone overuse},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642697,
author = {Lee, Mina and Gero, Katy Ilonka and Chung, John Joon Young and Shum, Simon Buckingham and Raheja, Vipul and Shen, Hua and Venugopalan, Subhashini and Wambsganss, Thiemo and Zhou, David and Alghamdi, Emad A. and August, Tal and Bhat, Avinash and Choksi, Madiha Zahrah and Dutta, Senjuti and Guo, Jin L.C. and Hoque, Md Naimul and Kim, Yewon and Knight, Simon and Neshaei, Seyed Parsa and Shibani, Antonette and Shrivastava, Disha and Shroff, Lila and Sergeyuk, Agnia and Stark, Jessi and Sterman, Sarah and Wang, Sitong and Bosselut, Antoine and Buschek, Daniel and Chang, Joseph Chee and Chen, Sherol and Kreminski, Max and Park, Joonsuk and Pea, Roy and Rho, Eugenia Ha Rim and Shen, Zejiang and Siangliulue, Pao},
title = {A Design Space for Intelligent and Interactive Writing Assistants},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642697},
doi = {10.1145/3613904.3642697},
abstract = {In our era of rapid technological advancement, the research landscape for writing assistants has become increasingly fragmented across various research communities. We seek to address this challenge by proposing a design space as a structured way to examine and explore the multidimensional space of intelligent and interactive writing assistants. Through community collaboration, we explore five aspects of writing assistants: task, user, technology, interaction, and ecosystem. Within each aspect, we define dimensions and codes by systematically reviewing 115 papers, while leveraging the expertise of researchers in various disciplines. Our design space aims to offer researchers and designers a practical tool to navigate, comprehend, and compare the various possibilities of writing assistants, and aid in the design of new writing assistants.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {1054},
numpages = {35},
keywords = {Artificial Intelligence, Design Space, Language Models, Writing Assistants, Writing Support Tools},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613905.3650938,
author = {Schmitz, Martin and Sch\"{o}n, Dominik and Klagemann, Henning and Kosch, Thomas},
title = {3DA: Assessing 3D-Printed Electrodes for Measuring Electrodermal Activity},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650938},
doi = {10.1145/3613905.3650938},
abstract = {Electrodermal activity (EDA) reflects changes in skin conductance, which are closely tied to human psychophysiological states. For example, EDA sensors can assess stress, cognitive workload, arousal, or other measures tied to the sympathetic nervous system for interactive human-centered applications. Yet, current limitations involve the complex attachment and proper skin contact with EDA sensors. This paper explores the concept of 3D printing electrodes for EDA measurements, integrating sensors into arbitrary 3D-printed objects, alleviating the need for complex assembly and attachment. We examine the adaptation of conventional EDA circuits for 3D-printed electrodes, assessing different electrode shapes and their impact on the sensing accuracy. A user study (N=6) revealed that 3D-printed electrodes can measure EDA with similar accuracy, suggesting larger contact areas for improved precision. We derive design implications to facilitate the integration of EDA sensors into 3D-printed devices to foster diverse integration into everyday objects for prototyping physiological interfaces.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {14},
numpages = {7},
keywords = {3D Printing, Electrodermal Activity, Physiological Sensing},
location = {Honolulu, HI, USA},
series = {CHI EA '24},
tags = {Late Breaking Work,CHI24} 
}
@inproceedings{10.1145/3613904.3642426,
author = {Zargham, Nima and Fetni, Mohamed Lamine and Spillner, Laura and Muender, Thomas and Malaka, Rainer},
title = {"I Know What You Mean": Context-Aware Recognition to Enhance Speech-Based Games},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642426},
doi = {10.1145/3613904.3642426},
abstract = {Recent advances in language processing and speech recognition open up a large opportunity for video game companies to embrace voice interaction as an intuitive feature and appealing game mechanics. However, speech-based systems still remain liable to recognition errors. These add a layer of challenge on top of the game’s existing obstacles, preventing players from reaching their goals and thus often resulting in player frustration. This work investigates a novel method called context-aware speech recognition, where the game environment and actions are used as supplementary information to enhance recognition in a speech-based game. In a between-subject user study (<Formula format="inline"><TexMath><?TeX $N~{=}~40$?></TexMath><AltText>Math 1</AltText><File name="chi24-534-inline1" type="svg"/></Formula>), we compared our proposed method with a standard method in which recognition is based only on the voice input without taking context into account. Our results indicate that our proposed method could improve the player experience and the usability of the speech system.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {956},
numpages = {18},
keywords = {Game Design, Speech Recognition, Speech-Based Systems, Voice Interaction, Voice-Controlled Game},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,Honorable Mention,CHI24}
}
@inproceedings{10.1145/3613905.3650834,
author = {Sayffaerth, Clara and Rasch, Julian and M\"{u}ller, Florian},
title = {“Tele” Me More: Using Telepresence Charades to Connect Strangers and Exhibits in Different Museums},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650834},
doi = {10.1145/3613905.3650834},
abstract = {The museum is changing from a place of passive consumption to a place of interactive experiences, opening up new ways of engaging with exhibits and others. As a promising direction, this paper explores the potential of telepresence stations in the museum context to enhance social connectedness among visitors over distance. Emphasizing the significance of social exchange, our research focuses on studying telepresence to foster interactions between strangers, share knowledge, and promote social connectedness. To do so, we first observe exhibitions and then interview individual visitors of a technical museum about their experiences and needs. Based on the results, we design appropriate voiceless and touchless communication channels and test them in a study. The findings of our in-situ user study with 24 visitors unfamiliar with each other in the museum provide insights into behaviors and perceptions, contributing valuable knowledge on seamlessly integrating telepresence technology in exhibitions, with a focus on enhancing learning, social connections, and the museum experience in general.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {389},
numpages = {8},
keywords = {Museum, Remote Play, Social Connectedness, Telepresence},
location = {Honolulu, HI, USA},
series = {CHI EA '24},
tags = {Late Breaking Work,CHI24}
}
@inproceedings{10.1145/3613904.3641964,
author = {Kobiella, Charlotte and Flores L\'{o}pez, Yarhy Said and Waltenberger, Franz and Draxler, Fiona and Schmidt, Albrecht},
title = {"If the Machine Is As Good As Me, Then What Use Am I?" – How the Use of ChatGPT Changes Young Professionals' Perception of Productivity and Accomplishment},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641964},
doi = {10.1145/3613904.3641964},
abstract = {Large language models (LLMs) like ChatGPT have been widely adopted in work contexts. We explore the impact of ChatGPT on young professionals’ perception of productivity and sense of accomplishment. We collected LLMs’ main use cases in knowledge work through a preliminary study, which served as the basis for a two-week diary study with 21 young professionals reflecting on their ChatGPT use. Findings indicate that ChatGPT enhanced some participants’ perceptions of productivity and accomplishment by enabling greater creative output and satisfaction from efficient tool utilization. Others experienced decreased perceived productivity and accomplishment, driven by a diminished sense of ownership, perceived lack of challenge, and mediocre results. We found that the suitability of task delegation to ChatGPT varies strongly depending on the task nature. It’s especially suitable for comprehending broad subject domains, generating creative solutions, and uncovering new information. It’s less suitable for research tasks due to hallucinations, which necessitate extensive validation.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {1018},
numpages = {16},
keywords = {Generative AI, knowledge work, productivity, self-efficacy, sense of accomplishment},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642633,
author = {Kloft, Agnes Mercedes and Welsch, Robin and Kosch, Thomas and Villa, Steeven},
title = {"AI enhances our performance, I have no doubt this one will do the same": The Placebo effect is robust to negative descriptions of AI},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642633},
doi = {10.1145/3613904.3642633},
abstract = {Heightened AI expectations facilitate performance in human-AI interactions through placebo effects. While lowering expectations to control for placebo effects is advisable, overly negative expectations could induce nocebo effects. In a letter discrimination task, we informed participants that an AI would either increase or decrease their performance by adapting the interface, when in reality, no AI was present in any condition. A Bayesian analysis showed that participants had high expectations and performed descriptively better irrespective of the AI description when a sham-AI was present. Using cognitive modeling, we could trace this advantage back to participants gathering more information. A replication study verified that negative AI descriptions do not alter expectations, suggesting that performance expectations with AI are biased and robust to negative verbal descriptions. We discuss the impact of user expectations on AI interactions and evaluation.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {299},
numpages = {24},
keywords = {Artificial Intelligence, Decision-making, Performance expectation, Placebo},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Full Paper,CHI24}
}
@inproceedings{10.1145/3613904.3642368,
author = {Kaufhold, Marc-Andr\'{e} and Riebe, Thea and Bayer, Markus and Reuter, Christian},
title = {‘We Do Not Have the Capacity to Monitor All Media’: A Design Case Study on Cyber Situational Awareness in Computer Emergency Response Teams},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642368},
doi = {10.1145/3613904.3642368},
abstract = {Computer Emergency Response Teams (CERTs) provide advisory, preventive and reactive cybersecurity services for authorities, citizens, and businesses. However, their responsibility of monitoring, analyzing, and communicating cyber threats have become challenging due to the growing volume and varying quality of information disseminated through public channels. Based on a design case study conducted from 2021 to 2023, this paper combines three iterations of expert interviews, design workshops and cognitive walkthroughs to design an automated, cross-platform and real-time cybersecurity dashboard. By adopting the notion of cyber situational awareness, the study extracts user requirements and design heuristics for enhanced threat awareness and mission awareness in CERTs, discussing the aspects of source integration, data management, customizable visualization, relationship awareness, information assessment, software integration, (inter-)organizational collaboration, and communication of stakeholder warnings.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {580},
numpages = {16},
keywords = {Computer Emergency Response Teams, Cyber Situational Awareness, Design Case Studies, Security and Privacy},
location = {Honolulu, HI, USA},
series = {CHI '24},
tags = {Best Paper,Full Paper,CHI24}
}
@inproceedings{10.1145/3544549.3585912,
author = {Rigling, Sebastian and Yu, Xingyao and Sedlmair, Michael},
title = {“In Your Face!”: Visualizing Fitness Tracker Data in Augmented Reality},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585912},
doi = {10.1145/3544549.3585912},
abstract = {The benefits of augmented reality (AR) have been demonstrated in both medicine and fitness, while its application in areas where these two fields overlap has been barely explored. We argue that AR opens up new opportunities to interact with, understand and share personal health data. To this end, we developed an app prototype that uses a Snapchat-like face filter to visualize personal health data from a fitness tracker in AR. We tested this prototype in two pilot studies and found that AR does have potential in this type of application. We suggest that AR cannot replace the current interfaces of smartwatches and mobile apps, but it can pick up where current technology falls short in creating intrinsic motivation and personal health awareness. We also provide ideas for future work in this direction.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {176},
numpages = {7},
keywords = {augmented reality, fitness tracker, health, visualization},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Late Breaking Work,CHI23}
}
@article{10.1145/3503514,
author = {Marky, Karola and Ragozin, Kirill and Chernyshov, George and Matviienko, Andrii and Schmitz, Martin and M\"{u}hlh\"{a}user, Max and Eghtebas, Chloe and Kunze, Kai},
title = {“Nah, it’s just annoying!” A Deep Dive into User Perceptions of Two-Factor Authentication},
year = {2022},
issue_date = {October 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {5},
issn = {1073-0516},
url = {https://doi.org/10.1145/3503514},
doi = {10.1145/3503514},
abstract = {Two-factor authentication (2FA) is a recommended or imposed authentication mechanism for valuable online assets. However, 2FA mechanisms usually exhibit user experience issues that create user friction and even lead to poor acceptance, hampering the wider spread of 2FA. In this article, we investigate user perceptions of 2FA through in-depth interviews with 42 participants, revealing key requirements that are not well met today despite recently emerged 2FA solutions. First, we investigate past experiences with authentication mechanisms emphasizing problems and aspects that hamper good user experience. Second, we investigate the different authentication factors more closely. Our results reveal particularly interesting preferences regarding the authentication factor “ownership” in terms of properties, physical realizations, and interaction. These findings suggest a path toward 2FA mechanisms with considerably better user experience, promising to improve the acceptance and hence, the proliferation of 2FA for the benefit of security in the digital world.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = oct,
articleno = {43},
numpages = {32},
keywords = {Two-factor authentication, human factors, usability, user experience},
tags = {Journal,CHI23}
}
@inproceedings{10.1145/3544548.3581436,
author = {Krings, Kevin and Bohn, Nino S. and Hille, Nora Anna Luise and Ludwig, Thomas},
title = {“What if everyone is able to program?” – Exploring the Role of Software Development in Science Fiction},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581436},
doi = {10.1145/3544548.3581436},
abstract = {For decades, research around emerging technologies has been inspired by science fiction and vice versa. While so far almost only the technologies themselves have been considered, we explore the underlying software development and programming approaches. We therefore conduct a detailed media content analysis of twenty-seven movies that examines the role of software development in science fiction by identifying and investigating new approaches to programming and how software development is conceptualized portrayed within science fiction scenes. With the additional analysis of eighteen design fiction stories exploring the scenario “What if everyone is able to program?”, we envision potential impacts of the democratization of software development on business and society. Our study opens new discussions and perspectives, by investigating the current vision of the future of programming and uncovers new approaches to software development which can serve as a starting point for further research in the HCI community.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {597},
numpages = {13},
keywords = {Content Analysis, Design Fiction, End-User Development (EUD), Science Fiction, Software Development},
location = {Hamburg, Germany},
series = {CHI '23},
tags={Full Paper,CHI23}
}
@inproceedings{10.1145/3544548.3581527,
author = {Engelbutzeder, Philip and Bollmann, Yannick and Berns, Katie and Landwehr, Marvin and Sch\"{a}fer, Franka and Randall, Dave and Wulf, Volker},
title = {(Re-)Distributional Food Justice: Negotiating conflicting views of fairness within a local grassroots community},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581527},
doi = {10.1145/3544548.3581527},
abstract = {Sustainable HCI and Human-Food-Interaction research have developing interest in preventing food waste through food sharing. Sustainability requires attention to both the opportunities and challenges associated with the building of food sharing groups engaged in the redistribution of food but also in developing a wider agenda which includes, for instance, the local production of food resources. In this paper, we argue for a better understanding of the different conceptions of ‘fairness’ which inform volunteer and guest practice and in turn mediate community-building efforts. We examine the practices surrounding ‘SharingEvent’ and challenges faced to sustainability by the heterogenous, and sometimes contested, commitments of the people involved. We further consider how ICT provided opportunities for explicit examination of ideological differences concerning what ‘sharing’ might mean. Our findings show that community building is dependent on the negotiation of different values and purposes identified. We derive recommendations for action-oriented researchers ultimately concerned with systemic transformation.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {136},
numpages = {16},
keywords = {Community, Fairness, Food Sharing, Grassroots, Justice, Surplus},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544548.3581163,
author = {Sergeeva, Anastasia and Rohles, Bj\"{o}rn and Distler, Verena and Koenig, Vincent},
title = {“We Need a Big Revolution in Email Advertising”: Users’ Perception of Persuasion in Permission-based Advertising Emails},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581163},
doi = {10.1145/3544548.3581163},
abstract = {Persuasive tactics intend to encourage users to open advertising emails. However, these tactics can overwhelm users, which makes them frustrated and leads to lower open rates. This paper intends to understand which persuasive tactics are used and how they are perceived by users. We first developed a categorization of inbox-level persuasive tactics in permission-based advertising emails. We then asked participants to interact with an email inbox prototype, combined with interviews (N=32), to investigate their opinions towards advertising emails and underlying persuasive tactics. Our qualitative findings reveal poor user experience with advertising emails, which was related to feeling surveilled by companies, forced subscription, high prior knowledge about persuasive tactics, and a desire for more agency. We also found that using certain persuasive tactics on the inbox level is perceived as ethically inappropriate. Based on these insights, we provide design recommendations to improve advertising communication and make such emails more valuable to users.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {652},
numpages = {21},
keywords = {Attitude, Email Advertising, Persuasion, Reactance Theory, Subject Line},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544549.3585884,
author = {Leusmann, Jan and Oechsner, Carl and Prinz, Johanna and Welsch, Robin and Mayer, Sven},
title = {A Database for Kitchen Objects: Investigating Danger Perception in the Context of Human-Robot Interaction},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585884},
doi = {10.1145/3544549.3585884},
abstract = {In the future, humans collaborating closely with cobots in everyday tasks will require handing each other objects. So far, researchers have optimized human-robot collaboration concerning measures such as trust, safety, and enjoyment. However, as the objects themselves influence these measures, we need to investigate how humans perceive the danger level of objects. Thus, we created a database of 153 kitchen objects and conducted an online survey (N=300) investigating their perceived danger level. We found that (1) humans perceive kitchen objects vastly differently, (2) the object-holder has a strong effect on the danger perception, and (3) prior user knowledge increases the perceived danger of robots handling those objects. This shows that future human-robot collaboration studies must investigate different objects for a holistic image. We contribute a wiki-like open-source database to allow others to study predefined danger scenarios and eventually build object-aware systems: https://hri-objects.leusmann.io/.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {6},
numpages = {9},
keywords = {bayesian mixed models, dataset, human-computer interaction, human-robot interaction, kitchen, robots},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Late Breaking Work,CHI23}
}
@inproceedings{10.1145/3544548.3581410,
author = {Herbert, Franziska and Becker, Steffen and Schaewitz, Leonie and Hielscher, Jonas and Kowalewski, Marvin and Sasse, Angela and Acar, Yasemin and D\"{u}rmuth, Markus},
title = {A World Full of Privacy and Security (Mis)conceptions? Findings of a Representative Survey in 12 Countries},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581410},
doi = {10.1145/3544548.3581410},
abstract = {Misconceptions about digital security and privacy topics in the general public frequently lead to insecure behavior. However, little is known about the prevalence and extent of such misconceptions in a global context. In this work, we present the results of the first large-scale survey of a global population on misconceptions: We conducted an online survey with n = 12, 351&nbsp;participants in 12&nbsp;countries on four continents. By investigating influencing factors of misconceptions around eight common security and privacy topics (including E2EE, Wi-Fi, VPN, and malware), we find the country of residence to be the strongest estimate for holding misconceptions. We also identify differences between non-Western and Western countries, demonstrating the need for region-specific research on user security knowledge, perceptions, and behavior. While we did not observe many outright misconceptions, we did identify a lack of understanding and uncertainty about several fundamental privacy and security topics.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {582},
numpages = {23},
keywords = {Co-variance Analysis, Human-Centered Security, Online Survey, Security Misconceptions},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {CHI23,Full Paper}
}
@inproceedings{10.1145/3544548.3580695,
author = {Mildner, Thomas and Savino, Gian-Luca and Doyle, Philip R. and Cowan, Benjamin R. and Malaka, Rainer},
title = {About Engaging and Governing Strategies: A Thematic Analysis of Dark Patterns in Social Networking Services},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580695},
doi = {10.1145/3544548.3580695},
abstract = {Research in HCI has shown a growing interest in unethical design practices across numerous domains, often referred to as “dark patterns”. There is, however, a gap in related literature regarding social networking services (SNSs). In this context, studies emphasise a lack of users’ self-determination regarding control over personal data and time spent on SNSs. We collected over 16 hours of screen recordings from Facebook’s, Instagram’s, TikTok’s, and Twitter’s mobile applications to understand how dark patterns manifest in these SNSs. For this task, we turned towards HCI experts to mitigate possible difficulties of non-expert participants in recognising dark patterns, as prior studies have noticed. Supported by the recordings, two authors of this paper conducted a thematic analysis based on previously described taxonomies, manually classifying the recorded material while delivering two key findings: We observed which instances occur in SNSs and identified two strategies — engaging and governing — with five dark patterns undiscovered before.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {192},
numpages = {15},
keywords = {SNS, dark patterns, ethical interfaces, interface design, social media, social networking services, well-being},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23,Honorable Mention}
}
@inproceedings{10.1145/3544548.3581504,
author = {Berger, Arne and Kurze, Albrecht and Bischof, Andreas and Benjamin, Jesse Josua and Wong, Richmond Y. and Merrill, Nick},
title = {Accidentally Evil: On Questionable Values in Smart Home Co-Design},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581504},
doi = {10.1145/3544548.3581504},
abstract = {An ongoing mystery of HCI is how do well-intentioned designers consistently enable products with unintentionally evil consequences. Using “questionable values” as a lens, we retell and analyze four design scenarios for smart homes that were created by participants with an IoT toolkit we designed. The selected design scenarios reveal practices that violate principles of responsible smart home design. Through our analysis we show (1) how participants explore sensor-driven objectification of the home then leverage data for surveillance, nudging, and control over others; (2) how the dominant technosolutionist narratives of efficiency and productivity ground such questionable values; (3) and how the materiality of mass-produced sensors pre-mediates questionable design scenarios. We discuss how to attend to and utilize questionable values in design: Making space for questionable values will empower design researchers to better “look around corners”, anticipating tomorrow's concerns and forestalling the worst of their harms.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {629},
numpages = {14},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {CHI23,Full Paper}
}
@inproceedings{10.1145/3544548.3581171,
author = {Aufheimer, Maria and Gerling, Kathrin and Graham, T.C. Nicholas and Naaris, Mari and Konings, Marco J. and Monbaliu, Elegast and Hallez, Hans and Ortibus, Els},
title = {An Examination of Motivation in Physical Therapy Through the Lens of Self-Determination Theory: Implications for Game Design},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581171},
doi = {10.1145/3544548.3581171},
abstract = {While it is widely assumed that games can engage patients in therapy through their inherent ‘motivational pull’, relatively little attention has been paid to what HCI games research can learn from strategies employed by therapists. We address this gap by leveraging Self-Determination Theory (SDT) and its mini-theories Basic Psychological Needs Theory and Organismic Integration Theory as a theoretical lens on physical therapy for children and adolescents. Results from in-depth interviews with twelve therapists show that they carefully adjust sessions to allow patients to experience competence, making more comprehensive adjustments than currently offered by games. Additionally, we highlight how therapists leverage their relationship with patients to support motivation, but struggle to reconcile meaningful experiences of autonomy with therapeutic goals. On this basis, we reflect on implications for researchers and designers who create games for physical therapy, and the potential of SDT to provide a foundation for game design and therapeutic practice.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {725},
numpages = {16},
keywords = {Games, Motivation, Physical Therapy, Rehabilitation, Self-Determination Theory},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,Honorable Mention,CHI23}
}
@inproceedings{10.1145/3544548.3581438,
author = {Hubenschmid, Sebastian and Zagermann, Johannes and Leicht, Daniel and Reiterer, Harald and Feuchtner, Tiare},
title = {ARound the Smartphone: Investigating the Effects of Virtually-Extended Display Size on Spatial Memory},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581438},
doi = {10.1145/3544548.3581438},
abstract = {Smartphones conveniently place large information spaces in the palms of our hands. While research has shown that larger screens positively affect spatial memory, workload, and user experience, smartphones remain fairly compact for the sake of device ergonomics and portability. Thus, we investigate the use of hybrid user interfaces to virtually increase the available display size by complementing the smartphone with an augmented reality head-worn display. We thereby combine the benefits of familiar touch interaction with the near-infinite visual display space afforded by augmented reality. To better understand the potential of virtually-extended displays and the possible issues of splitting the user’s visual attention between two screens (real and virtual), we conducted a within-subjects experiment with 24 participants completing navigation tasks using different virtually-augmented display sizes. Our findings reveal that a desktop monitor size represents a “sweet spot” for extending smartphones with augmented reality, informing the design of hybrid user interfaces.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {527},
numpages = {15},
keywords = {augmented reality, hybrid user interfaces, spatial memory},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544549.3585745,
author = {Schenkluhn, Marius and Peukert, Christian and Weinhardt, Christof},
title = {Augmented Reality-based Indoor Positioning for Smart Home Automations},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585745},
doi = {10.1145/3544549.3585745},
abstract = {Ambient Assisted Living (AAL) has been discussed for some time; however, many systems are not considered as interoperable or user-friendly. This fact is an even more important issue as every interaction is more costly in terms of time and effort for people with disabilities or senior citizens. Therefore, this paper examines the potential of automations that can substitute typical daily interactions in AAL or Smart Home settings in general based on the users’ location. Particularly, we suggest the novel approach of using the indoor positioning capabilities of Augmented Reality (AR) head-mounted displays (HMD) to detect, track, and identify residents for the purpose of automatically controlling various Internet of Things (IoT) devices in Smart Homes. An implementation of this feature on an off-the-shelf AR HMD without additional external trackers is demonstrated and the results of an initial feasibility study are presented.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {44},
numpages = {6},
keywords = {Augmented Reality, Indoor Positioning},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Late Breaking Work,CHI23}
}
@inproceedings{10.1145/3544549.3585822,
author = {Flegel, Nadine and Wessel, Daniel and P\"{o}hler, Jonas and Van Laerhoven, Kristof and Mentler, Tilo},
title = {Autonomy and Safety: A Quantitative Study with Control Room Operators on Affinity for Technology Interaction and Wish for Pervasive Computing Solutions},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585822},
doi = {10.1145/3544549.3585822},
abstract = {Control rooms are central to the well-being of many people. In terms of human computer interaction (HCI), they are characterized by complex IT infrastructures providing numerous graphical user interfaces. More modern approaches have been researched for decades. However, they are rarely used. What role does the attitude of operators towards novel solutions play? In one of the first quantitative cross-domain studies in safety-related HCI research (N = 155), we gained insight into affinity for technology interaction (ATI) and wish for pervasive computing solutions of operators in three domains (emergency response, public utilities, maritime traffic). Results show that ATI values were rather high, with broader range only in maritime traffic operators. Furthermore, the assessment of autonomy is more strongly related to the desire for novel solutions than perceived added safety value. These findings can provide guidance for the design of pervasive computing solutions, not only but especially for users in safety-critical contexts.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {48},
numpages = {10},
keywords = {Affinity for Technology Interaction, Autonomy, Control Room, Pervasive Computing, Safety},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Late Breaking Work,CHI23}
}
@inproceedings{10.1145/3544548.3580760,
author = {Jansen, Pascal and Britten, Julian and H\"{a}usele, Alexander and Segschneider, Thilo and Colley, Mark and Rukzio, Enrico},
title = {AutoVis: Enabling Mixed-Immersive Analysis of Automotive User Interface Interaction Studies},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580760},
doi = {10.1145/3544548.3580760},
abstract = {Automotive user interface (AUI) evaluation becomes increasingly complex due to novel interaction modalities, driving automation, heterogeneous data, and dynamic environmental contexts. Immersive analytics may enable efficient explorations of the resulting multilayered interplay between humans, vehicles, and the environment. However, no such tool exists for the automotive domain. With AutoVis, we address this gap by combining a non-immersive desktop with a virtual reality view enabling mixed-immersive analysis of AUIs. We identify design requirements based on an analysis of AUI research and domain expert interviews (N=5). AutoVis supports analyzing passenger behavior, physiology, spatial interaction, and events in a replicated study environment using avatars, trajectories, and heatmaps. We apply context portals and driving-path events as automotive-specific visualizations. To validate AutoVis against real-world analysis tasks, we implemented a prototype, conducted heuristic walkthroughs using authentic data from a case study and public datasets, and leveraged a real vehicle in the analysis process.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {378},
numpages = {23},
keywords = {Immersive analytics, automotive user interfaces, interaction analysis, virtual reality, visualization},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544549.3585864,
author = {Volkmann, Torben and Dresel, Markus and Jochems, Nicole},
title = {Balancing Power Relations in Participatory Design: The Importance of Initiative and External Factors},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585864},
doi = {10.1145/3544549.3585864},
abstract = {Power imbalances between users and designers impede the intent to equal contributions in a participatory process. Recent years have shown that unforeseen external factors pose a risk of exacerbating this power imbalance by limiting in-person meetings and communication in general. This study evaluated a projects’ power relations using a three-part reflection-on-action approach. Results show, that external factors can act as an actor in the power relationship model and that the change of initiative can change the power relations. Thus, we propose a power relation triangle for Participatory Design processes, including participants, designers and external conditions as actors and the decision-making at the center based on the combination of the actor’s relations. This framework can help to better understand and address power imbalances in Participatory Design.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {50},
numpages = {6},
keywords = {decision-making, gerontechnology, older adults, participatory design, power, user-collaboration},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Late Breaking Work,CHI23}
}
@inproceedings{10.1145/3544549.3585816,
author = {Doerr, Nina and Angerbauer, Katrin and Reinelt, Melissa and Sedlmair, Michael},
title = {Bees, Birds and Butterflies: Investigating the Influence of Distractors on Visual Attention Guidance Techniques},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585816},
doi = {10.1145/3544549.3585816},
abstract = {Visual attention guidance methods direct the viewer’s gaze in immersive environments by visually highlighting elements of interest. The highlighting can be done, for instance, by adding a colored circle around elements, adding animated swarms (HiveFive), or removing objects from one eye in a stereoscopic display (Deadeye). We contribute a controlled user experiment (N=30) comparing these three techniques under the influence of visual distractors, such as bees flying by. Our results show that Circle and HiveFive performed best in terms of task performance and qualitative feedback, and were largely robust against different levels of distractions. Furthermore, we discovered a high mental demand for Deadeye.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {51},
numpages = {7},
keywords = {attention guidance, perception, virtual reality, visual attention},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Late Breaking Work,CHI23}
}
@inproceedings{10.1145/3544549.3573801,
author = {Birk, Max V. and Van Der Hof, Simone and Hodent, Celia and Gerling, Kathrin and Van Rooij, Antonius J.},
title = {Behavioural Design in Video Games: Ethical, Legal, and Health Impact on Players},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3573801},
doi = {10.1145/3544549.3573801},
abstract = {Video games use behavioural design strategies, i.e., dark patterns, to increase engagement and drive revenue. These practices affect consumer behaviour, e.g., lead to extended playtime, and subsequently health, such as social well-being. HCI approaches such as motivational design or personalization are central to behavioural design strategies. Some approaches, e.g., in-game messages to guilt trip users, are ethically and legally questionable. In this workshop, we explore the ethical, health, and legal implications of behavioural design strategies. Our workshop aims to integrate interdisciplinary viewpoints, to co-develop a road map to address behavioural design, and collect contemporary perspectives on the issue. Participants will take away knowledge from different expert perspectives, concrete steps to address the impact of behavioural design, and a multidisciplinary expert network that will tackle existing and emerging future challenges.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {331},
numpages = {4},
keywords = {behavioural design, consumer health, video games},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Workshop,CHI23}
}
@inproceedings{10.1145/3544549.3573830,
author = {Boeva, Yana and Berger, Arne and Bischof, Andreas and Doggett, Olivia and Heuer, Hendrik and Jarke, Juliane and Treusch, Pat and S\o{}raa, Roger Andre and Tacheva, Zhasmina and Voigt, Maja-Lee},
title = {Behind the Scenes of Automation: Ghostly Care-Work, Maintenance, and Interferences: Exploring participatory practices and methods to uncover the ghostly presence of humans and human labor in automation},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3573830},
doi = {10.1145/3544549.3573830},
abstract = {Industry and media have long represented automation as a harbinger of development and convenience in different areas of life. An anxious prospect to some, automation systems promise “progress” and profitability to others by conjuring corporate computational futures. What remains behind the scenes of these predictions and imaginaries of automation is the invisible human labor of global ghost workers caring for, maintaining, and repairing technologies. Invisible but irreplaceable, computation performed by humans in precarious conditions fills gaps that computer technologies lack skills and sensibility for. In this hybrid workshop, we ask who the “ghosts” are in the machines. The workshop will address the ghostly presence of humans and human labor in automation and its challenges to HCI research and design.&nbsp;},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {332},
numpages = {5},
keywords = {Automation, Design Fiction, Ghost work, Labor},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Workshop,CHI23}
}
@inproceedings{10.1145/3544549.3585881,
author = {Kruse, Lucie and Wittig, Joel and Finnern, Sebastian and Gundlach, Melvin and Iserlohe, Niclas and Ariza, Oscar and Steinicke, Frank},
title = {Blended Collaboration: Communication and Cooperation Between Two Users Across the Reality-Virtuality Continuum},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585881},
doi = {10.1145/3544549.3585881},
abstract = {Mixed reality (MR) technologies provide enormous potential for collaboration between multiple users across the Reality–Virtuality continuum. We evaluate communication in a MR-based two-user collaboration task, in which the users have to move an object through an obstacle without collision. We used a blended reality environment, in which one user is immersed in virtual reality, whereas the other uses mobile augmented reality. Both users have different abilities and information and mutually depend on each other for successful completion of the task. Communication consensus can either be achieved by using speech, visual widgets, or a combination of both. The results indicate that speech plays a fundamental role. The usage of widgets served as an extension rather than a replacement of language. However, the combination of speech and widgets improved the clearness of communication with less miscommunication. These results provide important indications about how to design blended collaboration across the Reality–Virtuality continuum.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {54},
numpages = {8},
keywords = {3D interaction, augmented reality, collaboration, communication, cooperation, multi-user XR, virtual reality},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Late Breaking Work,CHI23}
}
@inproceedings{10.1145/3544548.3580844,
author = {Lang, Florian and Pues, Verena and Schmidt, Albrecht and Machulla, Tonja-Katrin},
title = {BrailleBuddy: A Tangible User Interface to Support Children with Visual Impairment in Learning Braille},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580844},
doi = {10.1145/3544548.3580844},
abstract = {Learning to read Braille is crucial to academic success for people with blindness or severe visual impairment. In our work, we investigate how we can support early learning of Braille with tangible computing. In a human-centered inclusive design process with interviews, six design iterations with prototypes, and feedback from experts, students, and teachers, we created BrailleBuddy. BrailleBuddy is a tangible user interface supporting children with visual impairments in learning Braille. We evaluated BrailleBuddy in a user study with children with blindness. Our results show that BrailleBuddy provides intrinsic motivation for learning Braille and can be used by children without supervision. BrailleBuddy complements the educational program as it allows children to play with and explore Braille characters at their own pace, thus lowering the challenge of learning to read Braille. In addition, an open-source toolkit is provided to enable educators and researchers to support individual requirements.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {218},
numpages = {14},
keywords = {Blind, Braille, Children, Learning, Low Vision, Tangible User Interface, Visual Impairment},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544548.3580756,
author = {Bezabih, Alemitu and Gerling, Kathrin and Abebe, Workeabeba and Vanden Abeele, Vero},
title = {Challenges and Opportunities for Interactive Technology to Support Parents of HIV-Positive Children in Ethiopia in the Disclosure Process},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580756},
doi = {10.1145/3544548.3580756},
abstract = {Fearing stigma, parents often hide their children's HIV diagnosis from them, and postpone disclosure, in turn negatively impacting children's well-being. Our work explores whether interactive technology can support disclosure. In the first study, we examine disclosure experiences and the role of interactive technology from the perspective of HIV-positive children and parents. Through Thematic Analysis, we highlight how disclosure is linked with parents’ own experience of HIV, and that disclosure needs to be viewed as a process. On this basis, we contribute an experience prototype that guides parents through an incremental disclosure process using interactive storytelling. In a second study, we evaluate the prototype through interviews with six parents. Leveraging Interpretative Phenomenological Analysis, we show that the prototype has potential to transform how parents understand and approach disclosure. Based on our results, we present further design directions, and discuss the (limitations of the) role that technology can play in this context.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {557},
numpages = {17},
keywords = {Ethiopia, HIV, children, interactive technology, ongoing disclosure, parents, storytelling},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {CHI23,Full Paper}
}
@inproceedings{10.1145/3544548.3581216,
author = {Stefanidi, Evropi and Sch\"{o}ning, Johannes and Rogers, Yvonne and Niess, Jasmin},
title = {Children with ADHD and their Care Ecosystem: Designing Beyond Symptoms},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581216},
doi = {10.1145/3544548.3581216},
abstract = {Designing for children with ADHD has been of increasing interest to the HCI community. However, current approaches do not adequately involve all relevant stakeholders, and primarily focus on addressing symptoms, following a medical model of disability that is extrinsic to neurodivergent interests. To address this, we employed a multi-step, multi-stakeholder approach (N=31). First, we conducted 1) interviews with children with ADHD and their care ecosystem followed by 2) a co-design pilot with one child with ADHD and his therapists and an interview with a UX designer and an occupational therapist. We then employed 3) co-design sessions with neurotypical children and children with ADHD, and 4) a focus group with their therapists. We identified communication and reflection as key concepts for empowering and promoting the well-being of children with ADHD and their care ecosystem. We contribute design implications for future systems aiming to promote the overall well-being of this population.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {558},
numpages = {17},
keywords = {ADHD, assistive technologies, children, co-design, empowerment, interviews, neurodivergent, neurodiversity, participatory design, reflection, well-being},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {CHI23,Full Paper}
}
@inproceedings{10.1145/3544548.3580969,
author = {Dang, Hai and Goller, Sven and Lehmann, Florian and Buschek, Daniel},
title = {Choice Over Control: How Users Write with Large Language Models using Diegetic and Non-Diegetic Prompting},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580969},
doi = {10.1145/3544548.3580969},
abstract = {We propose a conceptual perspective on prompts for Large Language Models (LLMs) that distinguishes between (1) diegetic prompts (part of the narrative, e.g. “Once upon a time, I saw a fox...”), and (2) non-diegetic prompts (external, e.g. “Write about the adventures of the fox.”). With this lens, we study how 129 crowd workers on Prolific write short texts with different user interfaces (1 vs 3 suggestions, with/out non-diegetic prompts; implemented with GPT-3): When the interface offered multiple suggestions and provided an option for non-diegetic prompting, participants preferred choosing from multiple suggestions over controlling them via non-diegetic prompts. When participants provided non-diegetic prompts it was to ask for inspiration, topics or facts. Single suggestions in particular were guided both with diegetic and non-diegetic information. This work informs human-AI interaction with generative models by revealing that (1) writing non-diegetic prompts requires effort, (2) people combine diegetic and non-diegetic prompting, and (3) they use their draft (i.e. diegetic information) and suggestion timing to strategically guide LLMs.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {408},
numpages = {17},
keywords = {Co-creative systems, Human-AI collaboration, Large language models, User-centric natural language generation},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {CHI23,Full Paper}
}
@inproceedings{10.1145/3544548.3581196,
author = {Jakesch, Maurice and Bhat, Advait and Buschek, Daniel and Zalmanson, Lior and Naaman, Mor},
title = {Co-Writing with Opinionated Language Models Affects Users’ Views},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581196},
doi = {10.1145/3544548.3581196},
abstract = {If large language models like GPT-3 preferably produce a particular point of view, they may influence people’s opinions on an unknown scale. This study investigates whether a language-model-powered writing assistant that generates some opinions more often than others impacts what users write – and what they think. In an online experiment, we asked participants (N=1,506) to write a post discussing whether social media is good for society. Treatment group participants used a language-model-powered writing assistant configured to argue that social media is good or bad for society. Participants then completed a social media attitude survey, and independent judges (N=500) evaluated the opinions expressed in their writing. Using the opinionated language model affected the opinions expressed in participants’ writing and shifted their opinions in the subsequent attitude survey. We discuss the wider implications of our results and argue that the opinions built into AI language technologies need to be monitored and engineered more carefully.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {111},
numpages = {15},
keywords = {Co-writing, GPT-3, opinion change, risks of large language models},
location = {Hamburg, Germany},
series = {CHI '23},
tags ={Full Paper,Honorable Mention,CHI23} 
}
@inproceedings{10.1145/3544548.3580879,
author = {Schr\"{o}der, Jan-Henrik and Schacht, Daniel and Peper, Niklas and Hamurculu, Anita Marie and Jetter, Hans-Christian},
title = {Collaborating Across Realities: Analytical Lenses for Understanding Dyadic Collaboration in Transitional Interfaces},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580879},
doi = {10.1145/3544548.3580879},
abstract = {Transitional Interfaces are a yet underexplored, emerging class of cross-reality user interfaces that enable users to freely move along the reality-virtuality continuum during collaboration. To analyze and understand how such collaboration unfolds, we propose four analytical lenses derived from an exploratory study of transitional collaboration with 15 dyads. While solving a complex spatial optimization task, participants could freely switch between three contexts, each with different displays (desktop screens, tablet-based augmented reality, head-mounted virtual reality), input techniques (mouse, touch, handheld controllers), and visual representations (monoscopic and allocentric 2D/3D maps, stereoscopic egocentric views). Using the rich qualitative and quantitative data from our study, we evaluated participants’ perceptions of transitional collaboration and identified commonalities and differences between dyads. We then derived four lenses including metrics and visualizations to analyze key aspects of transitional collaboration: (1) place and distance, (2) temporal patterns, (3) group use of contexts, (4) individual use of contexts.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {97},
numpages = {16},
keywords = {analytical lenses, transitional collaboration, transitional interfaces, user study},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Best Paper,Full Paper,CHI23}
}
@inproceedings{10.1145/3544548.3580871,
author = {Namnakani, Omar and Abdrabou, Yasmeen and Grizou, Jonathan and Esteves, Augusto and Khamis, Mohamed},
title = {Comparing Dwell time, Pursuits and Gaze Gestures for Gaze Interaction on Handheld Mobile Devices},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580871},
doi = {10.1145/3544548.3580871},
abstract = {Gaze is promising for hands-free interaction on mobile devices. However, it is not clear how gaze interaction methods compare to each other in mobile settings. This paper presents the first experiment in a mobile setting that compares three of the most commonly used gaze interaction methods: Dwell time, Pursuits, and Gaze gestures. In our study, 24 participants selected one of 2, 4, 9, 12 and 32 targets via gaze while sitting and while walking. Results show that input using Pursuits is faster than Dwell time and Gaze gestures especially when there are many targets. Users prefer Pursuits when stationary, but prefer Dwell time when walking. While selection using Gaze gestures is more demanding and slower when there are many targets, it is suitable for contexts where accuracy is more important than speed. We conclude with guidelines for the design of gaze interaction on handheld mobile devices.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {258},
numpages = {17},
keywords = {Eye Tracking, Gaze-based Interaction, Smartphones, Smooth pursuit, Tablets},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@article{10.1145/3579456,
author = {Haug, Saskia and Benke, Ivo and Maedche, Alexander},
title = {Aligning Crowdworker Perspectives and Feedback Outcomes in Crowd-Feedback System Design},
year = {2023},
issue_date = {April 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {CSCW1},
url = {https://doi.org/10.1145/3579456},
doi = {10.1145/3579456},
abstract = {Leveraging crowdsourcing in software development has received growing attention in research and practice. Crowd feedback offers a scalable and flexible way to evaluate software design solutions and the potential of crowd-feedback systems has been demonstrated in different contexts by existing research studies. However, previous research lacks a deep understanding of the effects of individual design features of crowd-feedback systems on feedback quality and quantity. Additionally, existing studies primarily focused on understanding the requirements of feedback requesters but have not fully explored the qualitative perspectives of crowd-based feedback providers. In this paper, we address these research gaps with two research studies. In study 1, we conducted a feature analysis (N=10) and concluded that from a user perspective, a crowd-feedback system should have five core features (scenario, speech-to-text, markers, categories, and star rating). In the second study, we analyzed the effects of the design features on crowdworkers' perceptions and feedback outcomes (N=210). We learned that offering feedback providers scenarios as the context of use is perceived as most important. Regarding the resulting feedback quality, we discovered that more features are not always better as overwhelming feedback providers might decrease feedback quality. Offering feedback providers categories as inspiration can increase the feedback quantity. With our work, we contribute to research on crowd-feedback systems by aligning crowdworker perspectives and feedback outcomes and thereby making the software evaluation not only more scalable but also more human-centered.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = apr,
articleno = {23},
numpages = {28},
keywords = {crowd-feedback system, crowdsourcing, design, experimental study, feedback, qualitative interviews},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544548.3580987,
author = {Rusu, Marius and Mayer, Sven},
title = {Deep Learning Super-Resolution Network Facilitating Fiducial Tangibles on Capacitive Touchscreens},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580987},
doi = {10.1145/3544548.3580987},
abstract = {Over the last few years, we have seen many approaches using tangibles to address the limited expressiveness of touchscreens. Mainstream tangible detection uses fiducial markers embedded in the tangibles. However, the coarse sensor size of capacitive touchscreens makes tangibles bulky, limiting their usefulness. We propose a novel deep-learning super-resolution network to facilitate fiducial tangibles on capacitive touchscreens better. In detail, our network super-resolves the markers enabling off-the-shelf detection algorithms to track tangibles reliably. Our network generalizes to unseen marker sets, such as AprilTag, ArUco, and ARToolKit. Therefore, we are not limited to a fixed number of distinguishable objects and do not require data collection and network training for new fiducial markers. With extensive evaluation, including real-world users and five showcases, we demonstrate the applicability of our open-source approach on commodity mobile devices and further highlight the potential of tangibles on capacitive touchscreens.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {199},
numpages = {16},
keywords = {capacitive touchscreen, deep learning, human-computer interaction, super resolution},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {CHI23,Full Paper}
}
@inproceedings{10.1145/3544549.3583891,
author = {B\"{u}schel, Wolfgang and Krug, Katja and Klamka, Konstantin and Dachselt, Raimund},
title = {Demonstrating CleAR Sight: Transparent Interaction Panels for Augmented Reality},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3583891},
doi = {10.1145/3544549.3583891},
abstract = {In this work, we demonstrate our concepts for transparent interaction panels in augmented-reality environments. Mobile devices can support interaction with head-mounted displays by providing additional input channels, such as touch \& pen input and spatial device input, and also an additional, personal display. However, occlusion of the physical context, other people, or the virtual content can be problematic. To address this, we previously introduced CleAR Sight, a concept and research platform for transparent interaction panels to support interaction in HMD-based mixed reality. Here, we will demonstrate the different interaction and visualization techniques supported in CleAR Sight that facilitate basic manipulation, data exploration, and sketching \& annotation for various use cases such as 3D volume visualization, collaborative data analysis, and smart home control.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {432},
numpages = {5},
keywords = {augmented reality, human-computer interaction, transparent displays, visualization},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Interactivity/Demonstration,CHI23}
}
@inproceedings{10.1145/3472749.3474807,
author = {Kovacs, Robert and Rambold, Lukas and Fritzsche, Lukas and Meier, Dominik and Shigeyama, Jotaro and Katakura, Shohei and Zhang, Ran and Baudisch, Patrick},
title = {Trusscillator: a System for Fabricating Human-Scale Human-Powered Oscillating Devices},
year = {2021},
isbn = {9781450386357},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3472749.3474807},
doi = {10.1145/3472749.3474807},
abstract = {Trusscillator is an end-to-end system that allows non-engineers to create human-scale human-powered devices that perform oscillatory movements, such as playground equipment, workout devices, and interactive kinetic installations. While recent research has been focusing on generating mechanisms that produce specific movement-path, without considering the required energy for the motion (kinematic approach), Trusscillator supports users in designing mechanisms that recycle energy in the system in the form of oscillating mechanisms (dynamic approach), specifically with the help of coil-springs. The presented system features a novel set of tools tailored for designing the dynamic experience of the motion. These tools allow designers to focus on user experience-specific aspects, such as motion range, tempo, and effort while abstracting away the underlying technicalities of eigenfrequencies, spring constants, and energy. Since the forces involved in the resulting devices can be high, Trusscillator helps users to fabricate from steel by picking out appropriate steal springs, generating part lists, and producing stencils and welding jigs that help weld with precision. To validate our system, we designed, built, and tested a series of unique playground equipment featuring 2-4 degrees of movement.},
booktitle = {The 34th Annual ACM Symposium on User Interface Software and Technology},
pages = {1074–1088},
numpages = {15},
keywords = {dynamics, mechanical oscillation, personal fabrication, welding},
location = {Virtual Event, USA},
series = {UIST '21},
tags = {Interactivity/Demonstration,CHI23}
}
@inproceedings{10.1145/3544549.3583916,
author = {Steimle, J\"{u}rgen and Muehlhaus, Marie and Nicolae, Madalina Luciana and Nittala, Aditya Shekhar and Pourjafarian, Narjes and Sharma, Adwait and Teyssier, Marc and Koelle, Marion and Fruchard, Bruno and Strohmeier, Paul},
title = {Design and Fabrication of Body-Based Interfaces (Demo of Saarland HCI Lab)},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3583916},
doi = {10.1145/3544549.3583916},
abstract = {This Interactivity shows live demonstrations of our lab’s most recent work on body-based interfaces. The soft, curved and deformable surface of the human body presents unique opportunities and challenges for interfaces. New form factors, materials and interaction techniques are required that move past the conventional rigid, planar and rectangular devices and the corresponding interaction styles. We highlight three themes of challenges for soft body-based interfaces: 1) How to design interfaces that are optimized for the body? We demonstrate how interactive computational design tools can help novices and experts to create better device designs. 2) Once they are designed, how to physically prototype and fabricate soft interfaces? We show accessible DIY fabrication methods for soft devices made of functional materials that make use of biomaterials. 3) How to leverage the richness of interacting on the body? We demonstrate on-body and off-body interactions that leverage the soft properties of the interface.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {446},
numpages = {4},
keywords = {On-body interaction, computational design, critical design., fabrication, new materials},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Interactivity/Demonstration,CHI23}
}
@inproceedings{10.1145/3544548.3581421,
author = {Wolf, Sara and Luthe, Simon and Baumeister, Lennart and Moerike, Frauke and Janakiraman, Vyjayanthi and Hurtienne, J\"{o}rn},
title = {Designing for Uncontrollability: Drawing Inspiration from the Blessing Companion},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581421},
doi = {10.1145/3544548.3581421},
abstract = {This paper presents an inspirational concept for companion technology design, uncontrollability, and a corresponding artefact, the Blessing Companion. Both originated from a research through design project exploring companion technologies for blessing rituals. We established an exchange with Protestant theologians, explored believers’ experiences of blessings, co-speculated on potential technologies, and refined the resulting ideas through ideation, prototyping, and testing. Inspired by believers’ descriptions of blessing experiences as not plannable, predictable, controllable, or enforceable, we adopted the concept of uncontrollability, explored how it might be implemented in companion technologies, and designed the Blessing Companion. The Blessing Companion embodies uncontrollability through its ambiguous appearance and (partly) uncontrollable behaviour. It thus stands in contrast to the prevailing on-demand and user-driven interaction paradigms. We discuss how uncontrollability can be reflected in content, form, and interaction, highlight respective possibilities for companion technologies, and reflect on the Blessing Companion as an example of designing for religious rituals.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {845},
numpages = {14},
keywords = {Research through design, companion technology, religion, ritual, techno-spirituality, transcendent experience},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544548.3581189,
author = {Wei\ss{}, Sebastian and Heuten, Wilko},
title = {Don’t Panic! - Influence of Virtual Stressor Representations from the ICU Context on Perceived Stress Levels},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581189},
doi = {10.1145/3544548.3581189},
abstract = {Intensive care nurses are prone to suffering from chronic stress due to constant exposure to two main profession-related stressors: interruption and time pressure. These stressors have detrimental effects on the well-being of the nursing staff and, by proxy, the patients. To alleviate stress, increase safety, and support the training of stressful scenarios, we investigate the impact these stressors have on subjective and objective stress levels in a virtual environment. We designed an intensive care unit in which participants (n=26, 18 healthcare professionals) perform common tasks, e.g. refilling an infusion pump, whilst being exposed to interruptions and time pressure. Results from our between-subjects study provide data indicating stress increase in both stressor conditions, suggesting that artificially evoking work-related stressors for stress inoculation training (SIT) is a possible extension to simulation training during nursing education. This knowledge is helpful for designing training scenarios of safety-critical situations early in the professional apprenticeship.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {642},
numpages = {15},
keywords = {Nursing, Stress, Virtual Reality},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544548.3581199,
author = {Albers, Ruben and Sadeghian, Shadan and Laschke, Matthias and Hassenzahl, Marc},
title = {Dying, Death, and the Afterlife in Human-Computer Interaction. A Scoping Review.},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581199},
doi = {10.1145/3544548.3581199},
abstract = {Dying is a universal experience that entails uncertainty, loss, and termination. Often, people face death unprepared and miss out on opportunities to shape their final stage of life as well as their afterlife. To better understand how thanato-technology can support the dying and the bereaved, we performed a scoping review on the current state-of-art in Human Computer Interaction. Following the PRISMA-ScR procedure, we gathered and analyzed 107 relevant papers. We categorized theoretical and conceptual contributions into three overarching themes: digital remains, remembrance, and coping. We further highlight 18 practices, such as curation, honoring and letting go. We show that technology can help to capture the identity of the deceased, to validate the life lived, and to come to terms with death. However, available approaches focus more on the bereaved than on the dying. In addition, potentially important aspects of dying (e.g., balancing involvement and autonomy, spiritual meaning-making) remain largely unexplored.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {302},
numpages = {16},
keywords = {death, dying, end of life, scoping review, thanatosensitivity},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544548.3580824,
author = {Huber, Stephan and Rath\ss{}, Natalie},
title = {Empathic Accuracy and Mental Effort During Remote Assessments of Emotions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580824},
doi = {10.1145/3544548.3580824},
abstract = {Observing users in remote settings is unfavorable because it adds filters altering the information that underlie judgement. Still, the COVID pandemic led to an unprecedented popularity of remote user experience tests. In this work, we revisited the question, which information is most important for evaluators to assess users’ emotions successfully and efficiently. In an online study, we asked N=55 participants to assess users’ emotions from short videos of 30 interaction situations. As independent variable, we manipulated the combination of the information channels video of users, video of the interactive technology, and audio within subjects. Our findings indicate that empathic accuracy is highest and mental effort is lowest when all stimuli are present. Surprisingly, empathic accuracy was lowest and mental effort highest, when only video of users was available. We discuss these findings in the light of emotion literature focusing on persons’ facial expressions and derive practical implications for remote observations.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {63},
numpages = {13},
keywords = {Remote user research, emotion, empathy, meta-evaluation, observations},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544549.3585855,
author = {Sch\"{a}fer, Ren\'{e} and Wagner, Tobias and Lavnikevich, Ulyana and Borchers, Jan},
title = {Enhancing Notification Awareness for Online Presenters via a Wrist-Worn Device},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585855},
doi = {10.1145/3544549.3585855},
abstract = {The practice of giving presentations online has exploded during the Covid pandemic. However, in these settings, presenters often find themselves overlooking questions and feedback, e.g. via chat, from the audience, because the presenter’s screen is dominated by their slides, with other channels becoming less noticeable. This causes frustration among presenters and their audience alike. We investigate the impact of additional visual, auditory, and haptic cues for presenters in online scenarios, using a wrist-worn prototype. For this, we conducted a study where participants gave presentations via the videoconferencing tool Zoom on specific topics while trying to notice and correctly identify incoming notifications. Our findings indicate that supplementary notifications can be helpful in online presentations without inappropriately disturbing the presenter.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {103},
numpages = {6},
keywords = {Audience Feedback, Interaction Modalities, Notification Awareness, Online Presenters, Peripheral Recognition, Wrist-Worn},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {CHI23}
}
@inproceedings{10.1145/3544549.3585842,
author = {Wagner, Tobias and Hirzle, Teresa and Huckauf, Anke and Rukzio, Enrico},
title = {Exploring Gesture and Gaze Proxies to Communicate Instructor’s Nonverbal Cues in Lecture Videos},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585842},
doi = {10.1145/3544549.3585842},
abstract = {Teaching via lecture video has become the defacto standard for remote education, but videos make it difficult to interpret instructors’ nonverbal referencing to the content. This is problematic, as nonverbal cues are essential for students to follow and understand a lecture. As remedy, we explored different proxies representing instructors’ pointing gestures and gaze to provide students a point of reference in a lecture video: no proxy, gesture proxy, gaze proxy, alternating proxy, and concurrent proxies. In an online study with 100 students, we evaluated the proxies’ effects on mental effort, cognitive load, learning performance, and user experience. Our results show that the proxies had no significant effect on learning-directed aspects and that the gesture and alternating proxy achieved the highest pragmatic quality. Furthermore, we found that alternating between proxies is a promising approach providing students with information about instructors’ pointing and gaze position in a lecture video.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {113},
numpages = {7},
keywords = {Education, Eye-tracking, Gaze, Gesture, Lecture video},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Late Breaking Work,CHI23}
}
@inproceedings{10.1145/3544549.3585742,
author = {Katins, Christopher and Feger, Sebastian S. and Kosch, Thomas},
title = {Exploring Mixed Reality in General Aviation to Support Pilot Workload},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585742},
doi = {10.1145/3544549.3585742},
abstract = {Pilots in non-commercial aviation have minimal access to digital support tools. Equipping aircraft with modern technologies introduces high costs and is labor intensive. Hence, wearable or mobile support, such as common 2D maps displayed on standard tablets, is often the only digital information source used by pilots. Yet, they fail to adequately capture the 3D airspace and its surroundings, challenging the pilot’s workload. This work explores how mixed reality can support pilots by projecting supportive elements into their fields of view. Considering the design of a preliminary mixed reality prototype, we conducted a user study with twelve pilots in a full-sized flight simulator. Our measures show that the prototype positively influenced the participants’ situational awareness and overall landing routine efficiency, who also had generally favorable views regarding mixed reality in the cockpit. This work shows the utility of mixed reality technologies while emphasizing future research directions in general aviation.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {116},
numpages = {7},
keywords = {Augmented Reality, General Aviation, Highlighting, Mixed Reality, Situational Awareness, Workload},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Late Breaking Work,CHI23}
}
@inproceedings{10.1145/3544549.3585661,
author = {Schwarzer, Jan and Fietkau, Julian and Fuchs, Laurenz and Draheim, Susanne and Von Luck, Kai and Koch, Michael},
title = {Exploring Mobility Behavior Around Ambient Displays Using Clusters of Multi-dimensional Walking Trajectories},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585661},
doi = {10.1145/3544549.3585661},
abstract = {Spatial information has become crucial in ambient display research and helps to better understand how people behave in a display’s vicinity. Walking trajectories have long been used to uncover such information and tools have been developed to capture them anonymously and automatically. However, more research is needed on the level of automation during mobility behavior analyses. Particularly, working with depth-based skeletal data still requires significant manual effort to, for instance, determine walking trajectories similar in shape. To advance on this situation, we adopt both agglomerative hierarchical clustering and dynamic time warping in this research. To the best of our knowledge, both algorithms have so far not found application in our field. Using a multi-dimensional data set obtained from a longitudinal, real-world deployment, we demonstrate here the applicability and usefulness of this approach. In doing so, we contribute insightful ideas for future discussions on the methodological development in ambient display research.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {117},
numpages = {6},
keywords = {Ambient displays, agglomerative hierarchical clustering, dynamic time warping, mobility behavior, walking trajectories},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Late Breaking Work,CHI23}
}
@inproceedings{10.1145/3544549.3585624,
author = {Chiossi, Francesco and Ou, Changkun and Mayer, Sven},
title = {Exploring Physiological Correlates of Visual Complexity Adaptation: Insights from EDA, ECG, and EEG Data for Adaptation Evaluation in VR Adaptive Systems},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585624},
doi = {10.1145/3544549.3585624},
abstract = {Physiologically-adaptive Virtual Reality can drive interactions and adjust virtual content to better fit users’ needs and support specific goals. However, the complexity of psychophysiological inference hinders efficient adaptation as the relationship between cognitive and physiological features rarely show one-to-one correspondence. Therefore, it is necessary to employ multimodal approaches to evaluate the effect of adaptations. In this work, we analyzed a multimodal dataset (EEG, ECG, and EDA) acquired during interaction with a VR-adaptive system that employed EDA as input for adaptation of secondary task difficulty. We evaluated the effect of dynamic adjustments on different physiological features and their correlation. Our results show that when the adaptive system increased the secondary task difficulty, theta, beta, and phasic EDA features increased. Moreover, we found a high correlation between theta, alpha, and beta oscillations during difficulty adjustments. Our results show how specific EEG and EDA features can be employed for evaluating VR adaptive systems.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {118},
numpages = {7},
keywords = {Adaptive Systems, Physiological Computing, Virtual Reality},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags ={Late Breaking Work,CHI23}
}
@inproceedings{10.1145/3544548.3581223,
author = {Weiss, Yannick and Villa, Steeven and Schmidt, Albrecht and Mayer, Sven and M\"{u}ller, Florian},
title = {Using Pseudo-Stiffness to Enrich the Haptic Experience in Virtual Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581223},
doi = {10.1145/3544548.3581223},
abstract = {Providing users with a haptic sensation of the hardness and softness of objects in virtual reality is an open challenge. While physical props and haptic devices help, their haptic properties do not allow for dynamic adjustments. To overcome this limitation, we present a novel technique for changing the perceived stiffness of objects based on a visuo-haptic illusion. We achieved this by manipulating the hands’ Control-to-Display (C/D) ratio in virtual reality while pressing down on an object with fixed stiffness. In the first study (N=12), we determine the detection thresholds of the illusion. Our results show that we can exploit a C/D ratio from 0.7 to 3.5 without user detection. In the second study (N=12), we analyze the illusion’s impact on the perceived stiffness. Our results show that participants perceive the objects to be up to 28.1\% softer and 8.9\% stiffer, allowing for various haptic applications in virtual reality.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {388},
numpages = {15},
keywords = {haptic illusions, pseudo-haptics, virtual reality},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544549.3585606,
author = {Brocker, Anke and Nedorubkova, Ekaterina and Voelker, Simon and Borchers, Jan},
title = {Exploring Shape Designs for Soft Robotics and Users’ Associations with Them},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585606},
doi = {10.1145/3544549.3585606},
abstract = {Soft robotics provides flexible structures and materials that move in natural and organic ways. They facilitate creating safe and tolerant mechanisms for human–machine interaction. This makes soft robotics attractive for tasks that rigid robots are unable to carry out. Users may also display a higher acceptance of soft robots compared to rigid robots because their natural way of movement helps users to relate to scenarios they know from everyday life, making the interaction with the soft robot feel more intuitive. However, the variety of soft robotics shape designs, and how to integrate them into applications, have not been explored fully yet. In a user study, we investigated users’ associations and ideas for application areas for 36 soft robotics shape designs, brainstormed with users beforehand. We derived first design recommendations for soft robotics designs such as clear signifiers indicating the possible motion.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {120},
numpages = {7},
keywords = {Human Associations, Movement Effects, Shape Design, Soft Robotics, Soft Robotics Application},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Late Breaking Work,CHI23}
}
@inproceedings{10.1145/3544549.3585674,
author = {Clavelin, Ga\"{e}lle and Bouhier, Mickael and Tseng, Wen-Jie and Gugenheimer, Jan},
title = {Exploring the Perception of Pain in Virtual Reality through Perceptual Manipulations},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585674},
doi = {10.1145/3544549.3585674},
abstract = {Perceptual manipulations (PMs) in Virtual Reality (VR) can steer users’ actions (e.g., redirection techniques) and amplify haptic perceptions (e.g., weight). However, their ability to amplify or induce negative perceptions such as physical pain is not well understood. In this work, we explore if PMs can be leveraged to induce the perception of pain, without modifying the physical stimulus. We implemented a VR experience combined with a haptic prototype, simulating the dislocation of a finger. A user study (n=18) compared three conditions (visual-only, haptic-only and combined) on the perception of physical pain and physical discomfort. We observed that using PMs with a haptic device resulted in a significantly higher perception of physical discomfort and an increase in the perception of pain compared to the unmodified sensation (haptic-only). Finally, we discuss how perception of pain can be leveraged in future VR applications and reflect on ethical concerns.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {126},
numpages = {7},
keywords = {Haptic Devices, Perceptual Manipulations, Virtual Reality},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Late Breaking Work,CHI23}
}
@inproceedings{10.1145/3544549.3585703,
author = {Mecke, Lukas and Prieto Romero, Ismael and Delgado Rodriguez, Sarah and Alt, Florian},
title = {Exploring the Use of Electromagnets to Influence Key Targeting on Physical Keyboards},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585703},
doi = {10.1145/3544549.3585703},
abstract = {In this work, we explore the use of force induced through electromagnets to influence finger movement while using a keyboard. To achieve this we generate a magnetic field below a keyboard and place a permanent magnet on the user’s finger as a minimally invasive approach to dynamically induce variable force. Contrary to other approaches our setup can thus generate forces even at a distance from the keyboard. We explore this concept by building a prototype and analyzing different configurations of electromagnets (i.e., attraction and repulsion) and placements of a permanent magnet on the user’s fingers in a preliminary study (N=4). Our force measurements show that we can induce 3.56&nbsp;N at a distance of 10&nbsp;mm. Placing the magnet on the index finger allowed for influencing key press times and was perceived as comfortable. Finally, we discuss implications and potential application areas like mid-air feedback and guidance.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {128},
numpages = {8},
keywords = {electromagnets, keyboards, output, typing},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Late Breaking Work,CHI23}
}
@inproceedings{10.1145/3544549.3585799,
author = {Meinhardt, Luca-Maxim and Van Laerhoven, Kristof and Dobbelstein, David},
title = {EyesOnMe: Investigating Haptic and Visual User Guidance for Near-Eye Positioning of Mobile Phones for Self-Eye-Examinations},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585799},
doi = {10.1145/3544549.3585799},
abstract = {The scarcity of professional ophthalmic equipment in rural areas and during exceptional situations such as the COVID-19 pandemic highlights the need for tele-ophthalmology. This late-breaking work presents a novel method for guiding users to a specific pose (3D position and 3D orientation) near the eye for mobile self-eye examinations using a smartphone. The user guidance is implemented utilizing haptic and visual modalities to guide the user and subsequently capture a close-up photo of the user’s eyes. In a within-subject user study (n=24), the required time, success rate, and perceived demand for the visual and haptic feedback conditions were examined. The results indicate that haptic feedback was the most efficient and least cognitively demanding in the positioning task near the eye, whereas relying on only visual feedback can be more difficult due to the near focus point or refractive errors.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {133},
numpages = {10},
keywords = {mobile self-ophthalmology, near-eye positioning, smartphone, user guidance},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Late Breaking Work,CHI23}
}
@inproceedings{10.1145/3544549.3585854,
author = {Wagner, Adrian and Preuschoff, Paul Miles and Wacker, Philipp and Voelker, Simon and Borchers, Jan},
title = {FabricFaces: Combining Textiles and 3D Printing for Maker-Friendly Folding-Based Assembly},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585854},
doi = {10.1145/3544549.3585854},
abstract = {We introduce a Personal Fabrication workflow to easily create feature-rich 3D objects with textile-covered surfaces. Our approach unfolds a 3D model into a series of flat frames with connectors, which are then 3D-printed onto a piece of fabric, and folded manually into the shape of the original model. This opens up an accessible way to incorporate established 2D textile workflows, such as embroidery, using color patterns, and combining different fabrics, when creating 3D objects. FabricFaces objects can also be flattened again easily for transport and storage. We provide an open-source plugin for the common 3D tool Blender. It enables a one-click workflow to turn a user-provided model into 3D printer instructions, textile cut patterns, and connector support. Generated frames can be refined quickly and iteratively through previews and extensive options for manual intervention. We present example objects illustrating a variety of use cases.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {135},
numpages = {7},
keywords = {3D Printing, Fabrication, Textiles},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Late Breaking Work,CHI23}
}
@inproceedings{10.1145/3544548.3580993,
author = {W\"{u}rsching, Leon and Putz, Florentin and Haesler, Steffen and Hollick, Matthias},
title = {FIDO2 the Rescue? Platform vs. Roaming Authentication on Smartphones},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580993},
doi = {10.1145/3544548.3580993},
abstract = {Modern smartphones support FIDO2 passwordless authentication using either external security keys or internal biometric authentication, but it is unclear whether users appreciate and accept these new forms of web authentication for their own accounts. We present the first lab study (N=87) comparing platform and roaming authentication on smartphones, determining the practical strengths and weaknesses of FIDO2 as perceived by users in a mobile scenario. Most participants were willing to adopt passwordless authentication during our in-person user study, but closer analysis shows that participants prioritize usability, security, and availability differently depending on the account type. We identify remaining adoption barriers that prevent FIDO2 from succeeding password authentication, such as missing support for contemporary usage patterns, including account delegation and usage on multiple clients.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {68},
numpages = {16},
keywords = {Accounts, Biometrics, Passwordless, Security, Usability, User Authentication},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Best Paper,Full Paper,CHI23} 
}
@inproceedings{10.1145/3544548.3580736,
author = {Tseng, Wen-Jie and Huron, Samuel and Lecolinet, Eric and Gugenheimer, Jan},
title = {FingerMapper: Mapping Finger Motions onto Virtual Arms to Enable Safe Virtual Reality Interaction in Confined Spaces},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580736},
doi = {10.1145/3544548.3580736},
abstract = {Whole-body movements enhance the presence and enjoyment of Virtual Reality (VR) experiences. However, using large gestures is often uncomfortable and impossible in confined spaces (e.g., public transport). We introduce FingerMapper, mapping small-scale finger motions onto virtual arms and hands to enable whole-body virtual movements in VR. In a first target selection study (n=13) comparing FingerMapper to hand tracking and ray-casting, we found that FingerMapper can significantly reduce physical motions and fatigue while having a similar degree of precision. In a consecutive study (n=13), we compared FingerMapper to hand tracking inside a confined space (the front passenger seat of a car). The results showed participants had significantly higher perceived safety and fewer collisions with FingerMapper while preserving a similar degree of presence and enjoyment as hand tracking. Finally, we present three example applications demonstrating how FingerMapper could be applied for locomotion and interaction for VR in confined spaces.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {874},
numpages = {14},
keywords = {Body Re-Association in VR, Confined Spaces, FingerMapper},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@article{10.1145/3533015,
author = {Brocker, Anke and Sch\"{a}fer, Ren\'{e} and Remy, Christian and Voelker, Simon and Borchers, Jan},
title = {Flowboard: How Seamless, Live, Flow-Based Programming Impacts Learning to Code for Embedded Electronics},
year = {2023},
issue_date = {February 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {1},
issn = {1073-0516},
url = {https://doi.org/10.1145/3533015},
doi = {10.1145/3533015},
abstract = {Toolkits like the Arduino system have brought embedded programming to STEM education. However, learning embedded programming is still hard, requiring an understanding of coding, electronics, and how both sides interact. To investigate the opportunities of using a different programming paradigm than the imperative approach to learning embedded coding, we developed Flowboard. Students code in a visual iPad editor using flow-based programming, which is conceptually closer to circuit diagrams than imperative code. Two breadboards with I/O pins mirrored on the iPad connect electronics and program graph more seamlessly than existing IDEs. Program changes take effect immediately. This liveness reflects circuit behavior better than edit-compile-run loops. A first study confirmed that students can solve basic embedded programming tasks with Flowboard while highlighting important differences to a typical imperative IDE, Ardublock. A second, in-depth study provided qualitative insights into Flowboard’s impact on students’ conceptual models of electronics and embedded programming and exploring.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = mar,
articleno = {2},
numpages = {36},
keywords = {Embedded development environments, visual flow-based programming, Arduino, electronics, young learners, learning tools},
tags = {Journal,CHI23}
}
@inproceedings{10.1145/3544548.3581259,
author = {Rasch, Julian and Rusakov, Vladislav Dmitrievic and Schmitz, Martin and M\"{u}ller, Florian},
title = {Going, Going, Gone: Exploring Intention Communication for Multi-User Locomotion in Virtual Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581259},
doi = {10.1145/3544548.3581259},
abstract = {Exploring virtual worlds together with others adds a social component to the Virtual Reality (VR) experience that increases connectedness. In the physical world, joint locomotion comes naturally through implicit intention communication and subsequent adjustments of the movement patterns. In VR, however, discrete locomotion techniques such as point&teleport come without prior intention communication, hampering the collective experience. Related work proposes fixed groups, with a single person controlling the group movement, resulting in the loss of individual movement capabilities. To close the gap and mediate between these two extremes, we introduce three intention communication methods and explore them with two baseline methods. We contribute the results of a controlled experiment (n=20) investigating these methods from the perspective of a leader and a follower in a dyadic locomotion task. Our results suggest shared visualizations support the understanding of movement intentions, increasing the group feeling while maintaining individual freedom of movement.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {785},
numpages = {13},
keywords = {Connectedness, Locomotion, Multi-User, SocialVR, Teleportation, Virtual Reality},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Best Paper,Full Paper,CHI23}
}
@inproceedings{10.1145/3544548.3580713,
author = {Parayno, Richard Lance and Deja, Janna Aika and Sta. Maria, Tyrone Justin and Samson, Briane Paul V. and Deja, Jordan Aiko},
title = {Good Day Manager! Exploring Social Relationships in NFT-based Play-to-Earn Games},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580713},
doi = {10.1145/3544548.3580713},
abstract = {Play-to-Earn (P2E) crypto-games recently emerged as a gig opportunity despite the absence of regulations. As these platforms continue to grow, there is a need to understand the interactions involved to protect vulnerable stakeholders. This paper describes how an unintended social dynamic became a strategy guiding players to navigate an unregulated space. First, we inquired through surveys (N = 69) and interviews (N = 9) to understand stakeholder motivations and practices in this space. Second, we analyzed data and then conceptualized eight themes (e.g., Management, Social, Gaming). Then, we uncovered four types of relationships (e.g., Manager-Scholar, Manager-Investor-Scholar, Coach-Mentee, Scholar-Turned-Manager) that shaped the behaviours of the different users on the platform. Lastly, we present design implications and recommendations to guide the design of P2E crypto games and the gig-focused communities that thrive around them. Our results contribute to ongoing discussions in designing digital gig economies and crypto-based games.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {206},
numpages = {11},
keywords = {Axie, NFT, cryptocurrency, perceptions, wallets},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544548.3580691,
author = {Pourjafarian, Narjes and Mjaku, Fjolla and Koelle, Marion and Schmitz, Martin and Borchers, Jan and Steimle, J\"{u}rgen},
title = {Handheld Tools Unleashed: Mixed-Initiative Physical Sketching with a Robotic Printer},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580691},
doi = {10.1145/3544548.3580691},
abstract = {Personal fabrication has mostly focused on handheld tools as embodied extensions of the user, and machines like laser cutters and 3D printers automating parts of the process without intervention. Although interactive digital fabrication has been explored as a middle ground, existing systems have a fixed allocation of user intervention vs. machine autonomy, limiting flexibility, creativity, and improvisation. We explore a new class of devices that combine the desirable properties of a handheld tool and an autonomous fabrication robot, offering a continuum from manual and assisted to autonomous fabrication, with seamless mode transitions. We exemplify the concept of mixed-initiative physical sketching with a working robotic printer that can be handheld for free-hand sketching, can provide interactive assistance during sketching, or move about for computer-generated sketches. We present interaction techniques to seamlessly transition between modes, and sketching techniques benefitting from these transitions to, e.g., extend (upscale, repeat) or revisit (refine, color) sketches. Our evaluation with seven sketchers illustrates that RoboSketch successfully leverages each mode’s strengths, and that mixed-initiative physical sketching makes computer-supported sketching more flexible.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {734},
numpages = {14},
keywords = {Sketching, fabrication, mixed-initiative fabrication, prototyping, robotic printer, sketching interfaces},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544548.3580716,
author = {Sabnis, Nihar and Wittchen, Dennis and Reed, Courtney N. and Pourjafarian, Narjes and Steimle, J\"{u}rgen and Strohmeier, Paul},
title = {Haptic Servos: Self-Contained Vibrotactile Rendering System for Creating or Augmenting Material Experiences},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580716},
doi = {10.1145/3544548.3580716},
abstract = {When vibrations are synchronized with our actions, we experience them as material properties. This has been used to create virtual experiences like friction, counter-force, compliance, or torsion. Implementing such experiences is non-trivial, requiring high temporal resolution in sensing, high fidelity tactile output, and low latency. To make this style of haptic feedback more accessible to non-domain experts, we present Haptic Servos: self-contained haptic rendering devices which encapsulate all timing-critical elements. We characterize Haptic Servos’ real-time performance, showing the system latency is <5&nbsp;ms. We explore the subjective experiences they can evoke, highlighting that qualitatively distinct experiences can be created based on input mapping, even if stimulation parameters and algorithm remain unchanged. A workshop demonstrated that users new to Haptic Servos require approximately ten minutes to set up a basic haptic rendering system. Haptic Servos are open source, we invite others to copy and modify our design.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {522},
numpages = {17},
keywords = {haptic feedback, haptic rendering, material experiences, prototyping, toolkit},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,Honorable Mention,CHI23} 
}
@inproceedings{10.1145/3544549.3585601,
author = {Pascher, Max and Franzen, Til and Kronhardt, Kirill and Gruenefeld, Uwe and Schneegass, Stefan and Gerken, Jens},
title = {HaptiX: Vibrotactile Haptic Feedback for Communication of 3D Directional Cues},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585601},
doi = {10.1145/3544549.3585601},
abstract = {In Human-Computer-Interaction, vibrotactile haptic feedback offers the advantage of being independent of any visual perception of the environment. Most importantly, the user’s field of view is not obscured by user interface elements, and the visual sense is not unnecessarily strained. This is especially advantageous when the visual channel is already busy, or the visual sense is limited. We developed three design variants based on different vibrotactile illusions to communicate 3D directional cues. In particular, we explored two variants based on the vibrotactile illusion of the cutaneous rabbit and one based on apparent vibrotactile motion. To communicate gradient information, we combined these with pulse-based and intensity-based mapping. A subsequent study showed that the pulse-based variants based on the vibrotactile illusion of the cutaneous rabbit are suitable for communicating both directional and gradient characteristics. The results further show that a representation of 3D directions via vibrations can be effective and beneficial.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {154},
numpages = {7},
keywords = {directional cues, haptic feedback, vibrotactile feedback},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Late Breaking Work,CHI23}
}
@inproceedings{10.1145/3544548.3580968,
author = {Krath, Jeanine and Altmeyer, Maximilian and Tondello, Gustavo F. and Nacke, Lennart E.},
title = {Hexad-12: Developing and Validating a Short Version of the Gamification User Types Hexad Scale},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580968},
doi = {10.1145/3544548.3580968},
abstract = {The Hexad scale is a crucial tool for personalized gamification in user experience (UX) design. However, completing a 24-item questionnaire can increase dropout rates and screen fatigue within online surveys. When included in larger surveys, scale brevity makes a difference. To reduce the time required for the assessment process, we developed and validated a 12-item version of the Hexad scale. To create it, we carried out an exploratory factor analysis on an existing data set to identify appropriate items (n = 882). To validate the 12-item version, we conducted a confirmatory factor analysis on a new data set (n = 1, 101). Our results show that Hexad-12 outperforms the original Hexad scale regarding model fit, reliability, convergent, and discriminant validity. Therefore, Hexad-12 resolves issues found in studies using the original Hexad scale and provides a suitable and swift instrument for concisely assessing Hexad user types in tailored gamification design.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {677},
numpages = {18},
keywords = {Adaptive Gamification, Gamification, Hexad, Personalization, Player Types, Tailored Gamification, User Types},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544548.3580857,
author = {Pascher, Max and Gruenefeld, Uwe and Schneegass, Stefan and Gerken, Jens},
title = {How to Communicate Robot Motion Intent: A Scoping Review},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580857},
doi = {10.1145/3544548.3580857},
abstract = {Robots are becoming increasingly omnipresent in our daily lives, supporting us and carrying out autonomous tasks. In Human-Robot Interaction, human actors benefit from understanding the robot’s motion intent to avoid task failures and foster collaboration. Finding effective ways to communicate this intent to users has recently received increased research interest. However, no common language has been established to systematize robot motion intent. This work presents a scoping review aimed at unifying existing knowledge. Based on our analysis, we present an intent communication model that depicts the relationship between robot and human through different intent dimensions (intent type, intent information, intent location). We discuss these different intent dimensions and their interrelationships with different kinds of robots and human roles. Throughout our analysis, we classify the existing research literature along our intent communication model, allowing us to identify key patterns and possible directions for future research.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {409},
numpages = {17},
keywords = {cobot, drone, intent, motion, robot, survey},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544548.3581184,
author = {Muehlhaus, Marie and Koelle, Marion and Saberpour, Artin and Steimle, J\"{u}rgen},
title = {I Need a Third Arm! Eliciting Body-based Interactions with a Wearable Robotic Arm},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581184},
doi = {10.1145/3544548.3581184},
abstract = {Wearable robotic arms (WRA) open up a unique interaction space that closely integrates the user’s body with an embodied robotic collaborator. This space affords diverse interaction styles, including body movement, hand gestures, or gaze. Yet, it is so-far unexplored which commands are desirable from a user perspective. Contributing findings from an elicitation study (N=14), we provide a comprehensive set of interactions for basic robot control, navigation, object manipulation, and emergency situations, performed when hands are free or occupied. Our study provides insights into preferred body parts, input modalities, and the users’ underlying sources of inspiration. Comparing interaction styles between WRAs and off-body robots, we highlight how WRAs enable a range of interactions specific for on-body robots and how users use WRAs both as tools and as collaborators. We conclude by providing guidance on the design of ad-hoc interaction with WRAs informed by user behavior.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {255},
numpages = {15},
keywords = {Wearable robotic arms, artificial limbs, augmented arms, elicitation study., gesture, human-robot interaction, supernumerary limbs},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {CHI23,Full Paper}
}
@inproceedings{10.1145/3544549.3585675,
author = {Nolte, Amelie and Glei\ss{}l, Barbara and Heckmann, Jule and Wallach, Dieter and Jochems, Nicole},
title = {"I Want To Be Able To Change The Speed And Size Of The Avatar": Assessing User Requirements For Animated Sign Language Translation Interfaces},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585675},
doi = {10.1145/3544549.3585675},
abstract = {Despite research having shown that signing users vary in their preferences and needs of distinct sign language (SL) parameters, current research on SL avatars lacks consideration of the UI context’s options for individualization or configuration of such parameters. Our paper addresses this gap as it presents our ability-oriented online survey, in which we asked native signers about parameters they would like to configure, as well content types that should be offered for translation within travel contexts. Our results indicate that parameters with a direct influence on the understandability of the avatar are most important for individual adjustments and situations with high time-pressure are valued highly for translation within travelling contexts. Also, our study design revealed that assessing the language background of participants in the form of an example-based self-assessment can help achieve more sensitive results, emphasizing the need for adequate research approaches.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {167},
numpages = {7},
keywords = {Deaf and Hard of Hearing user studies, requirements analysis, sign language avatar design},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Late Breaking Work,CHI23}
}
@inproceedings{10.1145/3544549.3585895,
author = {Gabel, Jenny and Ludwig, Melanie and Steinicke, Frank},
title = {Immersive Reading: Comparison of Performance and User Experience for Reading Long Texts in Virtual Reality},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585895},
doi = {10.1145/3544549.3585895},
abstract = {Specific use cases in virtual reality (VR) require users to read long texts on their headsets. We use VR to support researchers in the humanities, which includes the display of long text descriptions in VR. However, research on suitable user interface (UI) patterns for displaying and interacting with long texts in VR is scarce. To address this gap, we designed four text panel variants and conducted a within-participants study (N=24) to evaluate user experience (UX) and reading performance. Our findings suggest that there are no significant differences between conditions regarding reading performance. Yet, there are significant effects of conditions on some aspects of UX. Our work offers initial insights and future directions for research on the design of suitable UI patterns and the UX for reading long texts in VR.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {170},
numpages = {8},
keywords = {interface design patterns, reading, user-centred design, virtual reality},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Late Breaking Work,CHI23}
}
@inproceedings{10.1145/3544548.3581193,
author = {Bartkowski, Wieslaw and Nowak, Andrzej and Czajkowski, Filip Ignacy and Schmidt, Albrecht and M\"{u}ller, Florian},
title = {In Sync: Exploring Synchronization to Increase Trust Between Humans and Non-humanoid Robots},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581193},
doi = {10.1145/3544548.3581193},
abstract = {When we go for a walk with friends, we can observe an interesting effect: From step lengths to arm movements - our movements unconsciously align; they synchronize. Prior research found that this synchronization is a crucial aspect of human relations that strengthens social cohesion and trust. Generalizing from these findings in synchronization theory, we propose a dynamical approach that can be applied in the design of non-humanoid robots to increase trust. We contribute the results of a controlled experiment with 51 participants exploring our concept in a between-subjects design. For this, we built a prototype of a simple non-humanoid robot that can bend to follow human movements and vary the movement synchronization patterns. We found that synchronized movements lead to significantly higher ratings in an established questionnaire on trust between people and automation but did not influence the willingness to spend money in a trust game.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {367},
numpages = {14},
keywords = {design strategy, dynamical approach, non-humanoid robot, synchronization, trust},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544548.3580888,
author = {Zenner, Andr\'{e} and Ullmann, Kristin and Ariza, Oscar and Steinicke, Frank and Kr\"{u}ger, Antonio},
title = {Induce a Blink of the Eye: Evaluating Techniques for Triggering Eye Blinks in Virtual Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580888},
doi = {10.1145/3544548.3580888},
abstract = {As more and more virtual reality (VR) headsets support eye tracking, recent techniques started to use eye blinks to induce unnoticeable manipulations to the virtual environment, e.g., to redirect users’ actions. However, to exploit their full potential, more control over users’ blinking behavior in VR is required. To this end, we propose a set of reflex-based blink triggers that are suited specifically for VR. In accordance with blink-based techniques for redirection, we formulate (i) effectiveness, (ii) efficiency, (iii) reliability, and (iv) unobtrusiveness as central requirements for successful triggers. We implement the soft- and hardware-based methods and compare the four most promising approaches in a user study. Our results highlight the pros and cons of the tested triggers, and show those based on the menace, corneal, and dazzle reflexes to perform best. From these results, we derive recommendations that help choosing suitable blink triggers for VR applications.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {256},
numpages = {12},
keywords = {blink triggers, change blindness, eye blinks, virtual reality},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544548.3581497,
author = {Wo\'{z}niak, Miko\l{}aj P. and V\"{o}ge, Sarah and Kr\"{u}ger, Ronja and M\"{u}ller, Heiko and Koelle, Marion and Boll, Susanne},
title = {Inhabiting Interconnected Spaces: How Users Shape and Appropriate Their Smart Home Ecosystems},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581497},
doi = {10.1145/3544548.3581497},
abstract = {Over the last decade, smart home technology (SHT) has become an integral part of modern households. As a result, smart home ecosystems blend with daily social life, appropriated and integrated into personalised domestic environments. The lived experience of inhabiting smart home ecosystems, however, is not yet understood, resulting in a mismatch between ecosystem design and inhabitants’ needs. Drawing on contextual inquiry methods, we conducted an explorative interview study (N=20) with SHT users in their homes. Our thematic analysis reveals how users shape their smart home ecosystems (SHEs), considering social relationships at home, perceived ownership of SHTs, and expected key benefits. Notably, our analysis shows that household members consciously choose ‘their’ level of SHT interconnectedness, reflecting social, spatial and functional affinities between systems. Following our findings, we formulate five implications for designing future SHTs. Our work contributes insights on the dynamics and appropriation of smart home ecosystems by their inhabitants.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {636},
numpages = {18},
keywords = {interactive spaces, interconnectedness, smart home, smart home ecosystem},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544549.3583920,
author = {Li, Ke and Rolff, Tim and Schmidt, Susanne and Bacher, Reinhard and Leemans, Wim and Steinicke, Frank},
title = {Interacting with Neural Radiance Fields in Immersive Virtual Reality},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3583920},
doi = {10.1145/3544549.3583920},
abstract = {Recent advancements in the neural radiance field (NeRF) technology, in particular its extension by instant neural graphics primitives, provide tremendous opportunities for the use of real-time immersive virtual reality (VR) applications. Moreover, the recent release of an immersive neural graphics primitives framework (immersive-ngp) brings real-time, stereoscopic NeRF rendering to the Unity game engine. However, the system and application research combining NeRF and human-computer interaction in VR is still at the very beginning. In this demo, we present multiple interactive system features for immersive-ngp with design principles focusing on improving the usability and interactivity of the framework for small to medium-scale NeRF scenes. We demonstrate that these new feature implementations such as exocentric manipulation, VR tunneling effects, and immersive scene appearance editing enable novel VR-NeRF experiences, for example, for customized experiences in inspecting a particle accelerator environment.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {460},
numpages = {4},
keywords = {Immersive Virtual Reality, Neural Radiance Field},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Interactivity/Demonstration,CHI23}
}
@inproceedings{10.1145/3544548.3581303,
author = {Lanzer, Mirjam and Koniakowsky, Ina and Colley, Mark and Baumann, Martin},
title = {Interaction Effects of Pedestrian Behavior, Smartphone Distraction and External Communication of Automated Vehicles on Crossing and Gaze Behavior},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581303},
doi = {10.1145/3544548.3581303},
abstract = {External communication of automated vehicles is proposed to replace driver-pedestrian communication in ambiguous crossing situations. So far, research has focused on simpler scenarios with one attentive pedestrian and one automated vehicle. This virtual reality study (N=115) investigates a more complex scenario with other crossing pedestrians, a distracting task on the smartphone, and external communication by the automated vehicle. Interaction effects were found for crossing duration, gaze behavior, and subjective measures. For attentive pedestrians, the external communication resulted in shorter crossing durations, higher perceived safety, as well as lower perceived criticality, cognitive workload, and effort. These positive effects were not found when pedestrians were distracted. Instead, distracted pedestrians benefited from other crossing pedestrians because they looked less at the stopping vehicle, felt safer, perceived the situation as less critical, and reported lower cognitive workload and effort. Pedestrians initiated crossings earlier with a group or external communication and later with a smartphone.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {768},
numpages = {18},
keywords = {automated vehicles, eHMI, eye tracking, pedestrian group, smartphone distraction, unsignalized crossing, virtual reality},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544549.3585833,
author = {Berger, Christoph and Knierim, Michael Thomas and Benke, Ivo and Bartholomeyczik, Karen and Weinhardt, Christof},
title = {InterFlowCeption: Foundations for Technological Enhancement of Interoception to Foster Flow States during Mental Work: About the potential of technologically supported body awareness to promote flow experiences during mental work},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585833},
doi = {10.1145/3544549.3585833},
abstract = {Conducting mental work by interacting with digital technology increases productivity, but strains attentional capacities and mental well-being. In consequence, many mental workers try to cultivate their flow experience. However, this is complex and difficult to achieve. Nevertheless, current technological systems do not yet provide this support in mental work. As interoception, the individual bodily awareness is an underlying mechanism of numerous flow correlates, it might offer a new approach for flow-supporting systems in these scenarios. Results from a survey study with 176 digital workers show that adaptive regulation of interoceptive sensations correlates with higher levels of flow and engagement. Additionally, regular mindfulness practices improved workers' adaptive regulation of bodily signals. Based on these results and integrating the current literature, this work conceptualizes three future technological support systems, such as interoceptive biofeedback, and electrical or auditory stimulation to enhance interoceptive awareness and foster flow in mental work.CCS CONCEPTS • Human-centered computing • Human computer interaction (HCI) • Empirical studies in HCI},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {184},
numpages = {8},
keywords = {Body Awareness, Flow Experience, Interoception, Mental Work, Technological Support Systems, Work Engagement},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Late Breaking Work,CHI23}
}
@inproceedings{10.1145/3544549.3585672,
author = {Bethge, David and Patsch, Constantin and Hallgarten, Philipp and Kosch, Thomas},
title = {Interpretable Time-Dependent Convolutional Emotion Recognition with Contextual Data Streams},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585672},
doi = {10.1145/3544549.3585672},
abstract = {Emotion prediction is important when interacting with computers. However, emotions are complex, difficult to assess, understand, and hard to classify. Current emotion classification strategies skip why a specific emotion was predicted, complicating the user’s understanding of affective and empathic interface behaviors. Advances in deep learning showed that convolutional networks can learn powerful time-series patterns while showing classification decisions and feature importances. We present a novel convolution-based model that classifies emotions robustly. Our model not only offers high emotion-prediction performance but also enables transparency on the model decisions. Our solution thereby provides a time-aware feature interpretation of classification decisions using saliency maps. We evaluate the system on a contextual, real-world driving dataset involving twelve participants. Our model achieves a mean accuracy of in 5-class emotion classification on unknown roads and outperforms in-car facial expression recognition by . We conclude how emotion prediction can be improved by incorporating emotion sensing into interactive computing systems.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {186},
numpages = {9},
keywords = {Affective Computing, Emotion Classification, Explainable AI, Time-Series Classification},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Late Breaking Work,CHI23}
}
@inproceedings{10.1145/3544548.3581167,
author = {Windl, Maximiliane and Schmidt, Albrecht and Feger, Sebastian S.},
title = {Investigating Tangible Privacy-Preserving Mechanisms for Future Smart Homes},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581167},
doi = {10.1145/3544548.3581167},
abstract = {Most smart home devices have multiple sensors, such as cameras and microphones; however, most cannot be controlled individually. Tangible privacy mechanisms provide control over individual sensors and instill high certainty of privacy. Yet, it remains unclear how they can be used in future smart homes. We conducted three studies to understand how tangible privacy mechanisms scale across multiple devices and respond to user needs. First, we conducted a focus group (N=8) on speculative tangible control artifacts to understand the user perspective. Second, we ran a workshop at a human-computer interaction conference (N=8) on tangible privacy. Third, we conducted a six-week in-the-wild study with a tangible, static privacy dashboard across six households. Our findings help to contrast the need for tangible privacy mechanisms on the sensor level with user needs on a smart home level. Finally, we discuss our design implications for future smart homes through the lens of inclusive privacy.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {70},
numpages = {16},
keywords = {Configurable Smart Devices, Inclusive Privacy, Privacy, Speculative Design, Tangible Privacy Spectrum.},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544548.3581004,
author = {Drey, Tobias and Montag, Michael and Vogt, Andrea and Rixen, Nico and Seufert, Tina and Zander, Steffi and Rietzler, Michael and Rukzio, Enrico},
title = {Investigating the Effects of Individual Spatial Abilities on Virtual Reality Object Manipulation},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581004},
doi = {10.1145/3544548.3581004},
abstract = {Object manipulation in 3D space, meaning translating, rotating, and scaling, is ubiquitous in virtual reality (VR), and several interaction techniques have been developed in the past to optimize the task performance and usability. However, preliminary research indicates that individual spatial abilities also have an impact. Yet, it was never investigated if users’ spatial abilities influence VR object manipulation. We assessed this in a user study (N=66) using 21 manipulation tasks defined in a Fitts’ law-related approach. As interaction techniques, we chose gizmos for simultaneously manipulating 1 and 3 degrees of freedom (DOF) and a handle bar metaphor for 7 DOF. Higher spatial abilities resulted in significantly shorter task completion time and more targeted manipulations, while task accuracy was unaffected. However, an optimized interaction technique could compensate individual disadvantages. We propose seven guidelines on spatial abilities in interaction technique design and research to personalize and improve VR applications.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {398},
numpages = {24},
keywords = {Fitts’ law, docking task, individual characteristics, interaction technique, mixed reality, object manipulation, spatial abilities, virtual reality},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544548.3581049,
author = {Al-Taie, Ammar and Abdrabou, Yasmeen and Macdonald, Shaun Alexander and Pollick, Frank and Brewster, Stephen Anthony},
title = {Keep it Real: Investigating Driver-Cyclist Interaction in Real-World Traffic},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581049},
doi = {10.1145/3544548.3581049},
abstract = {Cyclists encounter drivers in many traffic scenarios; good communication is key to avoiding collisions. Little is known about everyday driver-cyclist interaction and communication. This is important in designing Automated Vehicles (AVs) that must drive safely around cyclists. We explored driver-cyclist interaction across diverse scenarios through in-the-wild observations (N = 414) and a naturalistic study involving cyclists wearing eye-trackers (N = 12). Results showed cyclists attended to road markings and traffic signs in controlled traffic scenarios but to vehicle sides and windows in uncontrolled encounters. Interactions were unlikely at controlled intersections, but various techniques were used to negotiate right-of-way in uncontrolled scenarios, e.g. cyclists used arm gestures and shoulder checks to communicate their intent and awareness when lane merging. Drivers communicated these through on-vehicle signals and head movements at roundabouts. We discuss the implications of driver-cyclist interaction behaviour on AV interaction design and offer insights into system requirements to support cyclists riding in traffic.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {769},
numpages = {15},
keywords = {Autonomous Vehicle-Cyclist Interaction, Cyclists, Eye-Tracking, Field Study, Naturalistic Study, Observations, Vulnerable Road Users},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,Honorable Mention,CHI23}
}
@inproceedings{10.1145/3544548.3580914,
author = {Katakura, Shohei and Taraz, Martin and Abdullah, Muhammad and Methfessel, Paul and Rambold, Lukas and Kovacs, Robert and Baudisch, Patrick},
title = {Kerfmeter: Automatic Kerf Calibration for Laser Cutting},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580914},
doi = {10.1145/3544548.3580914},
abstract = {We present Kerfmeter, a hardware + software device that automatically determines how much material the laser cutter burns off, also known as kerf. Its knowledge about kerf allows Kerfmeter to make the joints of laser cut 3D models fit together with just the right tension, i.e., loose enough to allow for comfortable assembly, yet tight enough to hold parts together without glue—all this without user interaction. Kerfmeter attaches to the head of a laser cutter and works as follows: when users send a model to the laser cutter, Kerfmeter intercepts the job, injects a brief calibration routine that determines kerf, dilates the cutting plan according to this kerf, and then proceeds to fabricate the cutting plan. During the calibration routine, Kerfmeter cuts a 2cm Archimedean spiral and uses a motor to rotate it in place until it jams against the surrounding material; the angle at which the spiral jams allows Kerfmeter to infer kerf. The calibration process takes about 20s, which is >10x faster than traditional, manual kerf calibration, while also eliminating the need for expertise. In our technical evaluation, Kerfmeter produced functioning press fit joints reliably at a precision comparable to traditional manual kerf strips. Kerfmeter makes it easy to sample repeatedly; we demonstrate how this allows boosting precision past any traditional kerf strip.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {691},
numpages = {13},
keywords = {laser cutting, personal fabrication, rapid prototyping},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544548.3580707,
author = {Kimmel, Simon and Jung, Frederike and Matviienko, Andrii and Heuten, Wilko and Boll, Susanne},
title = {Let’s Face It: Influence of Facial Expressions on Social Presence in Collaborative Virtual Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580707},
doi = {10.1145/3544548.3580707},
abstract = {As the world becomes more interconnected, physical separation between people increases. Existing collaborative Virtual Reality (VR) applications, designed to bridge this distance, are not yet sufficient in providing a sense of social connection comparable to face-to-face interactions. Possible reasons are the limited multimodality of VR systems and the lack of non-verbal cues in VR avatars. We systematically investigated how facial expressions influence Social Presence in two collaborative VR tasks. We explored four types of facial expressions: eyes and mouth movements, their combination, and no expressions, for two types of explanations: verbal and graphical. To examine how these expressions influence Social Presence, we conducted a controlled VR experiment (N = 48), in which participants had to explain a specific term to their counterpart. Our results demonstrate that eye and mouth movements positively influence Social Presence in VR. Particularly, combining verbal explanations and eye movements induces the highest feeling of co-presence.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {429},
numpages = {16},
keywords = {collaboration, facial expressions, social presence, virtual reality},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@article{10.1145/3557887,
author = {Han, Jiawen and Chernyshov, George and Sugawa, Moe and Zheng, Dingding and Hynds, Danny and Furukawa, Taichi and Padovani Macieira, Marcelo and Marky, Karola and Minamizawa, Kouta and Ward, Jamie A. and Kunze, Kai},
title = {Linking Audience Physiology to Choreography},
year = {2023},
issue_date = {February 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {1},
issn = {1073-0516},
url = {https://doi.org/10.1145/3557887},
doi = {10.1145/3557887},
abstract = {The use of wearable sensor technology opens up exciting avenues for both art and HCI research, providing new ways to explore the invisible link between audience and performer. To be effective, such work requires close collaboration between performers and researchers. In this article, we report on the co-design process and research insights from our work integrating physiological sensing and live performance. We explore the connection between the audience’s physiological data and their experience during the performance, analyzing a multi-modal dataset collected from 98 audience members. We identify notable moments based on HRV and EDA, and show how the audience’s physiological responses can be linked to the choreography. The longitudinal changes in HRV features suggest a strong connection to the choreographer’s intended narrative arc, while EDA features appear to correspond with short-term audience responses to dramatic moments. We discuss the physiological phenomena and implications for designing feedback systems and interdisciplinary collaborations.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = mar,
articleno = {9},
numpages = {32},
keywords = {Datasets, dance performance, electrodermal activity, heart activity},
tags = {Journal,CHI23}
}
@inproceedings{10.1145/3544548.3581332,
author = {Stefanidi, Evropi and Bentvelzen, Marit and Wo\'{z}niak, Pawe\l{} W. and Kosch, Thomas and Wo\'{z}niak, Miko\l{}aj P. and Mildner, Thomas and Schneegass, Stefan and M\"{u}ller, Heiko and Niess, Jasmin},
title = {Literature Reviews in HCI: A Review of Reviews},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581332},
doi = {10.1145/3544548.3581332},
abstract = {This paper analyses Human-Computer Interaction (HCI) literature reviews to provide a clear conceptual basis for authors, reviewers, and readers. HCI is multidisciplinary and various types of literature reviews exist, from systematic to critical reviews in the style of essays. Yet, there is insufficient consensus of what to expect of literature reviews in HCI. Thus, a shared understanding of literature reviews and clear terminology is needed to plan, evaluate, and use literature reviews, and to further improve review methodology. We analysed 189 literature reviews published at all SIGCHI conferences and ACM Transactions on Computer-Human Interaction (TOCHI) up until August 2022. We report on the main dimensions of variation: (i) contribution types and topics; and (ii) structure and methodologies applied. We identify gaps and trends to inform future meta work in HCI and provide a starting point on how to move towards a more comprehensive terminology system of literature reviews in HCI.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {509},
numpages = {24},
keywords = {literature review, literature survey, meta review, meta-analysis, method},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544548.3580988,
author = {Bonnail, Elise and Tseng, Wen-Jie and Mcgill, Mark and Lecolinet, Eric and Huron, Samuel and Gugenheimer, Jan},
title = {Memory Manipulations in Extended Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580988},
doi = {10.1145/3544548.3580988},
abstract = {Human memory has notable limitations (e.g., forgetting) which have necessitated a variety of memory aids (e.g., calendars). As we grow closer to mass adoption of everyday Extended Reality (XR), which is frequently leveraging perceptual limitations (e.g., redirected walking), it becomes pertinent to consider how XR could leverage memory limitations (forgetting, distorting, persistence) to induce memory manipulations. As memories highly impact our self-perception, social interactions, and behaviors, there is a pressing need to understand XR Memory Manipulations (XRMMs). We ran three speculative design workshops (n=12), with XR and memory researchers creating 48 XRMM scenarios. Through thematic analysis, we define XRMMs, present a framework of their core components and reveal three classes (at encoding, pre-retrieval, at retrieval). Each class differs in terms of technology (AR, VR) and impact on memory (influencing quality of memories, inducing forgetting, distorting memories). We raise ethical concerns and discuss opportunities of perceptual and memory manipulations in XR.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {875},
numpages = {20},
keywords = {Augmented Reality, Extended Reality, Perceptual Manipulations, Speculative Design, Virtual Reality, XR Memory Manipulations},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,Honorable Mention,CHI23}
}
@inproceedings{10.1145/3544549.3573814,
author = {Laschke, Matthias and Bucher, Amy and Coulton, Paul and Hassenzahl, Marc and Kuijer, Lenneke and Lallemand, Carine and Lockton, Dan and Ludden, Geke and Deterding, Sebastian},
title = {Moral Agents for Sustainable Transitions: Ethics, Politics, Design},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3573814},
doi = {10.1145/3544549.3573814},
abstract = {Artificial moral agents – systems that engage in explicit moral reasoning on their own and with users – present a potential new paradigm for behavior and system change for social and environmental sustainability. Moral agents could replace current individualist, prescriptive, inflexible, and opaque interventions with systems that transparently state their values and then openly deliberate and contest these with users, or agents that represent human and non-human stakeholders such as future generations, species, or ecosystems. Indeed, moral agents could mark a genuine new form of more-than-human interactions and human-technology relation, where we relate to artificial systems as a counterpart. To jointly articulate key questions and possible futures around moral agents, this workshop convenes HCI, AI, behaviour change, and critical and speculative design researchers and practitioners.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {359},
numpages = {6},
keywords = {artificial moral agents, behaviour change, more-than-human, sustainable HCI},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Workshop,CHI23}
}
@inproceedings{10.1145/3544548.3580973,
author = {Cmentowski, Sebastian and Karaosmanoglu, Sukran and Nacke, Lennart E. and Steinicke, Frank and Kr\"{u}ger, Jens Harald},
title = {Never Skip Leg Day Again: Training the Lower Body with Vertical Jumps in a Virtual Reality Exergame},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580973},
doi = {10.1145/3544548.3580973},
abstract = {Virtual Reality (VR) exergames can increase engagement in and motivation for physical activities. Most VR exergames focus on the upper body because many VR setups only track the users’ heads and hands. To become a serious alternative to existing exercise programs, VR exergames must provide a balanced workout and train the lower limbs, too. To address this issue, we built a VR exergame focused on vertical jump training to explore full-body exercise applications. To create a safe and effective training, nine domain experts participated in our prototype design. Our mixed-methods study confirms that the jump-centered exercises provided a worthy challenge and positive player experience, indicating long-term retention. Based on our findings, we present five design implications to guide future work: avoid an unintended forward drift, consider technical constraints, address safety concerns in full-body VR exergames, incorporate rhythmic elements with fluent movement patterns, adapt difficulty to players’ fitness progression status.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {786},
numpages = {18},
keywords = {VR, dynamic difficulty, exergame, health, serious games, sport, training, vertical jump, virtual reality},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,Honorable Mention,CHI23}
}
@inproceedings{10.1145/3544548.3580964,
author = {Ruoff, Marcel and Myers, Brad A and Maedche, Alexander},
title = {ONYX: Assisting Users in Teaching Natural Language Interfaces Through Multi-Modal Interactive Task Learning},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580964},
doi = {10.1145/3544548.3580964},
abstract = {Users are increasingly empowered to personalize natural language interfaces (NLIs) by teaching how to handle new natural language (NL) inputs. However, our formative study found that when teaching new NL inputs, users require assistance in clarifying ambiguities that arise and want insight into which parts of the input the NLI understands. In this paper we introduce ONYX, an intelligent agent that interactively learns new NL inputs by combining NL programming and programming-by-demonstration, also known as multi-modal interactive task learning. To address the aforementioned challenges, ONYX provides suggestions on how ONYX could handle new NL inputs based on previously learned concepts or user-defined procedures, and poses follow-up questions to clarify ambiguities in user demonstrations, using visual and textual aids to clarify the connections. Our evaluation shows that users provided with ONYX’s new features achieved significantly higher accuracy in teaching new NL inputs (median: 93.3\%) in contrast to those without (median: 73.3\%).},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {417},
numpages = {16},
keywords = {Data Visualization Tools, End User Development, Interactive Task Learning, Natural Language Interfaces},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544548.3580715,
author = {Luo, Weizhou and Yu, Zhongyuan and Rzayev, Rufat and Satkowski, Marc and Gumhold, Stefan and McGinity, Matthew and Dachselt, Raimund},
title = {Pearl: Physical Environment based Augmented Reality Lenses for In-Situ Human Movement Analysis},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580715},
doi = {10.1145/3544548.3580715},
abstract = {This paper presents Pearl, a mixed-reality approach for the analysis of human movement data in situ. As the physical environment shapes human motion and behavior, the analysis of such motion can benefit from the direct inclusion of the environment in the analytical process. We present methods for exploring movement data in relation to surrounding regions of interest, such as objects, furniture, and architectural elements. We introduce concepts for selecting and filtering data through direct interaction with the environment, and a suite of visualizations for revealing aggregated and emergent spatial and temporal relations. More sophisticated analysis is supported through complex queries comprising multiple regions of interest. To illustrate the potential of Pearl, we developed an Augmented Reality-based prototype and conducted expert review sessions and scenario walkthroughs in a simulated exhibition. Our contribution lays the foundation for leveraging the physical environment in the in-situ analysis of movement data.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {381},
numpages = {15},
keywords = {Immersive Analytics, In-situ visualization, affordance, augmented/mixed reality, movement data analysis, physical referents},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544548.3580751,
author = {Tang, Kymeng and Gerling, Kathrin and Vanden Abeele, Vero and Geurts, Luc and Aufheimer, Maria},
title = {Playful Reflection: Impact of Gamification on a Virtual Reality Simulation of Breastfeeding},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580751},
doi = {10.1145/3544548.3580751},
abstract = {Gamification is a popular technique to improve task engagement, and has broadly been deployed in health and education to a point where many users now expect gameful experiences in these settings. However, gamification has been criticised for being a potential obstacle to the experience of reflection. Motivated by this tension, our work examines how the addition of gamification to a Virtual Reality simulation of breastfeeding impacts player experience and reflection. Using a within-subjects design, we invited 34 participants to take part in a mixed-methods evaluation of a gamified and non-gamified variant of the simulation that included questionnaires and semi-structured interviews. Results show that gamification improved player experience and encouraged players to reflect on goal achievement and performance. However, it also diverted players’ attention from nuances within the act of nursing. Drawing on our findings, we contribute considerations for the application of gamification in personal and sensitive settings such as breastfeeding.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {787},
numpages = {13},
keywords = {Breastfeeding, Gamification, Reflection, Simulation, Virtual Reality},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544549.3585862,
author = {Krug, Katja and Satkowski, Marc and Docea, Reuben and Ku, Tzu-Yu and Dachselt, Raimund},
title = {Point Cloud Alignment through Mid-Air Gestures on a Stereoscopic Display},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585862},
doi = {10.1145/3544549.3585862},
abstract = {Manual point cloud registration is often a crucial step during the mapping of 3D point clouds and usually performed on a conventional desktop setup with mouse interaction. Since 3D point clouds are inherently spatial, these 2D applications suffer from impaired depth perception and inconvenient interaction. Nonetheless, there are few efforts to improve the usability of these applications. To address this, we propose an alternative setup, consisting of a stereoscopic display and an external hand tracker, allowing for enhanced depth perception and natural interaction without the need for body-worn devices or handheld controllers. We developed interaction techniques for point cloud alignment in 3D space, including visual feedback during alignment, and implemented a proof-of-concept prototype in the context of a surgical use case. We describe the use case, design and implementation of our concepts and outline future work. Herewith we provide a user-centered alternative to desktop applications for manual point cloud registration.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {230},
numpages = {7},
keywords = {image guidance navigation systems, mid-air interaction, point cloud alignment, point cloud registration, stereoscopic display},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Late Breaking Work,CHI23}
}
@inproceedings{10.1145/3544548.3581433,
author = {Rossmy, Beat and Terzimehi\'{c}, Na\dj{}a and D\"{o}ring, Tanja and Buschek, Daniel and Wiethoff, Alexander},
title = {Point of no Undo: Irreversible Interactions as a Design Strategy},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581433},
doi = {10.1145/3544548.3581433},
abstract = {Despite irreversibility being omnipresent in the lifeworld, research on interactions making use of irreversibility in computing systems is still in the early stages. User freedom – provided by the undo functionality – is considered to be a pillar of “usable” computer systems, overcoming irreversibility. Within this paper, we set up a thought experiment, challenging the “undo feature” and instead take advantage of irreversibility in the interaction with physical computing systems (tangibles, robots, etc). First, we present three material speculations, each inherently utilizing irreversibility. Second, we elaborate on the concept of irreversible interactions by contextualizing our work with critical HCI discourses and deducing three design strategies. Finally, we discuss irreversibility as a design element for self-reflection, meaningful acting, and a sustainable relationship with technology. While previously individual aspects of irreversibility have been explored, we contribute a comprehensive discussion of irreversible interactions in HCI presenting artifacts, a conceptualization, design strategies, and application purposes.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {140},
numpages = {18},
keywords = {Causality, Design Strategies, Irreversibility, Reality-Based Interaction, Robotic Interfaces, Speculative Design, Tangible User Interfaces},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544549.3585773,
author = {Valkov, Dimitar and Kockwelp, Pascal and Daiber, Florian and Kr\"{u}ger, Antonio},
title = {Reach Prediction using Finger Motion Dynamics},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585773},
doi = {10.1145/3544549.3585773},
abstract = {The ability to predict the object the user intends to grasp or to recognize the one she is already holding offers essential contextual information and may help to leverage the effects of point-to-point latency in interactive environments. This paper investigates the feasibility and accuracy of recognizing un-instrumented objects based on hand kinematics during reach-to-grasp and transport actions. In a data collection study, we recorded the hand motions of 16 participants while reaching out to grasp and then moving real and synthetic objects. Our results demonstrate that even a simple LSTM network can predict the time point at which the user grasps an object with 23 ms precision and the current distance to it with a precision better than 1 cm. The target’s size can be determined in advance with an accuracy better than 97\%. Our results have implications for designing adaptive and fine-grained interactive user interfaces in ubiquitous and mixed-reality environments.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {242},
numpages = {8},
keywords = {datasets, grasp prediction, hand gesture, neural networks},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Late Breaking Work,CHI23}
}
@inproceedings{10.1145/3544548.3580763,
author = {Wagener, Nadine and Reicherts, Leon and Zargham, Nima and Bart\l{}omiejczyk, Natalia and Scott, Ava Elizabeth and Wang, Katherine and Bentvelzen, Marit and Stefanidi, Evropi and Mildner, Thomas and Rogers, Yvonne and Niess, Jasmin},
title = {SelVReflect: A Guided VR Experience Fostering Reflection on Personal Challenges},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580763},
doi = {10.1145/3544548.3580763},
abstract = {Reflecting on personal challenges can be difficult. Without encouragement, the reflection process often remains superficial, thus inhibiting deeper understanding and learning from past experiences. To allow people to immerse themselves in and deeply reflect on past challenges, we developed SelVReflect, a VR experience which offers active voice-based guidance and a space to freely express oneself. SelVReflect was developed in an iterative design process (N=5) and evaluated in a user study with N=20 participants. We found that SelVReflect enabled participants to approach their challenge and its (emotional) components from different perspectives and to discover new relationships between these components. By making use of the spatial possibilities in VR, participants developed a better understanding of the situation and of themselves. We contribute empirical evidence of how a guided VR experience can support reflection. We discuss opportunities and design requirements for guided VR experiences that aim to foster deeper reflection.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {323},
numpages = {17},
keywords = {Creativity, Emotion, Expression, Guidance, Reflection, Self-care, Virtual Reality, Well-being},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544548.3580778,
author = {Chiossi, Francesco and Haliburton, Luke and Ou, Changkun and Butz, Andreas Martin and Schmidt, Albrecht},
title = {Short-Form Videos Degrade Our Capacity to Retain Intentions: Effect of Context Switching On Prospective Memory},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580778},
doi = {10.1145/3544548.3580778},
abstract = {Social media platforms use short, highly engaging videos to catch users’ attention. While the short-form video feeds popularized by TikTok are rapidly spreading to other platforms, we do not yet understand their impact on cognitive functions. We conducted a between-subjects experiment (N = 60) investigating the impact of engaging with TikTok, Twitter, and YouTube while performing a Prospective Memory task (i.e., executing a previously planned action). The study required participants to remember intentions over interruptions. We found that the TikTok condition significantly degraded the users’ performance in this task. As none of the other conditions (Twitter, YouTube, no activity) had a similar effect, our results indicate that the combination of short videos and rapid context-switching impairs intention recall and execution. We contribute a quantified understanding of the effect of social media feed format on Prospective Memory and outline consequences for media technology designers to not harm the users’ memory and wellbeing.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {30},
numpages = {15},
keywords = {Digital Wellbeing, Prospective Memory, Social Media, TikTok},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@article{10.1145/3569894,
author = {Sharma, Adwait and Salchow-H\"{o}mmen, Christina and Mollyn, Vimal Suresh and Nittala, Aditya Shekhar and Hedderich, Michael A. and Koelle, Marion and Seel, Thomas and Steimle, J\"{u}rgen},
title = {SparseIMU: Computational Design of Sparse IMU Layouts for Sensing Fine-grained Finger Microgestures},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {3},
issn = {1073-0516},
url = {https://doi.org/10.1145/3569894},
doi = {10.1145/3569894},
abstract = {Gestural interaction with freehands and while grasping an everyday object enables always-available input. To sense such gestures, minimal instrumentation of the user’s hand is desirable. However, the choice of an effective but minimal IMU layout remains challenging, due to the complexity of the multi-factorial space that comprises diverse finger gestures, objects, and grasps. We present SparseIMU, a rapid method for selecting minimal inertial sensor-based layouts for effective gesture recognition. Furthermore, we contribute a computational tool to guide designers with optimal sensor placement. Our approach builds on an extensive microgestures dataset that we collected with a dense network of 17 inertial measurement units (IMUs). We performed a series of analyses, including an evaluation of the entire combinatorial space for freehand and grasping microgestures (393 K layouts), and quantified the performance across different layout choices, revealing new gesture detection opportunities with IMUs. Finally, we demonstrate the versatility of our method with four scenarios.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = jun,
articleno = {39},
numpages = {40},
keywords = {design tool, objects, imu, sensor placement, hand gestures, Gesture recognition},
tags = {Interactivity/Demonstration,Journal,CHI23}
}
@inproceedings{10.1145/3544549.3585853,
author = {Ellenberg, Mats Ole and Satkowski, Marc and Luo, Weizhou and Dachselt, Raimund},
title = {Spatiality and Semantics - Towards Understanding Content Placement in Mixed Reality},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585853},
doi = {10.1145/3544549.3585853},
abstract = {Mixed Reality (MR) popularizes numerous situated applications where virtual content is spatially integrated into our physical environment. However, we only know little about what properties of an environment influence the way how people place digital content and perceive the resulting layout. We thus conducted a preliminary study (N = 8) examining how physical surfaces affect organizing virtual content like documents or charts, focusing on user perception and experience. We found, among others, that the situated layout of virtual content in its environment can be characterized by the level of spatial as well as semantic coupling. Consequently, we propose a two-dimensional design space to establish the vocabularies and detail their parameters for content organization. With our work, we aim to facilitate communication between designers or researchers, inform general MR interface design, and provide a first step towards future MR workspaces empowered by blending digital content and its real-world context.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {254},
numpages = {8},
keywords = {Augemented Reality, Content Organization, Design Space, Layout, Mixed Reality, User Study},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Late Breaking Work,CHI23}
}
@inproceedings{10.1145/3544549.3585739,
author = {Pre\ss{}ler, Jan and Schmid, Lukas and Hurtienne, J\"{o}rn},
title = {Statistically Controlling for Processing Fluency Reduces the Aesthetic-Usability Effect},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585739},
doi = {10.1145/3544549.3585739},
abstract = {The aesthetic-usability effect asserts that user interfaces that appear aesthetic also appear easier to use. Most explanations for the effect see aesthetics in a causal role. In contrast, we propose that processing fluency as a third variable causes both judgements of aesthetics and usability. Processing fluency refers to the subjective ease of information processing and has been shown to influence, among others, judgements of aesthetics and usability. We tested our proposition in an experiment in which users rated screenshots of city websites. The aesthetic-usability effect was replicated by our data: aesthetics and usability correlated .79. When controlling for fluency, however, the aesthetic-usability effect was considerably diminished; the correlation decreased to .34. Future research will address the limitations of this study by investigating a wider range of website designs and adding interactivity to the interfaces.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {261},
numpages = {7},
keywords = {aesthetic-usability effect, expected usability, processing fluency, websites},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Late Breaking Work,CHI23}
}
@inproceedings{10.1145/3544549.3574171,
author = {Calero Valdez, Andr\'{e} and Kojan, Lilian and Danks, Nicholas Patrick and Ray, Soumya},
title = {Structural Equation Modeling in HCI Research using SEMinR},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3574171},
doi = {10.1145/3544549.3574171},
abstract = {Structural equation models (SEMs) are statistical techniques that help to identify models of latent variables in survey data. This allows researchers to test both the quality of the measurement instrument—the survey—as well as the hypothesized relationships using a single model. Partial least squares structural equation modeling (PLS-SEM) is a subset of SEM that works well with small sample sizes and non-parametric data, which frequently occur in HCI research. In this course, we will provide a short introduction into SEMinR, an open-source library for the R language. SEMinR is an easy-to-use domain-specific language for defining, estimating, visualizing, and validating SEMs using the PLS method. SEMinR provides means for scientific reporting and can be used by academics and practitioners alike.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {553},
numpages = {3},
keywords = {SEMinR, SmartPLS, causal analysis, data analysis, psychometric methods, statistical methods, structural equation modeling, survey methods},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Course,CHI23}
}
@inproceedings{10.1145/3544548.3581180,
author = {Grundgeiger, Tobias and M\"{u}nz, Alea and Schlosser, Paul and Happel, Oliver},
title = {Supervising Multiple Operating Rooms Using a Head-Worn display: A Longitudinal Evaluation of the Experience of Supervising Anesthesiologists and Their Co-Workers},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581180},
doi = {10.1145/3544548.3581180},
abstract = {Research has explored head-worn displays (HWD) in various professional contexts. However, evaluations have been limited by short-term use, a focus on the person using the HWD, and on performance variables. In a field study, we evaluated a monocular, opaque HWD for multi-patient monitoring, which supervising anesthesiologists wore for 8-10 days each. We investigated the effect of prolonged HWD use on the experience of the supervising anesthesiologists and their co-workers using interviews and repeated observations. A reflexive thematic analysis showed (1) interaction and mindset changes over time, (2) information on the HWD is more than numbers, (3) the HWD affects co-workers' collaboration with supervisors, and (4) distraction depends on the point of view. Using activity theory, we discuss the fact that HWD use develops and changes over time and that even a single-user HWD influences the collaboration with co-workers. We conclude with implications for HWD design, implementation, and evaluation.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {345},
numpages = {18},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544548.3581150,
author = {Gr\"{o}newald, Laura and Weiblen, Julian and Laschke, Matthias and Christoforakos, Lara and Hassenzahl, Marc},
title = {Sustainability by Design. How to Encourage Users to Choose Energy-Saving Programs and Settings when Washing Laundry},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581150},
doi = {10.1145/3544548.3581150},
abstract = {One way to counteract anthropogenic climate change, is to reduce individual energy consumption. An especially energy-intensive everyday practice is doing the laundry. In Germany, laundry accounts for about 5\% of domestic electricity consumption. In part, this is because users do not make use of the energy-saving programs offered by modern washing machines. Based on different principles of behavior change, we created four concepts for washing machine interfaces to encourage users to choose energy-saving programs and settings. These concepts were implemented as functional prototypes. An online experiment (N=400) showed that all concepts increased the choice of energy-saving programs compared to a standard machine. Especially effective was to interrupt impulsive actions and suggest alternative choices (concept B) and to restructure the entry of settings (concept E). This demonstrates how small changes in a standard interfaces can significantly increase the probability of energy conservation in a private setting.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {524},
numpages = {14},
keywords = {Behavior change, empirical study, laundry washing, persuasive technology, prototyping, sustainability, sustainable HCI, sustainable interaction design},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544548.3581356,
author = {Sabnis, Nihar and Wittchen, Dennis and Vega, Gabriela and Reed, Courtney N. and Strohmeier, Paul},
title = {Tactile Symbols with Continuous and Motion-Coupled Vibration: An Exploration of using Embodied Experiences for Hermeneutic Design},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581356},
doi = {10.1145/3544548.3581356},
abstract = {With most digital devices, vibrotactile feedback consists of rhythmic patterns of continuous vibration. In contrast, when interacting with physical objects, we experience many of their material properties through vibration which is not continuous, but dynamically coupled to our actions. We assume the first style of vibration to lead to hermeneutic mediation, while the second style leads to embodied mediation. What if both types of mediation could be used to design tactile symbols? To investigate this, five haptic experts designed tactile symbols using continuous and motion-coupled vibration. Experts were interviewed to understand their symbols and design approach. A thematic analysis revealed themes showing that lived experience and affective qualities shaped design choices, that experts optimized for passive or active symbols, and that they considered context as part of the design. Our study suggests that adding embodied experiences as a design resource changes how participants think of tactile symbol design, thus broadening the scope of the symbol by design for context, and expanding their affective repertoire as changing the type of vibration influences perceived valence and arousal.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {688},
numpages = {19},
keywords = {embodied interaction, postphenomenology, symbol design, tactons, vibrotactile feedback},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544548.3581461,
author = {Sch\"{o}n, Dominik and Kosch, Thomas and M\"{u}ller, Florian and Schmitz, Martin and G\"{u}nther, Sebastian and Bommhardt, Lukas and M\"{u}hlh\"{a}user, Max},
title = {Tailor Twist: Assessing Rotational Mid-Air Interactions for Augmented Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581461},
doi = {10.1145/3544548.3581461},
abstract = {Mid-air gestures, widely used in today’s Augmented Reality (AR) applications, are prone to the “gorilla arm” effect, leading to discomfort with prolonged interactions. While prior work has proposed metrics to quantify this effect and means to improve comfort and ergonomics, these works usually only consider simplistic, one-dimensional AR interactions, like reaching for a point or pushing a button. However, interacting with AR environments also involves far more complex tasks, such as rotational knobs, potentially impacting ergonomics. This paper advances the understanding of the ergonomics of rotational mid-air interactions in AR. For this, we contribute the results of a controlled experiment exposing the participants to a rotational task in the interaction space defined by their arms’ reach. Based on the results, we discuss how novel future mid-air gesture modalities benefit from our findings concerning ergonomic-aware rotational interaction.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {400},
numpages = {14},
keywords = {Augmented Reality, Mid-Air Gesture, Rotational Interaction},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544549.3585734,
author = {Matviienko, Andrii and Durand-Pierre, Jean-Baptiste and Cvancar, Jona and M\"{u}hlh\"{a}user, Max},
title = {Text Me if You Can: Investigating Text Input Methods for Cyclists},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585734},
doi = {10.1145/3544549.3585734},
abstract = {Cycling is emerging as a relevant alternative to cars. However, the more people commute by bicycle, the higher the number of cyclists who use their smartphones on the go and endanger road safety. To better understand input while cycling, in this paper, we present the design and evaluation of three text input methods for cyclists: (1) touch input using smartphones, (2) midair input using a Microsoft Hololens 2, and (3) a set of ten physical buttons placed on both sides of the handlebar. We conducted a controlled indoor experiment (N = 12) on a bicycle simulator to evaluate these input methods. We found that text input via touch input was faster and less mentally demanding than input with midair gestures and physical buttons. However, the midair gestures were the least error-prone, and the physical buttons facilitated keeping both hands on the handlebars and were more intuitive and less distracting.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {270},
numpages = {7},
keywords = {cycling, mobile interaction, smartphone, text input},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Late Breaking Work,CHI23}
}
@inproceedings{10.1145/3544549.3583937,
author = {Borchers, Jan and Brocker, Anke and Hueber, Sebastian and Nowak, Oliver and Sch\"{a}fer, Ren\'{e} and Wagner, Adrian and Preuschoff, Paul Miles and Schirp, Lea Emilia},
title = {The Aachen Lab Demo: From Fundamental Perception to Design Tools},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3583937},
doi = {10.1145/3544549.3583937},
abstract = {This year, the Media Computing Group at RWTH Aachen University turns 20. We celebrate this anniversary with a Lab Interactivity Demo at CHI that showcases not past achievements, but the range of currently ongoing research at the lab. It features hands-on interactive demos ranging from fundamental research in perception and cognition with traditional devices, such as experiencing input latency and Dark Patterns, to new input and output techniques beyond the desktop, such as user-perspective rendering in handheld AR and interaction with time-based media through conducting, to physical interfaces and the tools and processes for their design and fabrication, such as textile icons and sliders, soft robotics, and 3D printing fabric-covered objects.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {472},
numpages = {4},
keywords = {conducting, dark patterns, e-textiles, latency, soft robotics, user-perspective rendering},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Interactivity/Demonstration,CHI23}
}
@inproceedings{10.1145/3544549.3583893,
author = {Jung, Frederike and Kaiser, Jonah-No\"{e}l and Von Holdt, Kai and Heuten, Wilko and Meyer, Jochen},
title = {The Art of Privacy – A Theatrical Privacy Installation in Virtual Reality},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3583893},
doi = {10.1145/3544549.3583893},
abstract = {In a digitized world, matters of (online) privacy become increasingly immanent in people’s lives. Paradoxically, while consumers claim they care about what happens to their personal data, they undertake little to protect it. Awareness is a crucial step towards making informed privacy decisions. Therefore, we present the Art of Privacy, a Virtual Reality (VR) installation, generated in collaboration with theater artists. This Interactivity immerses viewers into the world of data and unfolds possible consequences of clicking ‘accept’, without reading the terms and conditions or privacy policies. With this work, we contribute an artistic VR installation, designed to shed new light on digital privacy, spark discussions and encourage self-reflection of personal privacy behaviors.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {473},
numpages = {5},
keywords = {media art, mixed reality, privacy, virtual reality, visualization},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Interactivity/Demonstration,CHI23}
}
@inproceedings{10.1145/3544548.3581175,
author = {Benjamin, Jesse Josua and Biggs, Heidi and Berger, Arne and Rukanskaitundefined, Julija and Heidt, Michael B. and Merrill, Nick and Pierce, James and Lindley, Joseph},
title = {The Entoptic Field Camera as Metaphor-Driven Research-through-Design with AI Technologies},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581175},
doi = {10.1145/3544548.3581175},
abstract = {Artificial intelligence (AI) technologies are widely deployed in smartphone photography; and prompt-based image synthesis models have rapidly become commonplace. In this paper, we describe a Research-through-Design (RtD) project which explores this shift in the means and modes of image production via the creation and use of the Entoptic Field Camera. Entoptic phenomena usually refer to perceptions of floaters or bright blue dots stemming from the physiological interplay of the eye and brain. We use the term entoptic as a metaphor to investigate how the material interplay of data and models in AI technologies shapes human experiences of reality. Through our case study using first-person design and a field study, we offer implications for critical, reflective, more-than-human and ludic design to engage AI technologies; the conceptualisation of an RtD research space which contributes to AI literacy discourses; and outline a research trajectory concerning materiality and design affordances of AI technologies.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {178},
numpages = {19},
keywords = {GAN, artificial intelligence, image synthesis, materiality, research through design, technological mediation},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544549.3582739,
author = {Drewes, Heiko},
title = {The Fitts’ Law Filter Bubble},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3582739},
doi = {10.1145/3544549.3582739},
abstract = {Fitts derived a formula that allows one to calculate the time it takes to hit a target of a given size. MacKenzie called this formula imperfect and suggested an alternative formula. This paper asks some simple questions about MacKenzie’s theory. If the human-computer interaction (HCI) community does not have satisfying answers, it means that MacKenzie’s formula is unfounded. In consequence, the HCI community should stop using and citing MacKenzie’s formula and use Fitts’ original formula instead and only when necessary. Additionally, the HCI community should review the Fitts’ Law research of the last 35 years concerning criteria that indicate an echo chamber and a filter bubble and debate whether they want to publish papers based on information theory in the future.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {421},
numpages = {5},
keywords = {Fitts’ Law, MacKenzie’s formula, Shannon’s Theorem 17, information theory},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {alt.chi,CHI23}
}
@inproceedings{10.1145/3544548.3581170,
author = {Distler, Verena},
title = {The Influence of Context on Response to Spear-Phishing Attacks: an In-Situ Deception Study},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581170},
doi = {10.1145/3544548.3581170},
abstract = {In today’s digitized societies, phishing attacks are a security threat with damaging consequences. Organizations remain vulnerable to phishing attacks, and it is not clear how the work context influences people’s perceptions and behaviors related to phishing attempts. I investigate (1) how contextual factors influence reactions to a spear-phishing attempt, (2) why people report or do not report phishing attempts, (3) which opportunities for security-enhancing interventions people identify. I use an in-situ deception methodology to observe participants (N=14) in their realistic work environment. I triangulate observational and self-reported data to obtain rich qualitative insights into participants’ emotions, thoughts, and actions when receiving a targeted phishing email. I find that task, IT, internal and social context play an important role. The email’s request being aligned with expectations and perceived time pressure when responding to emails were associated with insecure behavior. The social context positively influenced phishing detection, but “phished” participants did not tell anyone.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {619},
numpages = {18},
keywords = {Empirical research, Human-computer interaction, Phishing, Qualitative research methods, Usable privacy and security},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544548.3581526,
author = {D\"{o}rrenb\"{a}cher, Judith and Ringfort-Felner, Ronda and Hassenzahl, Marc},
title = {The Intricacies of Social Robots: Secondary Analysis of Fictional Documentaries to Explore the Benefits and Challenges of Robots in Complex Social Settings},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581526},
doi = {10.1145/3544548.3581526},
abstract = {In the design of social robots, the focus is often on the robot itself rather than on the intricacies of possible application scenarios. In this paper, we examine eight fictional documentaries about social robots, such as SEYNO, a robot that promotes respect between passengers in trains, or PATO, a robot to watch movies with. Overall, robots were conceptualized either (1) to substitute humans in relationships or (2) to mediate relationships (human-human-robot-interaction). While the former is basis of many current approaches to social robotics, the latter is less common, but particularly interesting. For instance, the mediation perspective fundamentally impacts the role a robot takes (e.g., role model, black sheep, ally, opponent, moralizer) and thus its potential function and form. From the substitution perspective, robots are expected to mimic human emotions; from the mediation perspective, robots can be positive precisely because they remain objective and are neither emotional nor empathic.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {371},
numpages = {13},
keywords = {Social robots, design fiction, human-robot-interaction, otherware, sociability},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@article{10.1145/3529225,
author = {Kosch, Thomas and Welsch, Robin and Chuang, Lewis and Schmidt, Albrecht},
title = {The Placebo Effect of Artificial Intelligence in Human–Computer Interaction},
year = {2023},
issue_date = {December 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {6},
issn = {1073-0516},
url = {https://doi.org/10.1145/3529225},
doi = {10.1145/3529225},
abstract = {In medicine, patients can obtain real benefits from a sham treatment. These benefits are known as the placebo effect. We report two experiments (Experiment I: N = 369; Experiment II: N = 100) demonstrating a placebo effect in adaptive interfaces. Participants were asked to solve word puzzles while being supported by no system or an adaptive AI interface. All participants experienced the same word puzzle difficulty and had no support from an AI throughout the experiments. Our results showed that the belief of receiving adaptive AI support increases expectations regarding the participant’s own task performance, sustained after interaction. These expectations were positively correlated to performance, as indicated by the number of solved word puzzles. We integrate our findings into technological acceptance theories and discuss implications for the future assessment of AI-based user interfaces and novel technologies. We argue that system descriptions can elicit placebo effects through user expectations biasing the results of user-centered studies.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = jan,
articleno = {56},
numpages = {32},
keywords = {User studies, Placebo, User expectations, Human-AI interfaces, Placebo effect},
tags = {Journal,CHI23}
}
@article{10.1145/3555046,
author = {Spiers, Adam and Young, Eric and Kuchenbecker, Katherine J.},
title = {The S-BAN: Insights into the Perception of Shape-Changing Haptic Interfaces via Virtual Pedestrian Navigation},
year = {2023},
issue_date = {February 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {1},
issn = {1073-0516},
url = {https://doi.org/10.1145/3555046},
doi = {10.1145/3555046},
abstract = {Screen-based pedestrian navigation assistance can be distracting or inaccessible to users. Shape-changing haptic interfaces can overcome these concerns. The S-BAN is a new handheld haptic interface that utilizes a parallel kinematic structure to deliver 2-DOF spatial information over a continuous workspace, with a form factor suited to integration with other travel aids. The ability to pivot, extend and retract its body opens possibilities and questions around spatial data representation. We present a static study to understand user perception of absolute pose and relative motion for two spatial mappings, showing the highest sensitivity to relative motions in the cardinal directions. We then present an embodied navigation experiment in virtual reality (VR). User motion efficiency when guided by the S-BAN was statistically equivalent to using a vision-based tool (a smartphone proxy). Although haptic trials were slower than visual trials, participants’ heads were more elevated with the S-BAN, allowing greater visual focus on the environment.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = mar,
articleno = {11},
numpages = {31},
keywords = {Haptics, navigation, shape-changing interfaces},
tags = {Journal,CHI23}
}
@inproceedings{10.1145/3544549.3574192,
author = {Michahelles, Florian and Boll, Susanne and Siek, Katie A. and Salim, Flora D. and Quigley, Aaron J},
title = {The unwritten manual of becoming a professor of HCI},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3574192},
doi = {10.1145/3544549.3574192},
abstract = {This course is about preparing researchers for a permanent career in academia. Based on personal practice the course organizers will describe the settings, roles, procedures, and motivations of search and appointment committees. Furthermore, the course will cover strategies for preparing a successful lecture talk, scientific talk, and plans and vision talk. Finally, this course will discuss the do’s and don’t for the interview on leadership and social competencies. A dedicated module on training pitches will enable participants to practice concepts on-site and provide peer review among each other. The organizers will provide a safe space for sharing following the Chatham house rules.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {558},
numpages = {3},
keywords = {career, hci, professpr},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Course,CHI23}
}
@inproceedings{10.1145/3544548.3580986,
author = {Haliburton, Luke and Bart\l{}omiejczyk, Natalia and Schmidt, Albrecht and Wo\'{z}niak, Pawe\l{} W. and Niess, Jasmin},
title = {The Walking Talking Stick: Understanding Automated Note-Taking in Walking Meetings},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580986},
doi = {10.1145/3544548.3580986},
abstract = {While walking meetings offer a healthy alternative to sit-down meetings, they also pose practical challenges. Taking notes is difficult while walking, which limits the potential of walking meetings. To address this, we designed the Walking Talking Stick—a tangible device with integrated voice recording, transcription, and a physical highlighting button to facilitate note-taking during walking meetings. We investigated our system in a three-condition between-subjects user study with thirty pairs of participants (N=60) who conducted 15-minute outdoor walking meetings. Participants either used clip-on microphones, the prototype without the button, or the prototype with the highlighting button. We found that the tangible device increased task focus, and the physical highlighting button facilitated turn-taking and resulted in more useful notes. Our work demonstrates how interactive artifacts can incentivize users to hold meetings in motion and enhance conversation dynamics. We contribute insights for future systems which support conducting work tasks in mobile environments.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {431},
numpages = {16},
keywords = {CSCW, Mobile Work, Note-taking, Office Workers, Physical Activity, Walking Meetings},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Best Paper,Full Paper,CHI23}
}
@inproceedings{10.1145/3544549.3583901,
author = {Hoffmann, Philipp Pascal and Elsayed, Hesham and M\"{u}hlh\"{a}user, Max and Wehbe, Rina R. and Barrera Machuca, Mayra Donaji},
title = {ThermalPen: Adding Thermal Haptic Feedback to 3D Sketching},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3583901},
doi = {10.1145/3544549.3583901},
abstract = {Sketching in virtual 3D environments has enabled new forms of artistic expression and a variety of novel design use-cases. However, the lack of haptic feedback proves to be one of the main challenges in this field. While prior work has investigated vibrotactile and force-feedback devices, this paper proposes the addition of thermal feedback. We present ThermalPen, a novel pen for 3D sketching that associates the texture and colour of strokes with different thermal properties. For example, a fire texture elicits an increase in temperature, while an ice texture causes a temperature drop in the pen. Our goal with ThermalPen is to enhance the 3D sketching experience and allow users to use this tool to increase their creativity while sketching. We plan on evaluating the influence of thermal feedback on the 3D sketching experience, with a focus on user creativity in the future.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {474},
numpages = {4},
keywords = {3D Sketching, Creativity, Haptics, Pen-input, Thermal, User Experience, Virtual Reality},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Interactivity/Demonstration,CHI23}
}
@inproceedings{10.1145/3544548.3580954,
author = {M\"{u}ller, Florian and Schmitt, Daniel and Matviienko, Andrii and Sch\"{o}n, Dominik and G\"{u}nther, Sebastian and Kosch, Thomas and Schmitz, Martin},
title = {TicTacToes: Assessing Toe Movements as an Input Modality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580954},
doi = {10.1145/3544548.3580954},
abstract = {From carrying grocery bags to holding onto handles on the bus, there are a variety of situations where one or both hands are busy, hindering the vision of ubiquitous interaction with technology. Voice commands, as a popular hands-free alternative, struggle with ambient noise and privacy issues. As an alternative approach, research explored movements of various body parts (e.g., head, arms) as input modalities, with foot-based techniques proving particularly suitable for hands-free interaction. Whereas previous research only considered the movement of the foot as a whole, in this work, we argue that our toes offer further degrees of freedom that can be leveraged for interaction. To explore the viability of toe-based interaction, we contribute the results of a controlled experiment with 18 participants assessing the impact of five factors on the accuracy, efficiency and user experience of such interfaces. Based on the findings, we provide design recommendations for future toe-based interfaces.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {520},
numpages = {17},
keywords = {Body-Centric Interaction, Foot, Foot-Based Interaction, Input, Toes},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544548.3581420,
author = {Hosseini, Masoumehsadat and Ihmels, Tjado and Chen, Ziqian and Koelle, Marion and M\"{u}ller, Heiko and Boll, Susanne},
title = {Towards a Consensus Gesture Set: A Survey of Mid-Air Gestures in HCI for Maximized Agreement Across Domains},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581420},
doi = {10.1145/3544548.3581420},
abstract = {Mid-air gesture-based systems are becoming ubiquitous. Many mid-air gestures control different kinds of interactive devices, applications, and systems. They are, however, still targeted at specific devices in specific domains and are not necessarily consistent across domain boundaries. A comprehensive evaluation of the transferability of gesture vocabulary between domains is also lacking. Consequently, interaction designers cannot decide which gestures to use for which domain. In this systematic literature review, we contribute to the future research agenda in this area, based on an analysis of 172 papers. As part of our analysis, we clustered gestures according to the dimensions of an existing taxonomy to identify their common characteristics in different domains, and we investigated the extent to which existing mid-air gesture sets are consistent across different domains. We derived a consensus gesture set containing 22 gestures based on agreement rates calculation and considered their transferability across different domains.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {311},
numpages = {24},
keywords = {Mid-air gestures, agreement rate, application domain, systematic literature review},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544549.3583888,
author = {Schmelter, Thereza and Kruse, Lucie and Karaosmanoglu, Sukran and Rings, Sebastian and Steinicke, Frank and Hildebrand, Kristian},
title = {Towards More Inclusive and Accessible Virtual Reality: Conducting Large-scale Studies in the Wild},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3583888},
doi = {10.1145/3544549.3583888},
abstract = {In this work, we demonstrate a mobile laboratory with virtual and augmented reality (VR/AR) technology housed in a truck that enables large-scale VR/AR studies and therapies in real-world environments. This project aims to improve accessibility and inclusiveness in human-computer interaction (HCI) methods, providing a platform for researchers, medical professionals, and patients to utilize laboratory hardware and space. The mobile laboratory is equipped with motion tracking technology and other hardware to allow for a range of user groups to participate in VR studies and therapies that could otherwise never partake or benefit from these services. Our findings, applications, and experiences will be presented at the CHI interactivity track, with the goal of fostering future research opportunities.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {476},
numpages = {5},
keywords = {evaluation, health, living lab, mobility, motion tracking, research, truck, virtual reality},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Interactivity/Demonstration,CHI23}
}
@inproceedings{10.1145/3544548.3580909,
author = {Windl, Maximiliane and Winterhalter, Verena and Schmidt, Albrecht and Mayer, Sven},
title = {Understanding and Mitigating Technology-Facilitated Privacy Violations in the Physical World},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580909},
doi = {10.1145/3544548.3580909},
abstract = {We are constantly surrounded by technology that collects and processes sensitive data, paving the way for privacy violations. Yet, current research investigating technology-facilitated privacy violations in the physical world is scattered and focused on specific scenarios or investigates such violations purely from an expert’s perspective. Informed through a large-scale online survey, we first construct a scenario taxonomy based on user-experienced privacy violations in the physical world through technology. We then validate our taxonomy and establish mitigation strategies using interviews and co-design sessions with privacy and security experts. In summary, this work contributes (1) a refined scenario taxonomy for technology-facilitated privacy violations in the physical world, (2) an understanding of how privacy violations manifest in the physical world, (3) a decision tree on how to inform users, and (4) a design space to create notices whenever adequate. With this, we contribute a conceptual framework to enable a privacy-preserving technology-connected world.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {585},
numpages = {16},
keywords = {privacy, privacy policies, smart environments},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544548.3581485,
author = {Villa, Steeven and Niess, Jasmin and Nakao, Takuro and Lazar, Jonathan and Schmidt, Albrecht and Machulla, Tonja-Katrin},
title = {Understanding Perception of Human Augmentation: A Mixed-Method Study},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581485},
doi = {10.1145/3544548.3581485},
abstract = {Technologies that help users overcome their limitations and integrate with the human body are often termed “human augmentations”. Such technologies are now available on the consumer market, potentially supporting people in their everyday activities. To date, there is no systematic understanding of the perception of human augmentations yet. To address this gap and build an understanding of how to design positive experiences with human augmentations, we conducted a mixed-method study of the perception of augmented humans (AHs). We conducted two scenario-based studies: interviews (n = 16) and an online study (n = 506) with participants from four countries. The scenarios include one out of three augmentation categories (sensory, motor, and cognitive) and specify if the augmented person has a disability or not. Overall, results show that the type of augmentation and disability impacted user attitudes towards AHs. We derive design dimensions for creating technological augmentations for a diverse and global audience.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {65},
numpages = {16},
keywords = {augmented human, human augmentation, social attitudes},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544548.3581557,
author = {M\"{u}ller, Florian and Ye, Arantxa and Sch\"{o}n, Dominik and Rasch, Julian},
title = {UndoPort: Exploring the Influence of Undo-Actions for Locomotion in Virtual Reality on the Efficiency, Spatial Understanding and User Experience},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581557},
doi = {10.1145/3544548.3581557},
abstract = {When we get lost in Virtual Reality (VR) or want to return to a previous location, we use the same methods of locomotion for the way back as for the way forward. This is time-consuming and requires additional physical orientation changes, increasing the risk of getting tangled in the headsets’ cables. In this paper, we propose the use of undo actions to revert locomotion steps in VR. We explore eight different variations of undo actions as extensions of point&teleport, based on the possibility to undo position and orientation changes together with two different visualizations of the undo step (discrete and continuous). We contribute the results of a controlled experiment with 24 participants investigating the efficiency and orientation of the undo techniques in a radial maze task. We found that the combination of position and orientation undo together with a discrete visualization resulted in the highest efficiency without increasing orientation errors.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {234},
numpages = {15},
keywords = {Locomotion, Teleport, Undo, Virtual Reality},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544549.3585643,
author = {Meinhardt, Luca-Maxim and Colley, Mark and Fa\ss{}bender, Alexander and Rietzler, Michael and Rukzio, Enrico},
title = {Up, Up and Away - Investigating Information Needs for Helicopter Pilots in future Urban Air Mobility},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585643},
doi = {10.1145/3544549.3585643},
abstract = {This qualitative work aims to address the emerging challenges and opportunities through advanced automation and visualization capabilities in the field of helicopter piloting for future Urban Air Mobility. A workshop was conducted with N=6 professional helicopter pilots to gather insights on these topics. The participants discussed key themes, including information needs, user interfaces, and automation. The results unveiled novel opportunities and highlighted challenges for research on aiding helicopter pilots in the fields of obstacle avoidance, map visualization, and air traffic visualization, such as augmenting flight paths to increase their situation awareness.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {304},
numpages = {6},
keywords = {Helicopters, Urban Air Mobility, Virtual Reality, Workshop},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Late Breaking Work,CHI23}
}
@inproceedings{10.1145/3544549.3583895,
author = {Reinschluessel, Anke Verena and Muender, Thomas and Fischer, Roland and Kraft, Valentin and Uslar, Verena Nicole and Weyhe, Dirk and Schenk, Andrea and Zachmann, Gabriel and D\"{o}ring, Tanja and Malaka, Rainer},
title = {Versatile Immersive Virtual and Augmented Tangible OR – Using VR, AR and Tangibles to Support Surgical Practice},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3583895},
doi = {10.1145/3544549.3583895},
abstract = {Immersive technologies such as virtual reality (VR) and augmented reality (AR), in combination with advanced image segmentation and visualization, have considerable potential to improve and support a surgeon’s work. We demonstrate a solution to help surgeons plan and perform surgeries and educate future medical staff using VR, AR, and tangibles. A VR planning tool improves spatial understanding of an individual’s anatomy, a tangible organ model allows for intuitive interaction, and AR gives contactless access to medical images in the operating room. Additionally, we present improvements regarding point cloud representations to provide detailed visual information to a remote expert and about the remote expert. Therefore, we give an exemplary setup showing how recent interaction techniques and modalities benefit an area that can positively change the life of patients.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {477},
numpages = {5},
keywords = {AR, VR, augmented reality, multiuser, point clouds, surgery, tangibles, virtual reality},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Interactivity/Demonstration,CHI23}
}
@inproceedings{10.1145/3544549.3585594,
author = {Wolf, Sara and Weber, Michael and Hurtienne, J\"{o}rn},
title = {Virtual Tourism, Real Experience: A Motive-Oriented Approach to Virtual Tourism},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585594},
doi = {10.1145/3544549.3585594},
abstract = {Virtual tourism products promise to combine the best of two worlds: Staying in the safety of one’s home while having engaging tourism experiences. Previous tourism research has emphasised that tourism experiences involve more than just seeing other places. They address cultural motives such as novelty and education and socio-psychological motives like relaxation, escape from a mundane environment or facilitation of social interaction. We suggest applying the motive-oriented perspective in HCI research on virtual tourism and report on a corresponding analysis of 21 virtual tourism products. Our findings show that current virtual tourism products neglect the breadth of tourist motives. They mainly focus on cultural motives while rarely addressing socio-psychological motives, especially kinship relationships and prestige. Our findings demonstrate the usefulness of the motive-oriented perspective for HCI and inspired conceptual ideas for addressing motives in virtual tourism products that may be useful for future research and design in this area.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {309},
numpages = {7},
keywords = {Virtual tourism, tourist, tourist experience, tourist needs, virtual tour},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Late Breaking Work,CHI23}
}
@inproceedings{10.1145/3544548.3581230,
author = {Sykownik, Philipp and Karaosmanoglu, Sukran and Emmerich, Katharina and Steinicke, Frank and Masuch, Maic},
title = {VR Almost There: Simulating Co-located Multiplayer Experiences in Social Virtual Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581230},
doi = {10.1145/3544548.3581230},
abstract = {Consumer social virtual reality (VR) applications have recently started to enable social interactions at a distance. Yet it is still relatively unknown if and to what extent such applications provide meaningful social experiences in cases where in-person leisure activities are not feasible. To explore this, we developed a custom social VR application and conducted an exploratory lab study with 25 dyads in which we compared an in-person and a virtual version of a co-located multiplayer scenario. Our mixed-methods analysis revealed that both scenarios created a socially rich atmosphere and strengthened the social closeness between players. However, the lack of facial animations, limited body language, and a low field of view led to VR’s main social experiential limitations: a reduced mutual awareness and emotional understanding compared to the in-person scenario. We derive implications for social VR design and research as well as game user research.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {789},
numpages = {19},
keywords = {multiplayer games, player experience, social interaction, social presence, social virtual reality},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544549.3585726,
author = {Wieland, Markus and Sedlmair, Michael and Machulla, Tonja-Katrin},
title = {VR, Gaze, and Visual Impairment: An Exploratory Study of the Perception of Eye Contact across different Sensory Modalities for People with Visual Impairments in Virtual Reality},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585726},
doi = {10.1145/3544549.3585726},
abstract = {As social virtual reality (VR) becomes more popular, avatars are being designed with realistic behaviors incorporating non-verbal cues like eye contact. However, perceiving eye contact during a conversation can be challenging for people with visual impairments. VR presents an opportunity to display eye contact cues in alternative ways, making them perceivable for people with visual impairments. We performed an exploratory study to gain initial insights on designing eye contact cues for people with visual impairments, including a focus group for a deeper understanding of the topic. We implemented eye contact cues via visual, auditory, and tactile sensory modalities in VR and tested these approaches with eleven participants with visual impairments and collected qualitative feedback. The results show that visual cues indicating the gaze direction were preferred, but auditory and tactile cues were also prevalent as they do not superimpose additional visual information.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {313},
numpages = {6},
keywords = {assistive technology, eye contact, social virtual reality, visual impairment},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Late Breaking Work,CHI23}
}
@inproceedings{10.1145/3544549.3585868,
author = {Borgwardt, Malte and Boueke, Jonas and Sanabria, Mar\'{\i}a Fernanda and Bonfert, Michael and Porzel, Robert},
title = {VRisbee: How Hand Visibility Impacts Throwing Accuracy and Experience in Virtual Reality},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585868},
doi = {10.1145/3544549.3585868},
abstract = {Hand interaction plays a key role in virtual reality (VR) sports. While in reality, athletes mostly rely on haptic perception when holding and throwing objects, these sensational cues can be missing or differ in virtual environments. In this work, we investigated how the visibility of a virtual hand can support players when throwing and what impact it has on the overall experience. We developed a Frisbee simulation in VR and asked 29 study participants to hit a target. We measured the throwing accuracy and self-reports of presence, disc control, and body ownership. The results show a subtle advantage of hand visibility in terms of accuracy. Visible hands further improved the subjective impression of realism, body ownership and subjective control over the disc.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {314},
numpages = {7},
keywords = {embodiment, self-avatar, sports, throwing, virtual reality},
location = {Hamburg, Germany},
series = {CHI EA '23},
tags = {Doctoral Consortium,CHI23}
}
@inproceedings{10.1145/3544548.3581050,
author = {Matviienko, Andrii and Hoxha, Hajris and M\"{u}hlh\"{a}user, Max},
title = {What does it mean to cycle in Virtual Reality? Exploring Cycling Fidelity and Control of VR Bicycle Simulators},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581050},
doi = {10.1145/3544548.3581050},
abstract = {Creating highly realistic Virtual Reality (VR) bicycle experiences can be time-consuming and expensive. Moreover, it is unclear what hardware parts are necessary to design a bicycle simulator and whether a bicycle is needed at all. In this paper, we investigated cycling fidelity and control of VR bicycle simulators. For this, we developed and evaluated three cycling simulators: (1) cycling without a bicycle (bikeless), (2) cycling on a fixed (stationary) and (3) moving bicycle (tandem) with four levels of control (no control, steering, pedaling, and steering + pedaling). To evaluate all combinations of fidelity and control, we conducted a controlled experiment (N = 24) in indoor and outdoor settings. We found that the bikeless setup provides the highest feeling of safety, while the tandem leads to the highest realism without increasing motion sickness. Moreover, we discovered that bicycles are not essential for cycling in VR.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {879},
numpages = {15},
keywords = {bicycle simulators, cycling, locomotion, virtual reality},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3544548.3580920,
author = {Sch\"{a}fer, Ren\'{e} and Nowak, Oliver and Suchmann, Lovis Bero and Schr\"{o}der, S\"{o}ren and Borchers, Jan},
title = {What’s That Shape? Investigating Eyes-Free Recognition of Textile Icons},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580920},
doi = {10.1145/3544548.3580920},
abstract = {Textile surfaces, such as on sofas, cushions, and clothes, offer promising alternative locations to place controls for digital devices. Textiles are a natural, even abundant part of living spaces, and support unobtrusive input. While there is solid work on technical implementations of textile interfaces, there is little guidance regarding their design—especially their haptic cues, which are essential for eyes-free use. In particular, icons easily communicate information visually in a compact fashion, but it is unclear how to adapt them to the haptics-centric textile interface experience. Therefore, we investigated the recognizability of 84 haptic icons on fabrics. Each combines a shape, height profile (raised, recessed, or flat), and affected area (filled or outline). Our participants clearly preferred raised icons, and identified them with the highest accuracy and at competitive speeds. We also provide insights into icons that look very different, but are hard to distinguish via touch alone.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {580},
numpages = {12},
keywords = {Design Recommendations, Eyes-free Interaction, Haptic Recognition, Textile Icons, Textile Interfaces},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,Interactivity/Demonstration,CHI23}
}
@inproceedings{10.1145/3544548.3581072,
author = {Hirzle, Teresa and M\"{u}ller, Florian and Draxler, Fiona and Schmitz, Martin and Knierim, Pascal and Hornb\ae{}k, Kasper},
title = {When XR and AI Meet - A Scoping Review on Extended Reality and Artificial Intelligence},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581072},
doi = {10.1145/3544548.3581072},
abstract = {Research on Extended Reality (XR) and Artificial Intelligence (AI) is booming, which has led to an emerging body of literature in their intersection. However, the main topics in this intersection are unclear, as are the benefits of combining XR and AI. This paper presents a scoping review that highlights how XR is applied in AI research and vice versa. We screened 2619 publications from 203 international venues published between 2017 and 2021, followed by an in-depth review of 311 papers. Based on our review, we identify five main topics at the intersection of XR and AI, showing how research at the intersection can benefit each other. Furthermore, we present a list of commonly used datasets, software, libraries, and models to help researchers interested in this intersection. Finally, we present 13 research opportunities and recommendations for future work in XR and AI research.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {730},
numpages = {45},
keywords = {artificial intelligence, extended reality, scoping review},
location = {Hamburg, Germany},
series = {CHI '23},
tags = {Full Paper,CHI23}
}
@inproceedings{10.1145/3491102.3501946,
author = {Luo, Weizhou and Lehmann, Anke and Widengren, Hjalmar and Dachselt, Raimund},
title = {Where Should We Put It? Layout and Placement Strategies of Documents in Augmented Reality for Collaborative Sensemaking},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501946},
doi = {10.1145/3491102.3501946},
abstract = {Future offices are likely reshaped by Augmented Reality (AR) extending the display space while maintaining awareness of surroundings, and thus promise to support collaborative tasks such as brainstorming or sensemaking. However, it is unclear how physical surroundings and co-located collaboration influence the spatial organization of virtual content for sensemaking. Therefore, we conducted a study (N=28) to investigate the effect of office environments and work styles during a document classification task using AR with regard to content placement, layout strategies, and sensemaking workflows. Results show that participants require furniture, especially tables and whiteboards, to assist sensemaking and collaboration regardless of room settings, while generous free spaces (e.g., walls) are likely used when available. Moreover, collaborating participants tend to use furniture despite personal layout preferences. We identified different placement and layout strategies, as well as the transitions in-between. Finally, we propose design implications for future immersive sensemaking applications and beyond.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {627},
numpages = {16},
keywords = {Augmented Reality, Mixed Reality, affordance, collaborative sensemaking, content organization, qualitative user study, sensemaking, spatial layout, spatiality},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags = {CHI22,Full Paper}
}
@inproceedings{10.1145/3491101.3519717,
author = {Makhsadov, Akhmajon and Degraen, Donald and Zenner, Andr\'{e} and Kosmalla, Felix and Mushkina, Kamila and Kr\"{u}ger, Antonio},
title = {VRySmart: a Framework for Embedding Smart Devices in Virtual Reality},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3519717},
doi = {10.1145/3491101.3519717},
abstract = {As immersive virtual experiences find their way into our living room entertainment, they are becoming part of our daily technological consumption. However, state-of-the-art virtual reality (VR) remains disconnected from other digital devices in our environment, such as smartphones or tablets. As context switches between acting in the virtual environment and resolving external notifications negatively influence immersion, we look towards integrating smart devices into virtual experiences. To this aim, we present the VRySmart framework. Through either optical marker tracking or simultaneous localization and mapping (SLAM), embedded smart devices can be used as VR controllers with different levels of integration while their content is incorporated into the virtual context to support the plausibility of the illusion. To investigate user impressions, we conducted a study (N = 10) where participants used a smartphone in four different virtual scenarios. Participants positively assessed smart device usage in VR. We conclude by framing implications for future work.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {358},
numpages = {8},
keywords = {virtual reality, smart devices, haptic feedback, framework.},
location = {New Orleans, LA, USA},
series = {CHI EA '22},
tags = {CHI22,Late Breaking Work}
}
@inproceedings{10.1145/3491102.3501821,
author = {Gruenefeld, Uwe and Auda, Jonas and Mathis, Florian and Schneegass, Stefan and Khamis, Mohamed and Gugenheimer, Jan and Mayer, Sven},
title = {VRception: Rapid Prototyping of Cross-Reality Systems in Virtual Reality},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501821},
doi = {10.1145/3491102.3501821},
abstract = {Cross-reality systems empower users to transition along the reality-virtuality continuum or collaborate with others experiencing different manifestations of it. However, prototyping these systems is challenging, as it requires sophisticated technical skills, time, and often expensive hardware. We present VRception, a concept and toolkit for quick and easy prototyping of cross-reality systems. By simulating all levels of the reality-virtuality continuum entirely in Virtual Reality, our concept overcomes the asynchronicity of realities, eliminating technical obstacles. Our VRception Toolkit leverages this concept to allow rapid prototyping of cross-reality systems and easy remixing of elements from all continuum levels. We replicated six cross-reality papers using our toolkit and presented them to their authors. Interviews with them revealed that our toolkit sufficiently replicates their core functionalities and allows quick iterations. Additionally, remote participants used our toolkit in pairs to collaboratively implement prototypes in about eight minutes that they would have otherwise expected to take days.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {611},
numpages = {15},
keywords = {Augmented Reality, Cross-Reality Systems, Prototyping, Transitional Interfaces, Virtual Reality},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags = {Full Paper,CHI22}
}
@inproceedings{10.1145/3491101.3519613,
author = {D\"{o}llinger, Nina and Wolf, Erik and Mal, David and Erdmannsd\"{o}rfer, Nico and Botsch, Mario and Latoschik, Marc Erich and Wienrich, Carolin},
title = {Virtual Reality for Mind and Body: Does the Sense of Embodiment Towards a Virtual Body Affect Physical Body Awareness?},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3519613},
doi = {10.1145/3491101.3519613},
abstract = {Mind-body therapies aim to improve health by combining physical and mental exercises. Recent developments tend to incorporate virtual reality (VR) into their design and execution, but there is a lack of research concerning the inclusion of virtual bodies and their effect on body awareness in these designs. In this study, 24 participants performed in-VR body awareness movement tasks in front of a virtual mirror while embodying a photorealistic, personalized avatar. Subsequently, they performed a heartbeat counting task and rated their perceived body awareness and sense of embodiment towards the avatar. We found a significant relationship between sense of embodiment and self-reported body awareness but not between sense of embodiment and heartbeat counting. Future work can build on these findings and further explore the relationship between avatar embodiment and body awareness.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {216},
numpages = {8},
keywords = {Virtual reality, body awareness, embodiment, mind-body-therapy},
location = {New Orleans, LA, USA},
series = {CHI EA '22},
tags = {CHI22,Late Breaking Work}
}
@inproceedings{10.1145/3491101.3519822,
author = {Hube, Natalie and Vidackovic, Kresimir and Sedlmair, Michael},
title = {Using Expressive Avatars to Increase Emotion Recognition: A Pilot Study},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3519822},
doi = {10.1145/3491101.3519822},
abstract = {Virtual avatars are widely used for collaborating in virtual environments. Yet, often these avatars lack expressiveness to determine a state of mind. Prior work has demonstrated effective usage of determining emotions and animated lip movement through analyzing mere audio tracks of spoken words. To provide this information on a virtual avatar, we created a natural audio data set consisting of 17 audio files from which we then extracted the underlying emotion and lip movement. To conduct a pilot study, we developed a prototypical system that displays the extracted visual parameters and then maps them on a virtual avatar while playing the corresponding audio file. We tested the system with 5 participants in two conditions: (i) while seeing the virtual avatar only an audio file was played. (ii) In addition to the audio file, the extracted facial visual parameters were displayed on the virtual avatar. Our results suggest the validity of using additional visual parameters in the avatars’ face as it helps to determine emotions. We conclude with a brief discussion on the outcomes and their implications on future work.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {260},
numpages = {7},
keywords = {avatars, emotion, lip synchronization, virtual reality},
location = {New Orleans, LA, USA},
series = {CHI EA '22},
tags = {CHI22,Late Breaking Work}
}
@inproceedings{10.1145/3491102.3502058,
author = {V\"{o}lkel, Sarah Theres and Schoedel, Ramona and Kaya, Lale and Mayer, Sven},
title = {User Perceptions of Extraversion in Chatbots after Repeated Use},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502058},
doi = {10.1145/3491102.3502058},
abstract = {Whilst imbuing robots and voice assistants with personality has been found to positively impact user experience, little is known about user perceptions of personality in purely text-based chatbots. In a within-subjects study, we asked N=34 participants to interact with three chatbots with different levels of Extraversion (extraverted, average, introverted), each over the course of four days. We systematically varied the chatbots’ responses to manipulate Extraversion based on work in the psycholinguistics of human behaviour. Our results show that participants perceived the extraverted and average chatbots as such, whereas verbal cues transferred from human behaviour were insufficient to create an introverted chatbot. Whilst most participants preferred interacting with the extraverted chatbot, participants engaged significantly more with the introverted chatbot as indicated by the users’ average number of written words. We discuss implications for researchers and practitioners on how to design chatbot personalities that can adapt to user preferences.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {253},
numpages = {18},
keywords = {chatbot, conversational agent, extraversion, personalisation, personality},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags = {CHI22,Full Paper}
}
@article{10.1145/3492802,
author = {Hirzle, Teresa and Fischbach, Fabian and Karlbauer, Julian and Jansen, Pascal and Gugenheimer, Jan and Rukzio, Enrico and Bulling, Andreas},
title = {Understanding, Addressing, and Analysing Digital Eye Strain in Virtual Reality Head-Mounted Displays},
year = {2022},
issue_date = {August 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {4},
issn = {1073-0516},
url = {https://doi.org/10.1145/3492802},
doi = {10.1145/3492802},
abstract = {Digital eye strain (DES), caused by prolonged exposure to digital screens, stresses the visual system and negatively affects users’ well-being and productivity. While DES is well-studied in computer displays, its impact on users of virtual reality (VR) head-mounted displays (HMDs) is largely unexplored—despite that some of their key properties (e.g., the vergence-accommodation conflict) make VR-HMDs particularly prone. This work provides the first comprehensive investigation into DES in VR HMDs. We present results from a survey with 68 experienced users to understand DES symptoms in VR-HMDs. To help address DES, we investigate eye exercises resulting from survey answers and blue light filtering in three user studies (N = 71). Results demonstrate that eye exercises, but not blue light filtering, can effectively reduce DES. We conclude with an extensive analysis of the user studies and condense our findings in 10 key challenges that guide future work in this emerging research area.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = mar,
articleno = {33},
numpages = {80},
keywords = {Virtual reality, digital eye strain, well-being},
tags = {CHI22,Journal}
}
@article{10.1145/3490554,
author = {Putze, Felix and Putze, Susanne and Sagehorn, Merle and Micek, Christopher and Solovey, Erin T.},
title = {Understanding HCI Practices and Challenges of Experiment Reporting with Brain Signals: Towards Reproducibility and Reuse},
year = {2022},
issue_date = {August 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {4},
issn = {1073-0516},
url = {https://doi.org/10.1145/3490554},
doi = {10.1145/3490554},
abstract = {In human-computer interaction (HCI), there has been a push towards open science, but to date, this has not happened consistently for HCI research utilizing brain signals due to unclear guidelines to support reuse and reproduction. To understand existing practices in the field, this paper examines 110 publications, exploring domains, applications, modalities, mental states and processes, and more. This analysis reveals variance in how authors report experiments, which creates challenges to understand, reproduce, and build on that research. It then describes an overarching experiment model that provides a formal structure for reporting HCI research with brain signals, including definitions, terminology, categories, and examples for each aspect. Multiple distinct reporting styles were identified through factor analysis and tied to different types of research. The paper concludes with recommendations and discusses future challenges. This creates actionable items from the abstract model and empirical observations to make HCI research with brain signals more reproducible and reusable.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = mar,
articleno = {31},
numpages = {43},
keywords = {reproducibility, experiment model, fNIRS, functional near-infrared spectroscopy, EEG, electroencephalography, Brain sensing},
tags = {CHI22,Journal}
}
@inproceedings{10.1145/3491102.3517641,
author = {Drey, Tobias and Albus, Patrick and der Kinderen, Simon and Milo, Maximilian and Segschneider, Thilo and Chanzab, Linda and Rietzler, Michael and Seufert, Tina and Rukzio, Enrico},
title = {Towards Collaborative Learning in Virtual Reality: A Comparison of Co-Located Symmetric and Asymmetric Pair-Learning},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517641},
doi = {10.1145/3491102.3517641},
abstract = {Pair-learning is beneficial for learning outcome, motivation, and social presence, and so is virtual reality (VR) by increasing immersion, engagement, motivation, and interest of students. Nevertheless, there is a research gap if the benefits of pair-learning and VR can be combined. Furthermore, it is not clear which influence it has if only one or both peers use VR. To investigate these aspects, we implemented two types of VR pair-learning systems, a symmetric system with both peers using VR and an asymmetric system with one using a tablet. In a user study (N=46), the symmetric system statistically significantly provided higher presence, immersion, player experience, and lower intrinsic cognitive load, which are all important for learning. Symmetric and asymmetric systems performed equally well regarding learning outcome, highlighting that both are valuable learning systems. We used these findings to define guidelines on how to design co-located VR pair-learning applications, including characteristics for symmetric and asymmetric systems.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {610},
numpages = {19},
keywords = {collaborative learning, pair-learning, signaling, symmetric and asymmetric system, virtual reality},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags = {CHI22,Full Paper}
}
@inproceedings{10.1145/3491101.3519824,
author = {Li, Jingyi and Frulli, Filippe and Clarke, Stella and Butz, Andreas},
title = {Towards Balancing Real-World Awareness and VR Immersion in Mobile VR},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3519824},
doi = {10.1145/3491101.3519824},
abstract = {Virtual Reality (VR) can be used to create immersive infotainment experiences for car passengers. However, not much is known about how to best incorporate the essentials of their surroundings for balancing real-world awareness and immersion. To address this gap, we explored 2D and 3D visual cues of the rear-seat space to notify passengers about different real-world tasks (lower armrest, take cup, close window, and hold handle) during a first-person game in VR. Results from our pilot study (n = 19) show that users perceive a lower workload in the task hold handle than all other tasks. They also feel more immersed in VR after completing this task, compared to take cup and close window. Based on our findings, we propose real-world task types, synchronous visual cues, and various input and transition approaches as promising future research directions.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {436},
numpages = {6},
keywords = {transitional interfaces, passenger, everyday mobile VR, HMD},
location = {New Orleans, LA, USA},
series = {CHI EA '22},
tags = {CHI22,Late Breaking Work}
}
@inproceedings{10.1145/3491102.3517447,
author = {Hoppe, Matthias and Baumann, Andrea and Tamunjoh, Patrick Chofor and Machulla, Tonja-Katrin and Wo\'{z}niak, Pawe\l{} W. and Schmidt, Albrecht and Welsch, Robin},
title = {There Is No First- or Third-Person View in Virtual Reality: Understanding the Perspective Continuum},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517447},
doi = {10.1145/3491102.3517447},
abstract = {Modern games make creative use of First- and Third-person perspectives (FPP and TPP) to allow the player to explore virtual worlds. Traditionally, FPP and TPP perspectives are seen as distinct concepts. Yet, Virtual Reality (VR) allows for flexibility in choosing perspectives. We introduce the notion of a perspective continuum in VR, which is technically related to the camera position and conceptually to how users perceive their environment in VR. A perspective continuum enables adapting and manipulating the sense of agency and involvement in the virtual world. This flexibility of perspectives broadens the design space of VR experiences through deliberately manipulating perception. In a study, we explore users’ attitudes, experiences and perceptions while controlling a virtual character from the two known perspectives. Statistical analysis of the empirical results shows the existence of a perspective continuum in VR. Our findings can be used to design experiences based on shifts of perception.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {360},
numpages = {13},
keywords = {Embodiment, First Person, Perspective, Third Person, Virtual Reality},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags = {CHI22,Full Paper}
}
@inproceedings{10.1145/3491101.3519632,
author = {Mehrotra, Siddharth and Brocker, Anke and Obrist, Marianna and Borchers, Jan},
title = {The Scent of Collaboration: Exploring the Effect of Smell on Social Interactions},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3519632},
doi = {10.1145/3491101.3519632},
abstract = {Social interactions are multisensory experiences. However, it is not well understood how technology-mediated smell can support social interactions, especially in collaborative tasks. To explore its effect on collaboration, we asked eleven pairs of users to work together on a writing task while wearing an interactive jewellery designed to emit scent in a controlled fashion. In a within-subjects experiment, participants were asked to collaboratively write a story about a standardized visual stimulus while exposed to with scent and without scent conditions. We analyzed video recordings and written stories using a combination of methods from HCI, psychology, sociology, and human communication research. We observed differences in both participants’ communication and creation of insightful stories in the with scent condition. Furthermore, scent helped participants recover from communication breakdown even though they were unaware of it. We discuss the possible implications of our findings and the potential of technology-mediated scent for collaborative activities.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {303},
numpages = {7},
keywords = {Social Interactions, Smell, Scent, Olfactory Interfaces, Necklace, Communication, Collaboration},
location = {New Orleans, LA, USA},
series = {CHI EA '22},
tags = {CHI22,Late Breaking Work}
}
@inproceedings{10.1145/3491101.3503734,
author = {Schneider, Oliver and Fruchard, Bruno and Wittchen, Dennis and Joshi, Bibhushan Raj and Freitag, Georg and Degraen, Donald and Strohmeier, Paul},
title = {Sustainable Haptic Design: Improving Collaboration, Sharing, and Reuse in Haptic Design Research},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3503734},
doi = {10.1145/3491101.3503734},
abstract = {Haptic devices have been around for decades, providing critical information, usability benefits and improved experiences across tasks from surgical operations to playful applications in Mixed Reality. We see more and more software and hardware solutions emerging that provide design tools, design approaches and platforms, both in academia and industry. However, we believe that designers often re-invent the wheel, and must spend an inordinate amount of time doing their work, which is not sustainable for long-term research. This workshop aims at gathering people from academia and industry to provide a common ground to discuss various insights on and visions of the field. We aim to bring together the various strands of haptics—devices, software, and design—to assess the current state-of-the-art and propose an agenda towards haptics as a united design discipline. We expect the outcome of the workshop to be a comprehensive overview of existing tools and approaches, along with recommendations on how to move the field forward, together.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {79},
numpages = {5},
keywords = {sustainability, haptic design, encoding, design tools},
location = {New Orleans, LA, USA},
series = {CHI EA '22},
tags = {Workshop,CHI22}
}
@inproceedings{10.1145/3491102.3517462,
author = {Engert, Severin and Klamka, Konstantin and Peetz, Andreas and Dachselt, Raimund},
title = {STRAIDE: A Research Platform for Shape-Changing Spatial Displays based on Actuated Strings},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517462},
doi = {10.1145/3491102.3517462},
abstract = {We present STRAIDE, a string-actuated interactive display environment that allows to explore the promising potential of shape-changing interfaces for casual visualizations. At the core, we envision a platform that spatially levitates elements to create dynamic visual shapes in space. We conceptualize this type of tangible mid-air display and discuss its multifaceted design dimensions. Through a design exploration, we realize a physical research platform with adjustable parameters and modular components. For conveniently designing and implementing novel applications, we provide developer tools ranging from graphical emulators to in-situ augmented reality representations. To demonstrate STRAIDE’s reconfigurability, we further introduce three representative physical setups as a basis for situated applications including ambient notifications, personal smart home controls, and entertainment. They serve as a technical validation, lay the foundations for a discussion with developers that provided valuable insights, and encourage ideas for future usage of this type of appealing interactive installation.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {263},
numpages = {16},
keywords = {Casual Visualization, Data Physicalization, Prototyping Platform, Shape-Changing Interface, Spatial Display, Tangible Interaction},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags ={Full Paper,CHI22}
}
@inproceedings{10.1145/3491101.3519847,
author = {Hennig, Anne and Neusser, Fabian and Pawelek, Aleksandra Alicja and Herrmann, Dominik and Mayer, Peter},
title = {Standing out among the daily spam: How to catch website owners’ attention by means of vulnerability notifications},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3519847},
doi = {10.1145/3491101.3519847},
abstract = {Running a business without having a website is nearly impossible nowadays. Most business owners use content managements systems to manage their websites. Yet, those can pose security risks and provide vulnerabilities for manipulations. With vulnerability notifications, website owners are notified about security risks. To identify common themes with respect to vulnerability notifications and provide deeper insight into the motivations of website owners to react to those notifications, we conducted 25 semi-structured interviews. In compliance with previous research, we could confirm that distrust in unexpected notifications is high and, in contrast to previous research, we suggest that verification possibilities are the most important factors to establish trust in notifications. We also endorse the findings that raising awareness for the severity and the complexity of the problems is crucial to increase remediation rates.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {317},
numpages = {8},
keywords = {web security, vulnerability notification, security awareness, CMS vulnerabilities},
location = {New Orleans, LA, USA},
series = {CHI EA '22},
tags = {CHI22,Late Breaking Work}
}
@inproceedings{10.1145/3491102.3501981,
author = {Schmitz, Martin and G\"{u}nther, Sebastian and Sch\"{o}n, Dominik and M\"{u}ller, Florian},
title = {Squeezy-Feely: Investigating Lateral Thumb-Index Pinching as an Input Modality},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501981},
doi = {10.1145/3491102.3501981},
abstract = {From zooming on smartphones and mid-air gestures to deformable user interfaces, thumb-index pinching grips are used in many interaction techniques. However, there is still a lack of systematic understanding of how the accuracy and efficiency of such grips are affected by various factors such as counterforce, grip span, and grip direction. Therefore, in this paper, we contribute an evaluation (N = 18) of thumb-index pinching performance in a visual targeting task using scales up to 75 items. As part of our findings, we conclude that the pinching interaction between the thumb and index finger is a promising modality also for one-dimensional input on higher scales. Furthermore, we discuss and outline implications for future user interfaces that benefit from pinching as an additional and complementary interaction modality.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {61},
numpages = {15},
keywords = {Deformation, Input, Mixed Reality, Pinching, Thumb-to-finger, User Studies},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags ={Full Paper,CHI22}
}
@inproceedings{10.1145/3491101.3519856,
author = {Wolf, Sara and Moerike, Frauke and Luthe, Simon and Nord, Ilona and Hurtienne, J\"{o}rn},
title = {Spirituality at the Breakfast Table: Experiences of Christian Online Worship Services},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3519856},
doi = {10.1145/3491101.3519856},
abstract = {Since the COVID-19 pandemics, we have witnessed an increase in online worship services. Nevertheless, HCI has little insight into how technological mediation influences religious experiences and how technology should be designed for use in religious contexts. Therefore, we see a unique opportunity to understand better real-world experiences of technology use in religious rituals and, more specifically, in online worship services. Inspired by contextual design, We virtually observed and interviewed eight persons during and after participation in online worship services. We identified a field of tension between faith, everyday life, individuality, and community. The data suggests that current online worship service systems do not account for believers’ needs for community, faith, or extraordinariness. We discuss opportunities for future research and design, and aim to contribute to the understanding of online worship service experiences and the design of technology-mediated religious experiences.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {316},
numpages = {7},
keywords = {Religion, community, extraordinary, faith, prayer, ritual, spirituality},
location = {New Orleans, LA, USA},
series = {CHI EA '22},
tags = {CHI22,Late Breaking Work}
}
@inproceedings{10.1145/3491101.3519758,
author = {Queck, Dirk and Albert, Iannis and Burkard, Nicole and Zimmer, Philipp and Volkmar, Georg and D\"{a}nekas, Bastian and Malaka, Rainer and Herrlich, Marc},
title = {SpiderClip: Towards an Open Source System for Wearable Device Simulation in Virtual Reality},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3519758},
doi = {10.1145/3491101.3519758},
abstract = {Smartwatches and fitness trackers integrate different sensors from inertial measurement units to heart rate sensors in a very compact and affordable form factor. This makes them interesting and relevant research tools. One potential application domain is virtual reality, e.g., for health related applications such as exergames or simulation approaches. However, commercial devices complicate and limit the collection of raw and real-time data, suffer from privacy issues and are not tailored to using them with VR tracking systems. We address these issues with an open source design to facilitate the construction of VR-enabled wearables for conducting scientific experiments. Our work is motivated by research in mixed realities in pervasive computing environments. We introduce our system and present a proof-of-concept study with 17 participants. Our results show that the wearable reliably measures high-quality data comparable to commercially available fitness trackers and that it does not impede movements or interfere with VR tracking.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {341},
numpages = {7},
keywords = {wearable, virtual reality, user interface, sensors, open source, open science, 3d printing},
location = {New Orleans, LA, USA},
series = {CHI EA '22},
tags = {CHI22,Late Breaking Work}
}
@inproceedings{10.1145/3491101.3519770,
author = {Brocker, Anke and Str\"{u}ver, Jakob and Voelker, Simon and Borchers, Jan},
title = {SoRoCAD: A Design Tool for the Building Blocks of Pneumatic Soft Robotics},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3519770},
doi = {10.1145/3491101.3519770},
abstract = {Soft robotics uses soft, flexible materials and elastic actuation mechanisms to create systems that are more adaptable and tolerant to unknown environments, and safer for human-machine interaction, than rigid robots. Pneumatic soft robots can be fabricated using more affordable materials compared to traditional robots and make use of technologies such as 3D printing, making them an attractive choice for research and DIY projects. However, their design is still highly unintuitive, and at up to two days, design iterations can take prohibitively long: The behavior of, e.g., a pneumatic silicone gripper only becomes apparent after designing and 3D printing its mold, casting, curing, assembling, and testing it. We introduce SoRoCAD, a design tool supporting a Maker-friendly soft robotics design and fabrication pipeline that incorporates simulating the final actuation into the design process.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {330},
numpages = {7},
keywords = {User Empowerment, Soft Robotics, Simulation, Fabrication, CAD Design},
location = {New Orleans, LA, USA},
series = {CHI EA '22},
tags = {CHI22,Late Breaking Work}
}
@inproceedings{10.1145/3491102.3517454,
author = {G\"{u}nther, Sebastian and Rasch, Julian and Sch\"{o}n, Dominik and M\"{u}ller, Florian and Schmitz, Martin and Riemann, Jan and Matviienko, Andrii and M\"{u}hlh\"{a}user, Max},
title = {Smooth as Steel Wool: Effects of Visual Stimuli on the Haptic Perception of Roughness in Virtual Reality},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517454},
doi = {10.1145/3491102.3517454},
abstract = {Haptic Feedback is essential for lifelike Virtual Reality (VR) experiences. To provide a wide range of matching sensations of being touched or stroked, current approaches typically need large numbers of different physical textures. However, even advanced devices can only accommodate a limited number of textures to remain wearable. Therefore, a better understanding is necessary of how expectations elicited by different visualizations affect haptic perception, to achieve a balance between physical constraints and great variety of matching physical textures. In this work, we conducted an experiment (N=31) assessing how the perception of roughness is affected within VR. We designed a prototype for arm stroking and compared the effects of different visualizations on the perception of physical textures with distinct roughnesses. Additionally, we used the visualizations’ real-world materials, no-haptics and vibrotactile feedback as baselines. As one result, we found that two levels of roughness can be sufficient to convey a realistic illusion.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {399},
numpages = {17},
keywords = {caress, haptic feedback, perception, roughness, stroke, touch, virtual reality},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags = {Full Paper,CHI22}
}
@inproceedings{10.1145/3491102.3501983,
author = {Matviienko, Andrii and M\"{u}ller, Florian and Schmitz, Martin and Fendrich, Marco and M\"{u}hlh\"{a}user, Max},
title = {SkyPort: Investigating 3D Teleportation Methods in Virtual Environments},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501983},
doi = {10.1145/3491102.3501983},
abstract = {Teleportation has become the de facto standard of locomotion in Virtual Reality (VR) environments. However, teleportation with parabolic and linear target aiming methods is restricted to horizontal 2D planes and it is unknown how they transfer to the 3D space. In this paper, we propose six 3D teleportation methods in virtual environments based on the combination of two existing aiming methods (linear and parabolic) and three types of transitioning to a target (instant, interpolated and continuous). To investigate the performance of the proposed teleportation methods, we conducted a controlled lab experiment (N = 24) with a mid-air coin collection task to assess accuracy, efficiency and VR sickness. We discovered that the linear aiming method leads to faster and more accurate target selection. Moreover, a combination of linear aiming and instant transitioning leads to the highest efficiency and accuracy without increasing VR sickness.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {516},
numpages = {11},
keywords = {locomotion, teleportation, virtual environments, virtual reality},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags = {Full Paper,Honorable Mention,CHI22}
}
@inproceedings{10.1145/3491102.3517473,
author = {Nowak, Oliver and Sch\"{a}fer, Ren\'{e} and Brocker, Anke and Wacker, Philipp and Borchers, Jan},
title = {Shaping Textile Sliders: An Evaluation of Form Factors and Tick Marks for Textile Sliders},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517473},
doi = {10.1145/3491102.3517473},
abstract = {Textile interfaces enable designers to integrate unobtrusive media and smart home controls into furniture such as sofas. While the technical aspects of such controllers have been the subject of numerous research projects, the physical form factor of these controls has received little attention so far. This work investigates how general design properties, such as overall slider shape, raised vs. recessed sliders, and number and layout of tick marks, affect users’ preferences and performance. Our first user study identified a preference for certain design combinations, such as recessed, closed-shaped sliders. Our second user study included performance measurements on variations of the preferred designs from study&nbsp;1, and took a closer look at tick marks. Tick marks supported orientation better than slider shape. Sliders with at least three tick marks were preferred, and performed well. Non-uniform, equally distributed tick marks reduced the movements users needed to orient themselves on the slider.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {214},
numpages = {14},
keywords = {Continuous input, Design recommendations, Embroidery, Eyes-free interaction, Non-wearables, Sliders, Smart textiles, Textile interfaces},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags = {Full Paper,CHI22}
}
@inproceedings{10.1145/3491102.3517682,
author = {Stemasov, Evgeny and Wagner, Tobias and Gugenheimer, Jan and Rukzio, Enrico},
title = {ShapeFindAR: Exploring In-Situ Spatial Search for Physical Artifact Retrieval using Mixed Reality},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517682},
doi = {10.1145/3491102.3517682},
abstract = {Personal fabrication is made more accessible through repositories like Thingiverse, as they replace modeling with retrieval. However, they require users to translate spatial requirements to keywords, which paints an incomplete picture of physical artifacts: proportions or morphology are non-trivially encoded through text only. We explore a vision of in-situ spatial search for (future) physical artifacts, and present ShapeFindAR, a mixed-reality tool to search for 3D models using in-situ sketches blended with textual queries. With ShapeFindAR, users search for geometry, and not necessarily precise labels, while coupling the search process to the physical environment (e.g., by sketching in-situ, extracting search terms from objects present, or tracing them). We developed ShapeFindAR for HoloLens 2, connected to a database of 3D-printable artifacts. We specify in-situ spatial search, describe its advantages, and present walkthroughs using ShapeFindAR, which highlight novel ways for users to articulate their wishes, without requiring complex modeling tools or profound domain knowledge.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {292},
numpages = {12},
keywords = {3D-Printing, In-Situ Search, Mixed Reality, Model Repositories, Personal Fabrication, Physical Artifact Retrieval, Spatial Search},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags = {Full Paper,CHI22}
}
@article{10.1145/3472617,
author = {Radiah, Rivu and M\"{a}kel\"{a}, Ville and Prange, Sarah and Rodriguez, Sarah Delgado and Piening, Robin and Zhou, Yumeng and K\"{o}hle, Kay and Pfeuffer, Ken and Abdelrahman, Yomna and Hoppe, Matthias and Schmidt, Albrecht and Alt, Florian},
title = {Remote VR Studies: A Framework for Running Virtual Reality Studies Remotely Via Participant-Owned HMDs},
year = {2021},
issue_date = {December 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {28},
number = {6},
issn = {1073-0516},
url = {https://doi.org/10.1145/3472617},
doi = {10.1145/3472617},
abstract = {We investigate opportunities and challenges of running virtual reality (VR) studies remotely. Today, many consumers own head-mounted displays (HMDs), allowing them to participate in scientific studies from their homes using their own equipment. Researchers can benefit from this approach by being able to recruit study populations normally out of their reach, and to conduct research at times when it is difficult to get people into the lab (cf. the COVID pandemic). In an initial online survey (N = 227), we assessed HMD owners’ demographics, their VR setups and their attitudes toward remote participation. We then identified different approaches to running remote studies and conducted two case studies for an in-depth understanding. We synthesize our findings into a framework for remote VR studies, discuss strengths and weaknesses of the different approaches, and derive best practices. Our work is valuable for Human-Computer Interaction (HCI) researchers conducting VR studies outside labs.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = nov,
articleno = {46},
numpages = {36},
keywords = {data collection methods, remote studies, user studies, Virtual reality},
tags = {Journal,CHI22}
}
@inproceedings{10.1145/3491102.3517550,
author = {Hubenschmid, Sebastian and Wieland, Jonathan and Fink, Daniel Immanuel and Batch, Andrea and Zagermann, Johannes and Elmqvist, Niklas and Reiterer, Harald},
title = {ReLive: Bridging In-Situ and Ex-Situ Visual Analytics for Analyzing Mixed Reality User Studies},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517550},
doi = {10.1145/3491102.3517550},
abstract = {The nascent field of mixed reality is seeing an ever-increasing need for user studies and field evaluation, which are particularly challenging given device heterogeneity, diversity of use, and mobile deployment. Immersive analytics tools have recently emerged to support such analysis in situ, yet the complexity of the data also warrants an ex-situ analysis using more traditional non-immersive visual analytics setups. To bridge the gap between both approaches, we introduce ReLive: a mixed-immersion visual analytics framework for exploring and analyzing mixed reality user studies. ReLive combines an in-situ virtual reality view with a complementary ex-situ desktop view. While the virtual reality view allows users to relive interactive spatial recordings replicating the original study, the synchronized desktop view provides a familiar interface for analyzing aggregated data. We validated our concepts in a two-step evaluation consisting of a design walkthrough and an empirical expert user study.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {24},
numpages = {20},
keywords = {Immersive analytics, data visualization, virtual reality., visual analytics},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags = {Full Paper,CHI22}
}
@inproceedings{10.1145/3491102.3501959,
author = {Matviienko, Andrii and M\"{u}ller, Florian and Zickler, Marcel and Gasche, Lisa Alina and Abels, Julia and Steinert, Till and M\"{u}hlh\"{a}user, Max},
title = {Reducing Virtual Reality Sickness for Cyclists in VR Bicycle Simulators},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501959},
doi = {10.1145/3491102.3501959},
abstract = {Virtual Reality (VR) bicycle simulations aim to recreate the feeling of riding a bicycle and are commonly used in many application areas. However, current solutions still create mismatches between the visuals and physical movement, which causes VR sickness and diminishes the cycling experience. To reduce VR sickness in bicycle simulators, we conducted two controlled lab experiments addressing two main causes of VR sickness: (1) steering methods and (2) cycling trajectory. In the first experiment (N = 18) we compared handlebar, HMD, and upper-body steering methods. In the second experiment (N = 24) we explored three types of movement in VR (1D, 2D, and 3D trajectories) and three countermeasures (airflow, vibration, and dynamic Field-of-View) to reduce VR sickness. We found that handlebar steering leads to the lowest VR sickness without decreasing cycling performance and airflow suggests to be the most promising method to reduce VR sickness for all three types of trajectories.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {187},
numpages = {14},
keywords = {VR sickness, bicycle simulators, cycling, virtual reality},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags = {Full Paper,CHI22}
}
@inproceedings{10.1145/3491102.3517593,
author = {Huang, Ann and Knierim, Pascal and Chiossi, Francesco and Chuang, Lewis L and Welsch, Robin},
title = {Proxemics for Human-Agent Interaction in Augmented Reality},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517593},
doi = {10.1145/3491102.3517593},
abstract = {Augmented Reality (AR) embeds virtual content in physical spaces, including virtual agents that are known to exert a social presence on users. Existing design guidelines for AR rarely consider the social implications of an agent’s personal space (PS) and that it can impact user behavior and arousal. We report an experiment (N=54) where participants interacted with agents in an AR art gallery scenario. When participants approached six virtual agents (i.e., two males, two females, a humanoid robot, and a pillar) to ask for directions, we found that participants respected the agents’ PS and modulated interpersonal distances according to the human-like agents’ perceived gender. When participants were instructed to walk through the agents, we observed heightened skin-conductance levels that indicate physiological arousal. These results are discussed in terms of proxemic theory that result in design recommendations for implementing pervasive AR experiences with virtual agents.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {421},
numpages = {13},
keywords = {Augmented Reality, Human-Agent Interaction, Perception, Personal Space, Proxemics, Virtual Agents},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags = {Full Paper,CHI22}
}
@inproceedings{10.1145/3491102.3502074,
author = {Pourjafarian, Narjes and Koelle, Marion and Mjaku, Fjolla and Strohmeier, Paul and Steimle, J\"{u}rgen},
title = {Print-A-Sketch: A Handheld Printer for Physical Sketching of Circuits and Sensors on Everyday Surfaces},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502074},
doi = {10.1145/3491102.3502074},
abstract = {We present Print-A-Sketch, an open-source handheld printer prototype for sketching circuits and sensors. Print-A-Sketch combines desirable properties from free-hand sketching and functional electronic printing. Manual human control of large strokes is augmented with computer control of fine detail. Shared control of Print-A-Sketch supports sketching interactive interfaces on everyday objects – including many objects with materials or sizes which otherwise are difficult to print on. We present an overview of challenges involved in such a system and show how these can be addressed using context-aware, dynamic printing. Continuous sensing ensures quality prints by adjusting inking-rate to hand movement and material properties. Continuous sensing also enables the print to adapt to previously printed traces to support incremental and iterative sketching. Results show good conductivity on many materials and high spatial precision, supporting on-the-fly creation of functional interfaces.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {270},
numpages = {17},
keywords = {Fabrication, conductive inkjet printing, new materials, printed electronics, prototyping, sketching interfaces},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags = {Full Paper,CHI22}
}
@inproceedings{10.1145/3491101.3519827,
author = {Volk, Vera and Prange, Sarah and Alt, Florian},
title = {PriCheck– An Online Privacy Assistant for Smart Device Purchases},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3519827},
doi = {10.1145/3491101.3519827},
abstract = {In this paper, we present PriCheck, a browser extension that provides privacy-relevant information about smart devices (e.g., in an online shop). This information is oftentimes hidden, difficult to access, and, thus, often neglected when buying a new device. With PriCheck, we enable users to make informed purchase decisions. We conducted an exploratory study using the browser extension in a simplified (mock) online shop for smart devices. Participants chose devices with and without using the extension. We found that participants (N = 11) appreciated the usability and available information of PriCheck, helping them with informed decisions for privacy-preserving products. We hope our work will stimulate further discussion on how to make privacy information for novel products available, understandable, and easy to access for users.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {275},
numpages = {5},
keywords = {usable security, smart devices, privacy, browser extension},
location = {New Orleans, LA, USA},
series = {CHI EA '22},
tags = {Late Breaking Work,CHI22}
}
@inproceedings{10.1145/3491102.3517463,
author = {Marchetti, Emanuela and Grimme, Sophie and Hornecker, Eva and Kollakidou, Avgi and Graf, Philipp},
title = {Pet-Robot or Appliance? Care Home Residents with Dementia Respond to a Zoomorphic Floor Washing Robot},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517463},
doi = {10.1145/3491102.3517463},
abstract = {Any active entity that shares space with people is interpreted as a social actor. Based on this notion, we explore how robots that integrate functional utility with a social role and character can integrate meaningfully into daily practice. Informed by interviews and observations, we designed a zoomorphic floor cleaning robot which playfully interacts with care home residents affected by dementia. A field study shows that playful interaction can facilitate the introduction of utilitarian robots in care homes, being nonthreatening and easy to make sense of. Residents previously reacted with distress to a Roomba robot, but were now amused by and played with our cartoonish cat robot or simply tolerated its presence. They showed awareness of the machine-nature of the robot, even while engaging in pretend-play. A playful approach to the design of functional robots can thus explicitly conceptualize such robots as social actors in their context of use.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {512},
numpages = {21},
keywords = {assistive robot, care home, character design, dementia, field study, playful design, pretend-play, social robot, toy},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags = {Full Paper,CHI22}
}
@inproceedings{10.1145/3491102.3501937,
author = {M\"{a}kel\"{a}, Ville and Winter, Jonas and Schwab, Jasmin and Koch, Michael and Alt, Florian},
title = {Pandemic Displays: Considering Hygiene on Public Touchscreens in the Post-Pandemic Era},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501937},
doi = {10.1145/3491102.3501937},
abstract = {The COVID-19 pandemic created unprecedented questions for touch-based public displays regarding hygiene, risks, and general awareness. We study how people perceive and consider hygiene on shared touchscreens, and how touchscreens could be improved through hygiene-related functions. First, we report the results from an online survey (n = 286). Second, we present a hygiene concept for touchscreens that visualizes prior touches and provides information about the cleaning of the display and number of prior users. Third, we report the feedback for our hygiene concept from 77 participants. We find that there is demand for improved awareness of public displays’ hygiene status, especially among those with stronger concerns about COVID-19. A particularly desired detail is when the display has been cleaned. For visualizing prior touches, fingerprints worked best. We present further considerations for designing for hygiene on public displays.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {284},
numpages = {12},
keywords = {COVID-19, Hygiene, Pandemic, Public displays, Touch interaction},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags = {Full Paper,CHI22}
}
@inproceedings{10.1145/3491101.3519793,
author = {Ruoff, Marcel and Myers, Brad A and Maedche, Alexander},
title = {ONYX - User Interfaces for Assisting in Interactive Task Learning for Natural Language Interfaces of Data Visualization Tools},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3519793},
doi = {10.1145/3491101.3519793},
abstract = {While natural language interfaces (NLIs) are increasingly utilized to simplify the interaction with data visualization tools, improving and adapting the NLIs to the individual needs of users still requires the support of developers. ONYX introduces an interactive task learning (ITL) based approach which enables NLIs to learn from users through natural interactions. Users can personalize the NLI with new commands using direct manipulation, known commands, or by combining both. To further support users during the training process, we derived two design goals for the user interface, namely providing suggestions based on sub-parts of the command and addressing ambiguities through follow-up questions and instantiated them in ONYX. In order to trigger reflections and gain feedback on possible design trade-offs of ONYX and the instantiated design goals, we performed a formative user study to understand how to successfully integrate the suggestions and follow-up question into the interaction.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {433},
numpages = {7},
keywords = {Data visualization tools, Interactive task learning, Natural language interfaces, Participatory design},
location = {New Orleans, LA, USA},
series = {CHI EA '22},
tags = {Full Paper,CHI22}
}
@inproceedings{10.1145/3491101.3519676,
author = {Alizadeh, Fatemeh and Mniestri, Aikaterini and Uhde, Alarith and Stevens, Gunnar},
title = {On Appropriation and Nostalgic Reminiscence of Technology},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3519676},
doi = {10.1145/3491101.3519676},
abstract = {Technological objects present themselves as necessary, only to become obsolete faster than ever before. This phenomenon has led to a population that experiences a plethora of technological objects and interfaces as they age, which become associated with certain stages of life and disappear thereafter. Noting the expanding body of literature within HCI about appropriation, our work pinpoints an area that needs more attention, “outdated technologies.” In other words, we assert that design practices can profit as much from imaginaries of the future as they can from reassessing artefacts from the past in a critical way. In a two-week fieldwork with 37 HCI students, we gathered an international collection of nostalgic devices from 14 different countries to investigate what memories people still have of older technologies and the ways in which these memories reveal normative and accidental use of technological objects. We found that participants primarily remembered older technologies with positive connotations and shared memories of how they had adapted and appropriated these technologies, rather than normative uses. We refer to this phenomenon as nostalgic reminiscence. In the future, we would like to develop this concept further by discussing how nostalgic reminiscence can be operationalized to stimulate speculative design in the present.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {287},
numpages = {6},
keywords = {storytelling, remembering, nostalgia, memories, appropriation, Interaction design},
location = {New Orleans, LA, USA},
series = {CHI EA '22},
tags = {Late Breaking Work,CHI22}
}
@inproceedings{10.1145/3491102.3517668,
author = {Nittala, Aditya Shekhar and Steimle, J\"{u}rgen},
title = {Next Steps in Epidermal Computing: Opportunities and Challenges for Soft On-Skin Devices},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517668},
doi = {10.1145/3491102.3517668},
abstract = {Skin is a promising interaction medium and has been widely explored for mobile, and expressive interaction. Recent research in HCI has seen the development of Epidermal Computing Devices: ultra-thin and non-invasive devices which reside on the user’s skin, offering intimate integration with the curved surfaces of the body, while having physical and mechanical properties that are akin to skin, expanding the horizon of on-body interaction. However, with rapid technological advancements in multiple disciplines, we see a need to synthesize the main open research questions and opportunities for the HCI community to advance future research in this area. By systematically analyzing Epidermal Devices contributed in the HCI community, physical sciences research and from our experiences in designing and building Epidermal Devices, we identify opportunities and challenges for advancing research across five themes. This multi-disciplinary synthesis enables multiple research communities to facilitate progression towards more coordinated endeavors for advancing Epidermal Computing.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {389},
numpages = {22},
keywords = {epidermal devices, soft wearables, survey, wearable devices},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags = {Full Paper,CHI22}
}
@inproceedings{10.1145/3491102.3501861,
author = {Wagener, Nadine and Niess, Jasmin and Rogers, Yvonne and Sch\"{o}ning, Johannes},
title = {Mood Worlds: A Virtual Environment for Autonomous Emotional Expression},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501861},
doi = {10.1145/3491102.3501861},
abstract = {Immersive interactive technologies such as virtual reality (VR) have the potential to foster well-being. While VR applications have been successfully used to evoke positive emotions through the presetting of light, colour and scenery, the experiential potential of allowing users to independently create a virtual environment (VE) has not yet been sufficiently addressed. To that end, we explore how the autonomous design of a VE can affect emotional engagement and well-being. We present Mood Worlds – a VR application allowing users to visualise their emotions by self-creating a VE. In an exploratory evaluation (N=16), we found that Mood Worlds is an effective tool supporting emotional engagement. Additionally, we found that an autonomous creation process in VR increases positive emotions and well-being. Our work shows that VR can be an effective tool to visualise emotions, thereby increasing positive affect. We discuss opportunities and design requirements for VR as positive technology.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {22},
numpages = {16},
keywords = {Emotion Regulation, Emotions, Happiness, Positive Technology, Virtual Reality, Well-being},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags = {Full Paper,CHI22}
}
@inproceedings{10.1145/3491101.3519804,
author = {Saad, Alia and Gruenefeld, Uwe and Mecke, Lukas and Koelle, Marion and Alt, Florian and Schneegass, Stefan},
title = {Mask removal isn’t always convenient in public! – The Impact of the Covid-19 Pandemic on Device Usage and User Authentication},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3519804},
doi = {10.1145/3491101.3519804},
abstract = {The ongoing Covid-19 pandemic has impacted our everyday lives and demands everyone to take countermeasures such as wearing masks or disinfecting their hands. However, while previous work suggests that these countermeasures may profoundly impact biometric authentication, an investigation of the actual impact is still missing. Hence, in this work, we present our findings from an online survey (n=334) on experienced changes in device usage and failures of authentication. Our results show significant changes in personal and shared device usage, as well as a significant increase in experienced failures when comparing the present situation to before the Covid-19 pandemic. From our qualitative analysis of participants’ responses, we derive potential reasons for these changes in device usage and increases in authentication failures. Our findings suggest that making authentication contactless is only one of the aspects relevant to encounter the novel challenges caused by the pandemic.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {218},
numpages = {7},
keywords = {Covid-19, authentication, biometrics, mobile devices, usable security},
location = {New Orleans, LA, USA},
series = {CHI EA '22},
tags = {Late Breaking Work,CHI22}
}
@inproceedings{10.1145/3491102.3517684,
author = {Haas, Gabriel and Rietzler, Michael and Jones, Matt and Rukzio, Enrico},
title = {Keep it Short: A Comparison of Voice Assistants’ Response Behavior},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517684},
doi = {10.1145/3491102.3517684},
abstract = {Voice assistants (VAs) are present in homes, smartphones, and cars. They allow users to perform tasks without graphical or tactile user interfaces, as they are designed for natural language interaction. However, we found that currently, VAs are emulating human behavior by responding in complete sentences, limiting the design options, and preventing VAs from meeting their full potential as a utilitarian tool. We implemented a VA that handles requests in three response styles: two differing short keyword-based response styles and a full-sentence baseline. In a user study, 72 participants interacted with our VA by issuing eight requests. Results show that the short responses were perceived similarly useful and likable while being perceived as more efficient, especially for commands, and sometimes better to comprehend than the baseline. To achieve widespread adoption, we argue that VAs should be customizable and adapt to users instead of always responding in full sentences.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {321},
numpages = {12},
keywords = {virtual assistant, voice assistant, voice user interface},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags = {Full Paper,CHI22}
}
@inproceedings{10.1145/3491102.3501943,
author = {Windl, Maximiliane and Feger, Sebastian S. and Zijlstra, Lara and Schmidt, Albrecht and Wozniak, Pawel W.},
title = {‘It Is Not Always Discovery Time’: Four Pragmatic Approaches in Designing AI Systems},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501943},
doi = {10.1145/3491102.3501943},
abstract = {While systems that use Artificial Intelligence (AI) are increasingly becoming part of everyday technology use, we do not fully understand how AI changes design processes. A structured understanding of how designers work with AI is needed to improve the design process and educate future designers. To that end, we conducted interviews with designers who participated in projects which used AI. While past work focused on AI systems created by experienced designers, we focus on the perspectives of a diverse sample of interaction designers. Our results show that the design process of an interactive system is affected when AI is integrated and that design teams adapt their processes to accommodate AI. Based on our data, we contribute four approaches adopted by interaction designers working with AI: a priori, post-hoc, model-centric, and competence-centric. Our work contributes a pragmatic account of how design processes for AI systems are enacted.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {50},
numpages = {12},
keywords = {artificial intelligence, data work, design, process},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags = {Full Paper,CHI22}
}
@article{10.1145/3459604,
author = {Marky, Karola and Zollinger, Marie-Laure and Roenne, Peter and Ryan, Peter Y. A. and Grube, Tim and Kunze, Kai},
title = {Investigating Usability and User Experience of Individually Verifiable Internet Voting Schemes},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {28},
number = {5},
issn = {1073-0516},
url = {https://doi.org/10.1145/3459604},
doi = {10.1145/3459604},
abstract = {Internet voting can afford more inclusive and inexpensive elections. The flip side is that the integrity of the election can be compromised by adversarial attacks and malfunctioning voting infrastructure. Individual verifiability aims to protect against such risks by letting voters verify that their votes are correctly registered in the electronic ballot box. Therefore, voters need to carry out additional tasks making human factors crucial for security. In this article, we establish a categorization of individually verifiable Internet voting schemes based on voter interactions. For each category in our proposed categorization, we evaluate a voting scheme in a user study with a total of 100 participants. In our study, we assessed usability, user experience, trust, and further qualitative data to gain deeper insights into voting schemes. Based on our results, we conclude with recommendations for developers and policymakers to inform the choices and design of individually verifiable Internet voting schemes.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = sep,
articleno = {30},
numpages = {36},
keywords = {human factors, individual verifiability, Internet voting, E-Voting},
tags = {Journal,CHI22}
}
@inproceedings{10.1145/3491101.3503743,
author = {Marky, Karola and Kilian, Annika and Wei\ss{}, Andreas and Karolus, Jakob and Hoppe, Matthias and Wozniak, Pawel W. and M\"{u}hlh\"{a}user, Max and Kosch, Thomas},
title = {Intelligent Music Interfaces: When Interactive Assistance and Augmentation Meet Musical Instruments},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3503743},
doi = {10.1145/3491101.3503743},
abstract = {The interactive augmentation of musical instruments to foster self-expressiveness and learning has a rich history. Over the past decades, the incorporation of interactive technologies into musical instruments emerged into a new research field requiring strong collaboration between different disciplines. The workshop ”Intelligent Music Interfaces” consequently covers a wide range of musical research subjects and directions, including (a) current challenges in musical learning, (b) prototyping for improvements, (c) new means of musical expression, and (d) evaluation of the solutions.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {84},
numpages = {4},
keywords = {Artistic Performance, Augmented Instruments, Music Interfaces, Musical Instruments, Self-Expression},
location = {New Orleans, LA, USA},
series = {CHI EA '22},
tags = {Workshop,CHI22}
}
@inproceedings{10.1145/3491101.3519621,
author = {Auda, Jonas and Gruenefeld, Uwe and Schneegass, Stefan},
title = {If The Map Fits! Exploring Minimaps as Distractors from Non-Euclidean Spaces in Virtual Reality},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3519621},
doi = {10.1145/3491101.3519621},
abstract = {With non-Euclidean spaces, Virtual Reality (VR) experiences can more efficiently exploit the available physical space by using overlapping virtual rooms. However, the illusion created by these spaces can be discovered, if the overlap is too large. Thus, in this work, we investigate if users can be distracted from the overlap by showing a minimap that suggests that there is none. When done correctly, more VR space can be mapped into the existing physical space, allowing for more spacious virtual experiences. Through a user study, we found that participants uncovered the overlap of two virtual rooms when it was at 100\% or the overlapping room extended even further. Our results show that the additional minimap renders overlapping virtual rooms more believable and can serve as a helpful tool to use physical space more efficiently for natural locomotion in VR.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {297},
numpages = {6},
keywords = {Distraction, Illusions, Locomotion, Minimap, Non-Euclidean, Overlap, Virtual Reality},
location = {New Orleans, LA, USA},
series = {CHI EA '22},
tags = {Late Breaking Work,CHI22}
}
@inproceedings{10.1145/3491101.3519826,
author = {Elagroudy, Passant and Saleh, Mennatallah and Sturm, Christian and Schmidt, Albrecht},
title = {How do Users Expect their Smart Memory Vaults to Utilize Their Shared Memories?},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3519826},
doi = {10.1145/3491101.3519826},
abstract = {Social media (SM) is a popular accessible form of smart memory vaults. Prior work shows that users are still unable to understand how their shared memories are used by smart systems to create Smart Interactions involving Personal Memories (SIPMs). This can lead to negative social repercussions such as cyberbullying. This work investigates the most memorable SIPMs on Facebook for Egyptian users and their impact on platform usage. We conducted an online survey (N=53) requesting critical incident reports about surprising Facebook SIPMs. The most remembered SIPMs were: customizing advertisements, cuing offline interactions, sharing data with third parties and personalizing the newsfeed. Our results suggest that SIPMs, particularly customized advertisements act as ambient memory augmentation solutions to the users’ shared memories. Additionally, negative platform perception does not necessarily translate into reduction of platform usage. Our work inspires the discussion about users expectations towards ambient usage of their data on smart memory vaults.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {448},
numpages = {6},
keywords = {advertisements, affect, critical incident report, informed consent, memory vaults, personalization, privacy, social media, user experience},
location = {New Orleans, LA, USA},
series = {CHI EA '22},
tags = {Late Breaking Work,CHI22}
}
@inproceedings{10.1145/3491101.3503706,
author = {Cannanure, Vikram Kamath and Karusala, Naveena and Rivera-Loaiza, Cuauht\'{e}moc and Prabhakar, Annu Sible and Varanasi, Rama Adithya and Tuli, Anupriya and Gamage, Dilrukshi and Noor, Faria and Nemer, David and Das, Dipto and Dray, Susan and Sturm, Christian and Kumar, Neha},
title = {HCI Across Borders: Navigating Shifting Borders at CHI},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3503706},
doi = {10.1145/3491101.3503706},
abstract = {Human–Computer Interaction (HCI) research has led to major innovations used by large and diverse audiences in different parts of the world. However, a recent meta-analysis&nbsp;[25] found that research at CHI is still highly (73\%) concentrated in western contexts. HCI Across Borders (HCIxB) has gathered a diverse audience by conducting workshops and symposia since CHI 2016, aiming to expand borders within CHI. For CHI 2022, we expect to regroup for a virtual workshop to reflect on shifting boundaries from CHI’s past and emerging challenges in HCI research, education, and practice in recent years.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {115},
numpages = {5},
keywords = {Cultural Diversity, Geographic Diversity, HCI Across Borders, HCI and Global Development},
location = {New Orleans, LA, USA},
series = {CHI EA '22},
tags = {Workshop,CHI22}
}
@inproceedings{10.1145/3491102.3501953,
author = {Muender, Thomas and Bonfert, Michael and Reinschluessel, Anke Verena and Malaka, Rainer and D\"{o}ring, Tanja},
title = {Haptic Fidelity Framework: Defining the Factors of Realistic Haptic Feedback for Virtual Reality},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501953},
doi = {10.1145/3491102.3501953},
abstract = {Providing haptic feedback in virtual reality to make the experience more realistic has become a strong focus of research in recent years. The resulting haptic feedback systems differ greatly in their technologies, feedback possibilities, and overall realism making it challenging to compare different systems. We propose the Haptic Fidelity Framework providing the means to describe, understand and compare haptic feedback systems. The framework locates a system in the spectrum of providing realistic or abstract haptic feedback using the Haptic Fidelity dimension. It comprises 14 criteria that either describe foundational or limiting factors. A second Versatility dimension captures the current trade-off between highly realistic but application-specific and more abstract but widely applicable feedback. To validate the framework, we compared the Haptic Fidelity score to the perceived feedback realism of evaluations from 38 papers and found a strong correlation suggesting the framework accurately describes the realism of haptic feedback.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {431},
numpages = {17},
keywords = {feedback, fidelity, framework, haptic feedback, haptics, immersion, realism, user experience, versatility, virtual environment},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags = {Full Paper,CHI22}
}
@inproceedings{10.1145/3491102.3502141,
author = {Dang, Hai and Mecke, Lukas and Buschek, Daniel},
title = {GANSlider: How Users Control Generative Models for Images using Multiple Sliders with and without Feedforward Information},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502141},
doi = {10.1145/3491102.3502141},
abstract = {We investigate how multiple sliders with and without feedforward visualizations influence users’ control of generative models. In an online study (N=138), we collected a dataset of people interacting with a generative adversarial network (StyleGAN2) in an image reconstruction task. We found that more control dimensions (sliders) significantly increase task difficulty and user actions. Visual feedforward partly mitigates this by enabling more goal-directed interaction. However, we found no evidence of faster or more accurate task performance. This indicates a tradeoff between feedforward detail and implied cognitive costs, such as attention. Moreover, we found that visualizations alone are not always sufficient for users to understand individual control dimensions. Our study quantifies fundamental UI design factors and resulting interaction behavior in this context, revealing opportunities for improvement in the UI design for interactive applications of generative models. We close by discussing design directions and further aspects.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {569},
numpages = {15},
keywords = {dataset, generative adversarial network, image manipulation, interactive AI, user study},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags = {Full Paper,CHI22}
}
@inproceedings{10.1145/3491102.3501919,
author = {Park, Keunwoo and Lempert, Conrad and Abdullah, Muhammad and Katakura, Shohei and Shigeyama, Jotaro and Roumen, Thijs and Baudisch, Patrick},
title = {FoolProofJoint: Reducing Assembly Errors of Laser Cut 3D Models by Means of Custom Joint Patterns},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501919},
doi = {10.1145/3491102.3501919},
abstract = {We present FoolProofJoint, a software tool that simplifies the assembly of laser-cut 3D models and reduces the risk of erroneous assembly. FoolProofJoint achieves this by modifying finger joint patterns. Wherever possible, FoolProofJoint makes similar looking pieces fully interchangeable, thereby speeding up the user's visual search for a matching piece. When that is not possible, FoolProofJoint gives finger joints a unique pattern of individual finger placements so as to fit only with the correct piece, thereby preventing erroneous assembly. In our benchmark set of 217 laser-cut 3D models downloaded from kyub.com, FoolProofJoint made groups of similar looking pieces fully interchangeable for 65\% of all groups of similar pieces; FoolProofJoint fully prevented assembly mistakes for 97\% of all models.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {271},
numpages = {12},
keywords = {Personal fabrication, laser cutting, manual assembly, rapid prototyping},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags = {Full Paper,CHI22}
}
@inproceedings{10.1145/3491101.3519792,
author = {Langner, Moritz and Toreini, Peyman and Maedche, Alexander},
title = {EyeMeet: A Joint Attention Support System for Remote Meetings},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3519792},
doi = {10.1145/3491101.3519792},
abstract = {A major challenge in remote meetings is that awareness cues, such as gaze, become degraded despite playing a crucial role in communication and establishing joint attention. Eye tracking allows overcoming these obstacles by enabling augmentation of remote meetings with gaze information. In this project, we followed a participatory approach by first distributing a scenario-based survey to students (n=79) to uncover their preference of eye-based joint attention support (real-time, retrospective, real-time \& retrospective, no) for remote university meetings. Building on these findings, we developed EyeMeet, an eye-based joint attention support system that combines state-of-the-art real-time joint attention support with a retrospective attention feedback for remote meetings. In a four-week study, two student groups worked remotely on course assignments using EyeMeet. Our findings of the study highlight that EyeMeets supports students in staying more focused on the meetings. Complementing real-time joint attention support, retrospective joint attention feedback is recognized to provide valuable support for reflecting and adapting behavior for upcoming meetings.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {452},
numpages = {7},
keywords = {Remote meeting, Joint attention, Feedback, Eye tracking, Collaboration},
location = {New Orleans, LA, USA},
series = {CHI EA '22},
tags = {Late Breaking Work,CHI22}
}
@inproceedings{10.1145/3491101.3519715,
author = {Muender, Thomas and Reinschluessel, Anke Verena and Salzmann, Daniela and L\"{u}ck, Thomas and Schenk, Andrea and Weyhe, Dirk and D\"{o}ring, Tanja and Malaka, Rainer},
title = {Evaluating Soft Organ-Shaped Tangibles for Medical Virtual Reality},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3519715},
doi = {10.1145/3491101.3519715},
abstract = {Connecting digital information with the physical is one of the essential ideas of tangible user interfaces. The design of the physical representation is important especially for specialised domains like surgery planning, because surgeons rely heavily on their tactile senses. Therefore, this research work investigates the effect of a soft and a hard 3D model as an interaction device for virtual reality surgical planning. A user study with 13 surgeons reveals a clear preference for the softer, more realistic material and a significantly higher haptic user experience for the soft model compared to the hard one. These results advocate for stressing material aspects along with the interaction design in domains with an inherently high focus on tactile aspects.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {237},
numpages = {8},
keywords = {virtual reality, surgical planning, surgery, natural interaction, model, material, liver, 3D prints},
location = {New Orleans, LA, USA},
series = {CHI EA '22},
tags = {Late Breaking Work,CHI22}
}
@inproceedings{10.1145/3491102.3517714,
author = {Krau\ss{}, Veronika and Nebeling, Michael and Jasche, Florian and Boden, Alexander},
title = {Elements of XR Prototyping: Characterizing the Role and Use of Prototypes in Augmented and Virtual Reality Design},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517714},
doi = {10.1145/3491102.3517714},
abstract = {Current research in augmented, virtual, and mixed reality (XR) reveals a lack of tool support for designing and, in particular, prototyping XR applications. While recent tools research is often motivated by studying the requirements of non-technical designers and end-user developers, the perspective of industry practitioners is less well understood. In an interview study with 17 practitioners from different industry sectors working on professional XR projects, we establish the design practices in industry, from early project stages to the final product. To better understand XR design challenges, we characterize the different methods and tools used for prototyping and describe the role and use of key prototypes in the different projects. We extract common elements of XR prototyping, elaborating on the tools and materials used for prototyping and establishing different views on the notion of fidelity. Finally, we highlight key issues for future XR tools research.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {310},
numpages = {18},
keywords = {XR, augmented reality, authoring, interaction design, interface design., mixed reality, prototyping, virtual reality},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags = {Full Paper,CHI22}
}
@inproceedings{10.1145/3491102.3517571,
author = {Colley, Mark and Bajrovic, Elvedin and Rukzio, Enrico},
title = {Effects of Pedestrian Behavior, Time Pressure, and Repeated Exposure on Crossing Decisions in Front of Automated Vehicles Equipped with External Communication},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517571},
doi = {10.1145/3491102.3517571},
abstract = {Automated vehicles are expected to substitute driver-pedestrian communication via LED strips or displays. This communication is expected to improve trust and the crossing process in general. However, numerous factors such as other pedestrians’ behavior, perceived time pressure, or previous experience influence crossing decisions. Therefore, we report the results of a triply subdivided Virtual Reality study (N=18) evaluating these. Results show that external communication was perceived as hedonically pleasing, increased perceived safety and trust, and also that pedestrians’ behavior affected participants’ behavior. A timer did not alter crossing behavior, however, repeated exposure increased trust and reduced crossing times, showing a habituation effect. Our work helps better to integrate research on external communication in ecologically valid settings.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {367},
numpages = {11},
keywords = {Autonomous vehicles, Chicken Game, External communication, Pedestrian Behavior, eHMI.},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags = {Full Paper,CHI22}
}
@inproceedings{10.1145/3491101.3519831,
author = {Matviienko, Andrii and M\"{u}ller, Florian and Sch\"{o}n, Dominik and Fayard, R\'{e}gis and Abaspur, Salar and Li, Yi and M\"{u}hlh\"{a}user, Max},
title = {E-ScootAR: Exploring Unimodal Warnings for E-Scooter Riders in Augmented Reality},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3519831},
doi = {10.1145/3491101.3519831},
abstract = {Micro-mobility is becoming a more popular means of transportation. However, this increased popularity brings its challenges. In particular, the accident rates for E-Scooter riders increase, which endangers the riders and other road users. In this paper, we explore the idea of augmenting E-Scooters with unimodal warnings to prevent collisions with other road users, which include Augmented Reality (AR) notifications, vibrotactile feedback on the handlebar, and auditory signals in the AR glasses. We conducted an outdoor experiment (N = 13) using an Augmented Reality simulation and compared these types of warnings in terms of reaction time, accident rate, and feeling of safety. Our results indicate that AR and auditory warnings lead to shorter reaction times, have a better perception, and create a better feeling of safety than vibrotactile warnings. Moreover, auditory signals have a higher acceptance by the riders compared to the other two types of warnings.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {406},
numpages = {7},
keywords = {traffic safety, micro-mobility, augmented reality, E-Scooter},
location = {New Orleans, LA, USA},
series = {CHI EA '22},
tags = {Late Breaking Work,CHI22}
}
@inproceedings{10.1145/3491102.3517671,
author = {Feick, Martin and Regitz, Kora Persephone and Tang, Anthony and Kr\"{u}ger, Antonio},
title = {Designing Visuo-Haptic Illusions with Proxies in Virtual Reality: Exploration of Grasp, Movement Trajectory and Object Mass},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517671},
doi = {10.1145/3491102.3517671},
abstract = {Visuo-haptic illusions are a method to expand proxy-based interactions in VR by introducing unnoticeable discrepancies between the virtual and real world. Yet how different design variables affect the illusions with proxies is still unclear. To unpack a subset of variables, we conducted two user studies with 48 participants to explore the impact of (1) different grasping types and movement trajectories, and (2) different grasping types and object masses on the discrepancy which may be introduced. Our Bayes analysis suggests that grasping types and object masses (≤ 500 g) did not noticeably affect the discrepancy, but for movement trajectory, results were inconclusive. Further, we identified a significant difference between (un)restricted movement trajectories. Our data shows considerable differences in participants’ proprioceptive accuracy, which seem to correlate with their prior VR experience. Finally, we illustrate the impact of our key findings on the visuo-haptic illusion design process by showcasing a new design workflow.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {635},
numpages = {15},
keywords = {Grasp, Movement Trajectory, Object Mass, Visuo-Haptic Illusions},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags = {Full Paper,CHI22}
}
@inproceedings{10.1145/3491102.3502140,
author = {Rixen, Jan Ole and Colley, Mark and Askari, Ali and Gugenheimer, Jan and Rukzio, Enrico},
title = {Consent in the Age of AR: Investigating The Comfort With Displaying Personal Information in Augmented Reality},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502140},
doi = {10.1145/3491102.3502140},
abstract = {Social Media (SM) has shown that we adapt our communication and disclosure behaviors to available technological opportunities. Head-mounted Augmented Reality (AR) will soon allow to effortlessly display the information we disclosed not isolated from our physical presence (e.g., on a smartphone) but visually attached to the human body. In this work, we explore how the medium (AR vs. Smartphone), our role (being augmented vs. augmenting), and characteristics of information types (e.g., level of intimacy, self-disclosed vs. non-self-disclosed) impact the users’ comfort when displaying personal information. Conducting an online survey (N=148), we found that AR technology and being augmented negatively impacted this comfort. Additionally, we report that AR mitigated the effects of information characteristics compared to those they had on smartphones. In light of our results, we discuss that information augmentation should be built on consent and openness, focusing more on the comfort of the augmented rather than the technological possibilities.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {295},
numpages = {14},
keywords = {Augmented Reality, Comfort, Consent, Data Glasses, Disclosure, Mixed Reality, Personal Information, Public Experiences, Social Acceptability, User Acceptance},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags = {Full Paper,CHI22}
}
@inproceedings{10.1145/3491102.3517435,
author = {Carros, Felix and Schwaninger, Isabel and Preussner, Adrian and Randall, Dave and Wieching, Rainer and Fitzpatrick, Geraldine and Wulf, Volker},
title = {Care Workers Making Use of Robots: Results of a Three-Month Study on Human-Robot Interaction within a Care Home},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517435},
doi = {10.1145/3491102.3517435},
abstract = {Research on social robots in care has often focused on either the care recipients or the technology itself, neglecting the care workers who, in and through their collaborative and coordinative practices, will need to work with the robots. To better understand these interactions with a social robot (Pepper), we undertook a 3 month long-term study within a care home to gain empirical insights into the way the robot was used. We observed how care workers learned to use the device, applied it to their daily work life, and encountered obstacles. Our findings show that the care workers used the robot regularly (1:07 hours/day) mostly in one-to-one interactions with residents. While the robot had a limited effect on reducing the workload of care workers, it had other positive effects, demonstrating the potential to enhance the quality of care.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {631},
numpages = {15},
keywords = {Appropriation, CSCW, Care Robot, Care Work, Covid-19, Empirical Study, Empowerment, HCI, HRI, Humanoid, Long-term, Nurse, Pandemic, Participatory Design, Practice-based, Residential Care, Robotic Support, Social Robot, Social Service, Sustainable Technology Integration, Usage Patterns, Work Practices},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags = {Full Paper,CHI22}
}
@inproceedings{10.1145/3491101.3519631,
author = {Sousa Calepso, Aimee and Hube, Natalie and Berenguel Senn, Noah and Brandt, Vincent and Sedlmair, Michael},
title = {cARdLearner: Using Expressive Virtual Agents when Learning Vocabulary in Augmented Reality},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3519631},
doi = {10.1145/3491101.3519631},
abstract = {Augmented reality (AR) has a diverse range of applications, including language teaching. When studying a foreign language, one of the biggest challenges learners face is memorizing new vocabulary. While augmented holograms are a promising means of supporting this memorization process, few studies have explored their potential in the language learning context. We demonstrate the possibility of using flashcard along with an expressive holographic agent on vocabulary learning. Users scan a flashcard and play an animation that is connected with an emotion related to the word they are seeing. Our goal is to propose an alternative to the traditional use of flashcards, and also introduce another way of using AR in the association process.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {245},
numpages = {6},
keywords = {augmented reality, contextual learning, language learning},
location = {New Orleans, LA, USA},
series = {CHI EA '22},
tags = {Late Breaking Work,CHI22}
}
@inproceedings{10.1145/3491102.3517560,
author = {Matviienko, Andrii and M\"{u}ller, Florian and Sch\"{o}n, Dominik and Seesemann, Paul and G\"{u}nther, Sebastian and M\"{u}hlh\"{a}user, Max},
title = {BikeAR: Understanding Cyclists’ Crossing Decision-Making at Uncontrolled Intersections using Augmented Reality},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517560},
doi = {10.1145/3491102.3517560},
abstract = {Cycling has become increasingly popular as a means of transportation. However, cyclists remain a highly vulnerable group of road users. According to accident reports, one of the most dangerous situations for cyclists are uncontrolled intersections, where cars approach from both directions. To address this issue and assist cyclists in crossing decision-making at uncontrolled intersections, we designed two visualizations that: (1) highlight occluded cars through an X-ray vision and (2) depict the remaining time the intersection is safe to cross via a Countdown. To investigate the efficiency of these visualizations, we proposed an Augmented Reality simulation as a novel evaluation method, in which the above visualizations are represented as AR, and conducted a controlled experiment with 24 participants indoors. We found that the X-ray ensures a fast selection of shorter gaps between cars, while the Countdown facilitates a feeling of safety and provides a better intersection overview.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {366},
numpages = {15},
keywords = {augmented reality, crossing decision-making, cyclist safety},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags = {Full Paper,CHI22}
}
@inproceedings{10.1145/3491102.3517676,
author = {Reipschl\"{a}ger, Patrick and Brudy, Frederik and Dachselt, Raimund and Matejka, Justin and Fitzmaurice, George and Anderson, Fraser},
title = {AvatAR: An Immersive Analysis Environment for Human Motion Data Combining Interactive 3D Avatars and Trajectories},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517676},
doi = {10.1145/3491102.3517676},
abstract = {Analysis of human motion data can reveal valuable insights about the utilization of space and interaction of humans with their environment. To support this, we present AvatAR, an immersive analysis environment for the in-situ visualization of human motion data, that combines 3D trajectories with virtual avatars showing people’s detailed movement and posture. Additionally, we describe how visualizations can be embedded directly into the environment, showing what a person looked at or what surfaces they touched, and how the avatar’s body parts can be used to access and manipulate those visualizations. AvatAR combines an AR HMD with a tablet to provide both mid-air and touch interaction for system control, as well as an additional overview device to help users navigate the environment. We implemented a prototype and present several scenarios to show that AvatAR can enhance the analysis of human motion data by making data not only explorable, but experienceable.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {23},
numpages = {15},
keywords = {Immersive Analytics, In-situ visualisation, analysing space utilization, augmented/mixed reality, human motion data, motion analysis},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags = {Full Paper,CHI22}
}
@inproceedings{10.1145/3491102.3517688,
author = {Windl, Maximiliane and Henze, Niels and Schmidt, Albrecht and Feger, Sebastian S.},
title = {Automating Contextual Privacy Policies: Design and Evaluation of a Production Tool for Digital Consumer Privacy Awareness},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517688},
doi = {10.1145/3491102.3517688},
abstract = {Users avoid engaging with privacy policies because they are lengthy and complex, making it challenging to retrieve relevant information. In response, research proposed contextual privacy policies (CPPs) that embed relevant privacy information directly into their affiliated contexts. To date, CPPs are limited to concept showcases. This work evolves CPPs into a production tool that automatically extracts and displays concise policy information. We first evaluated the technical functionality on the US’s 500 most visited websites with 59 participants. Based on our results, we further revised the tool to deploy it in the wild with 11 participants over ten days. We found that our tool is effective at embedding CPP information on websites. Moreover, we found that the tool’s usage led to more reflective privacy behavior, making CPPs powerful in helping users understand the consequences of their online activities. We contribute design implications around CPP presentation to inform future systems design.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {34},
numpages = {18},
keywords = {contextual privacy, online services, privacy, privacy policies},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags = {Full Paper,CHI22}
}
@inproceedings{10.1145/3491101.3503766,
author = {Pfleging, Bastian and Kun, Andrew L and Shaer, Orit},
title = {Automated Vehicles as a Space for Work \& Wellbeing},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3503766},
doi = {10.1145/3491101.3503766},
abstract = {The objective of this in-person CHI course is to provide CHI attendees with an introduction and overview of the rapidly evolving field of automotive user interfaces (AutomotiveUI). The course will focus on UI aspects in the transition towards automated driving. In particular, we will also discuss the opportunities of cars as a new space for non-driving-related activities, such as work, relaxation, and play. For newcomers and experts of other HCI fields, we will present the special properties of this field of HCI and provide an overview of new opportunities, but also general design and evaluation aspects of novel automotive user interfaces.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {135},
numpages = {3},
keywords = {Automotive user interfaces, manual and automated driving, non-driving-related activities, work and wellbeing.},
location = {New Orleans, LA, USA},
series = {CHI EA '22},
tags = {Course,CHI22}
}
@inproceedings{10.1145/3411764.3445196,
author = {Gerling, Kathrin and Spiel, Katta},
title = {A Critical Examination of Virtual Reality Technology in the Context of the Minority Body},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445196},
doi = {10.1145/3411764.3445196},
abstract = {Virtual Reality (VR) holds the promise of immersing people in virtual worlds. However, initial work on the relationship between VR and disability suggests that VR is a body-centric technology that poses barriers for disabled users. We supplement this work with a theoretical analysis of immersive VR through the lens of Surrogate Body theory, a concept from media theory for the structured examination of interactive media in use. Leveraging Critical Disability Studies, particularly the theory of the Minority Body, we explore the assumptions about bodies inherent in VR, and we reflect on implications of these assumptions when disabled people engage with the technology. Our findings show that VR is an inherently ableist technology that assumes a ‘corporeal standard’ (i.e., an ‘ideal’, non-disabled human body), and fails to adequately accommodate disabled people. We conclude with implications for HCI research on VR, and discuss design approaches that foster inclusive technology development.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {599},
numpages = {14},
keywords = {Surrogate Body Theory, Disability Studies},
location = {Yokohama, Japan},
series = {CHI '21},
tags = {Full Paper,CHI22}
}
@inproceedings{10.1145/3491101.3503711,
author = {Brocker, Anke and Barreiros, Jose A. and Shtarbanov, Ali and Gohlke, Kristian and Kilic Afsar, Ozgun and Schr\"{o}der, S\"{o}ren},
title = {Actuated Materials and Soft Robotics Strategies for Human-Computer Interaction Design},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3503711},
doi = {10.1145/3491101.3503711},
abstract = {The fields of programmable matter, actuated materials, and Soft Robotics are becoming increasingly more relevant for the design of novel applications, interfaces, and user experiences in the domain of Human-Computer Interaction (HCI). These research fields often use soft, flexible materials with elastic actuation mechanisms to build systems that are more adaptable, compliant, and suitable for a very broad range of environments. However, at the intersection between HCI and the aforementioned domains, there are numerous challenges related to fabrication methods, development tools, resource availability,&nbsp;nomenclature, design for inclusion, etc. This workshop aims to explore how to make Soft Robotics more accessible to both researchers and nonresearchers alike. We will (1) investigate and identify the various difficulties people face when developing HCI applications that require the transfer of knowledge from those other domains, and (2) discuss possible solutions and visions on how to overcome those difficulties.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {81},
numpages = {7},
keywords = {Tangible Interfaces, Soft Robotics, Shape Change, Programmable Materials, Pneumatic, Interaction Design, HCI, Fluidic, Fabrication, Design Tools},
location = {New Orleans, LA, USA},
series = {CHI EA '22},
tags = {Workshop,CHI22}
}
@inproceedings{10.1145/3491101.3519701,
author = {Colley, Mark and Kr\"{a}nzle, Taras and Rukzio, Enrico},
title = {Accessibility-Related Publication Distribution in HCI Based on a Meta-Analysis},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3519701},
doi = {10.1145/3491101.3519701},
abstract = {Accessibility research aims to aid humans that experience minor or major disabilities and conditions. However, researchers might have limited exposure to certain disabilities, therefore, focus on those prevalent in their own lives. This work presents a script-based meta-analysis on addressed populations in accessibility research published on top Human-Computer Interaction (HCI) venues (3617 full papers). We categorize the publications regarding the involved people and their disabilities. We found that work on vision disability makes up for almost one third (28.85\%) of the work published in general HCI. In light of these findings, we present possible conference- and funding-related explanatory approaches and argue that disability research could more reflect the prevalence of disabilities in the world.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {299},
numpages = {28},
keywords = {survey., overview, Accessibility},
location = {New Orleans, LA, USA},
series = {CHI EA '22},
tags = {Late Breaking Work,CHI22}
}
@inproceedings{10.1145/3491102.3517531,
author = {Abdrabou, Yasmeen and Sch\"{u}tte, Johannes and Shams, Ahmed and Pfeuffer, Ken and Buschek, Daniel and Khamis, Mohamed and Alt, Florian},
title = {”Your Eyes Tell You Have Used This Password Before”: Identifying Password Reuse from Gaze and Keystroke Dynamics},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517531},
doi = {10.1145/3491102.3517531},
abstract = {A significant drawback of text passwords for end-user authentication is password reuse. We propose a novel approach to detect password reuse by leveraging gaze as well as typing behavior and study its accuracy. We collected gaze and typing behavior from 49 users while creating accounts for 1) a webmail client and 2) a news website. While most participants came up with a new password, 32\% reported having reused an old password when setting up their accounts. We then compared different ML models to detect password reuse from the collected data. Our models achieve an accuracy of up to 87.7\% in detecting password reuse from gaze, 75.8\% accuracy from typing, and 88.75\% when considering both types of behavior. We demonstrate that using gaze, password reuse can already be detected during the registration process, before users entered their password. Our work paves the road for developing novel interventions to prevent password reuse.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {400},
numpages = {16},
keywords = {Gaze Behavior, Keystroke Dynamics, Machine Learning, Passwords},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags = {Full Paper,CHI22}
}
@inproceedings{10.1145/3491101.3519777,
author = {Prange, Sarah and Delgado Rodriguez, Sarah and Doeding, Timo and Alt, Florian},
title = {“Where did you first meet the owner?” – Exploring Usable Authentication for Smart Home Visitors},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3519777},
doi = {10.1145/3491101.3519777},
abstract = {Visitors in smart homes might want to use certain device features, as far as permitted by the device owner (e.g., streaming music on a smart speaker). At the same time, protecting access to features from attackers is crucial, motivating a need for authentication. However, it is unclear if and how smart home visitors should authenticate as they usually do not have access to respective interfaces. We explore considerations for the design of authentication for visitors evolving around, e.g., the visitors themselves as well as the environment and concrete mechanisms. Moreover, we suggest a concrete idea: security questions to authenticate visitors in smart homes. In an interview study (N = 24), we found that owners and visitors appreciated the low effort and would adapt our approach. We conclude with future research directions that we hope will spark further discussions around the design of authentication for smart homes, considering visitors and owners alike.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {415},
numpages = {7},
keywords = {visitors, usable security, smart homes, smart devices, security questions, authentication},
location = {New Orleans, LA, USA},
series = {CHI EA '22},
tags = {Late Breaking Work,CHI22}
}
@inproceedings{10.1145/3491101.3519843,
author = {Zargham, Nima and Alexandrovsky, Dmitry and Erich, Jan and Wenig, Nina and Malaka, Rainer},
title = {“I Want It That Way”: Exploring Users’ Customization and Personalization Preferences for Home Assistants},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3519843},
doi = {10.1145/3491101.3519843},
abstract = {Home assistants are becoming a widespread product, but they mostly come as a compact device and offer very few customization and personalization features, which often leads to dissatisfaction. With the technological advancements, these systems are becoming more adaptable to the users’ needs and can better imitate a human personality. To achieve that efficiently, understanding how different users envision their desired assistant is crucial. To identify people’s customization and personalization preferences and their desired personality for a home assistant, we designed a set of storyboards depicting a variety of possible features in a domestic setting and conducted a user study (), including a series of semi-structured interviews. Our quantitative results suggest that users prefer an agent which is highly agreeable and has higher conscientiousness and emotional stability. Furthermore, we discuss users’ customization and personalization preferences for a home assistant, which could be considered when designing the future generation of home assistants.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {270},
numpages = {8},
keywords = {Voice Assistants, Personalization, Personality, Home Assistants, Customization, Big Five},
location = {New Orleans, LA, USA},
series = {CHI EA '22},
tags = {Late Breaking Work,CHI22}
}
@inproceedings{10.1145/3491102.3502115,
author = {Zargham, Nima and Pfau, Johannes and Schnackenberg, Tobias and Malaka, Rainer},
title = {“I Didn’t Catch That, But I’ll Try My Best”: Anticipatory Error Handling in a Voice Controlled Game},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502115},
doi = {10.1145/3491102.3502115},
abstract = {Advances in speech recognition, language processing and natural interaction have led to an increased industrial and academic interest. While the robustness and usability of such systems are steadily increasing, speech-based systems are still susceptible to recognition errors. This makes intelligent error handling of utmost importance for the success of those systems. In this work, we integrated anticipatory error handling for a voice-controlled video game where the game would perform a locally optimized action in respect to goal completion and obstacle avoidance, when a command is not recognized. We evaluated the user experience of our approach versus traditional, repetition-based error handling (). Our results indicate that implementing anticipatory error handling can improve the usability of a system, if it follows the intention of the user. Otherwise, it impairs the user experience, even when deciding for technically optimal decisions.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {153},
numpages = {13},
keywords = {Error Handling, Game Design, Speech-Based Systems, Voice Interaction, Voice User Interfaces, Voice-Controlled Game},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags = {Full Paper,CHI22}
}
@inproceedings{10.1145/3491102.3502014,
author = {Dechant, Martin Johannes and Welsch, Robin and Frommel, Julian and Mandryk, Regan L},
title = {(Don’t) stand by me: How trait psychopathy and NPC emotion influence player perceptions, verbal responses, and movement behaviours in a gaming task},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502014},
doi = {10.1145/3491102.3502014},
abstract = {Social interactions are an essential part of many digital games, and provide benefits to players; however, problematic social interactions also lead to harm. To inform our understanding of the origins of harmful social behaviours in gaming contexts, we examine how trait psychopathy influences player perceptions and behaviours within a gaming task. After measuring participants’ (n=385) trait-level boldness, meanness, and disinhibition, we expose them to neutral and angry social interactions with a non-player character (NPC) in a gaming task and assess their perceptions, verbal responses, and movement behaviours. Our findings demonstrate that the traits significantly influence interpretation of NPC emotion, verbal responses to the NPC, and movement behaviours around the NPC. These insights can inform the design of social games and communities and can help designers and researchers better understand how social functioning translates into gaming contexts.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {468},
numpages = {17},
keywords = {behaviour, boldness, disinhibition, gaming, interpersonal distance, meanness, personality traits, psychopathy, social interaction},
location = {New Orleans, LA, USA},
series = {CHI '22},
tags = {Full Paper,CHI22}
}